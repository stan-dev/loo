[{"path":"https://mc-stan.org/loo/dev/articles/loo2-elpd.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Holdout validation and K-fold cross-validation of Stan programs with the loo package","text":"vignette demonstrates holdout validation K-fold cross-validation loo Stan program.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-elpd.html","id":"example-eradication-of-roaches-using-holdout-validation-approach","dir":"Articles","previous_headings":"","what":"Example: Eradication of Roaches using holdout validation approach","title":"Holdout validation and K-fold cross-validation of Stan programs with the loo package","text":"vignette uses example vignettes Using loo package (version >= 2.0.0) Avoiding model refits leave-one-cross-validation moment matching.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-elpd.html","id":"coding-the-stan-model","dir":"Articles","previous_headings":"Example: Eradication of Roaches using holdout validation approach","what":"Coding the Stan model","title":"Holdout validation and K-fold cross-validation of Stan programs with the loo package","text":"Stan code fitting Poisson regression model: Following usual approach recommended Writing Stan programs use loo package, compute log-likelihood observation generated quantities block Stan program.","code":"# Note: some syntax used in this Stan program requires RStan >= 2.26 (or CmdStanR) # To use an older version of RStan change the line declaring `y` to: int y[N]; stancode <- \" data {   int<lower=1> K;   int<lower=1> N;   matrix[N,K] x;   array[N] int y;   vector[N] offset;    real beta_prior_scale;   real alpha_prior_scale; } parameters {   vector[K] beta;   real intercept; } model {   y ~ poisson(exp(x * beta + intercept + offset));   beta ~ normal(0,beta_prior_scale);   intercept ~ normal(0,alpha_prior_scale); } generated quantities {   vector[N] log_lik;   for (n in 1:N)     log_lik[n] = poisson_lpmf(y[n] | exp(x[n] * beta + intercept + offset[n])); } \""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-elpd.html","id":"setup","dir":"Articles","previous_headings":"Example: Eradication of Roaches using holdout validation approach","what":"Setup","title":"Holdout validation and K-fold cross-validation of Stan programs with the loo package","text":"addition loo, load rstan package fitting model. also need rstanarm package data.","code":"library(\"rstan\") library(\"loo\") seed <- 9547 set.seed(seed)"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-elpd.html","id":"holdout-validation","dir":"Articles","previous_headings":"","what":"Holdout validation","title":"Holdout validation and K-fold cross-validation of Stan programs with the loo package","text":"approach, model first fit “train” data evaluated held-“test” data.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-elpd.html","id":"splitting-the-data-between-train-and-test","dir":"Articles","previous_headings":"Holdout validation","what":"Splitting the data between train and test","title":"Holdout validation and K-fold cross-validation of Stan programs with the loo package","text":"data divided train (80% data) test (20%):","code":"# Prepare data data(roaches, package = \"rstanarm\") roaches$roach1 <- sqrt(roaches$roach1) roaches$offset <- log(roaches[,\"exposure2\"]) # 20% of the data goes to the test set: roaches$test <- 0 roaches$test[sample(.2 * seq_len(nrow(roaches)))] <- 1 # data to \"train\" the model data_train <- list(y = roaches$y[roaches$test == 0],                    x = as.matrix(roaches[roaches$test == 0,                                          c(\"roach1\", \"treatment\", \"senior\")]),                    N = nrow(roaches[roaches$test == 0,]),                    K = 3,                    offset = roaches$offset[roaches$test == 0],                    beta_prior_scale = 2.5,                    alpha_prior_scale = 5.0                    ) # data to \"test\" the model data_test <- list(y = roaches$y[roaches$test == 1],                    x = as.matrix(roaches[roaches$test == 1,                                          c(\"roach1\", \"treatment\", \"senior\")]),                    N = nrow(roaches[roaches$test == 1,]),                    K = 3,                    offset = roaches$offset[roaches$test == 1],                    beta_prior_scale = 2.5,                    alpha_prior_scale = 5.0                    )"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-elpd.html","id":"fitting-the-model-with-rstan","dir":"Articles","previous_headings":"Holdout validation","what":"Fitting the model with RStan","title":"Holdout validation and K-fold cross-validation of Stan programs with the loo package","text":"Next fit model “test” data Stan using rstan package: recompute generated quantities using posterior draws conditional training data, now pass held-data get log predictive densities test data. using independent data, log predictive density coincides log likelihood test data.","code":"# Compile stanmodel <- stan_model(model_code = stancode) WARNING: Rtools is required to build R packages, but is not currently installed.  Please download and install the appropriate version of Rtools for 4.5.1 from https://cran.r-project.org/bin/windows/Rtools/. Trying to compile a simple C file Running \"C:/PROGRA~1/R/R-45~1.1/bin/x64/Rcmd.exe\" SHLIB foo.c using C compiler: 'gcc.exe (GCC) 14.2.0' gcc  -I\"C:/PROGRA~1/R/R-45~1.1/include\" -DNDEBUG   -I\"C:/Users/visru/AppData/Local/R/win-library/4.5/Rcpp/include/\"  -I\"C:/Users/visru/AppData/Local/R/win-library/4.5/RcppEigen/include/\"  -I\"C:/Users/visru/AppData/Local/R/win-library/4.5/RcppEigen/include/unsupported\"  -I\"C:/Users/visru/AppData/Local/R/win-library/4.5/BH/include\" -I\"C:/Users/visru/AppData/Local/R/win-library/4.5/StanHeaders/include/src/\"  -I\"C:/Users/visru/AppData/Local/R/win-library/4.5/StanHeaders/include/\"  -I\"C:/Users/visru/AppData/Local/R/win-library/4.5/RcppParallel/include/\" -DRCPP_PARALLEL_USE_TBB=1 -I\"C:/Users/visru/AppData/Local/R/win-library/4.5/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include \"C:/Users/visru/AppData/Local/R/win-library/4.5/StanHeaders/include/stan/math/prim/fun/Eigen.hpp\"  -std=c++1y    -I\"C:/rtools45/x86_64-w64-mingw32.static.posix/include\"      -O2 -Wall -std=gnu2x  -mfpmath=sse -msse2 -mstackrealign   -c foo.c -o foo.o cc1.exe: warning: command-line option '-std=c++14' is valid for C++/ObjC++ but not for C In file included from C:/Users/visru/AppData/Local/R/win-library/4.5/RcppEigen/include/Eigen/Core:19,                  from C:/Users/visru/AppData/Local/R/win-library/4.5/RcppEigen/include/Eigen/Dense:1,                  from C:/Users/visru/AppData/Local/R/win-library/4.5/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22,                  from <command-line>: C:/Users/visru/AppData/Local/R/win-library/4.5/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: cmath: No such file or directory   679 | #include <cmath>       |          ^~~~~~~ compilation terminated. make: *** [C:/PROGRA~1/R/R-45~1.1/etc/x64/Makeconf:289: foo.o] Error 1 WARNING: Rtools is required to build R packages, but is not currently installed.  Please download and install the appropriate version of Rtools for 4.5.1 from https://cran.r-project.org/bin/windows/Rtools/. # Fit model fit <- sampling(stanmodel, data = data_train, seed = seed, refresh = 0) gen_test <- gqs(stanmodel, draws = as.matrix(fit), data= data_test) log_pd <- extract_log_lik(gen_test)"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-elpd.html","id":"computing-holdout-elpd","dir":"Articles","previous_headings":"Holdout validation","what":"Computing holdout elpd:","title":"Holdout validation and K-fold cross-validation of Stan programs with the loo package","text":"Now evaluate predictive performance model test data using elpd(). one wants compare different models, function loo_compare() can used assess difference performance.","code":"(elpd_holdout <- elpd(log_pd)) Computed from 4000 by 52 log-likelihood matrix using the generic elpd function       Estimate    SE elpd  -1745.4 292.2 ic     3490.8 584.3"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-elpd.html","id":"k-fold-cross-validation","dir":"Articles","previous_headings":"","what":"K-fold cross validation","title":"Holdout validation and K-fold cross-validation of Stan programs with the loo package","text":"approach data divided folds, time one fold tested rest data used fit model (see Vehtari et al., 2017).","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-elpd.html","id":"splitting-the-data-in-folds","dir":"Articles","previous_headings":"K-fold cross validation","what":"Splitting the data in folds","title":"Holdout validation and K-fold cross-validation of Stan programs with the loo package","text":"use data already pre-processed divide 10 random folds using kfold_split_random","code":"# Prepare data roaches$fold <- kfold_split_random(K = 10, N = nrow(roaches))"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-elpd.html","id":"fitting-and-extracting-the-log-pointwise-predictive-densities-for-each-fold","dir":"Articles","previous_headings":"K-fold cross validation","what":"Fitting and extracting the log pointwise predictive densities for each fold","title":"Holdout validation and K-fold cross-validation of Stan programs with the loo package","text":"now loop 10 folds. fold following. First, fit model observations except ones belonging left-fold. Second, compute log pointwise predictive densities left-fold. Last, store predictive density observations left-fold matrix. output loop matrix log pointwise predictive densities observations.","code":"# Prepare a matrix with the number of post-warmup iterations by number of observations: log_pd_kfold <- matrix(nrow = 4000, ncol = nrow(roaches)) # Loop over the folds for(k in 1:10){   data_train <- list(y = roaches$y[roaches$fold != k],                    x = as.matrix(roaches[roaches$fold != k,                                          c(\"roach1\", \"treatment\", \"senior\")]),                    N = nrow(roaches[roaches$fold != k,]),                    K = 3,                    offset = roaches$offset[roaches$fold != k],                    beta_prior_scale = 2.5,                    alpha_prior_scale = 5.0                    )   data_test <- list(y = roaches$y[roaches$fold == k],                    x = as.matrix(roaches[roaches$fold == k,                                          c(\"roach1\", \"treatment\", \"senior\")]),                    N = nrow(roaches[roaches$fold == k,]),                    K = 3,                    offset = roaches$offset[roaches$fold == k],                    beta_prior_scale = 2.5,                    alpha_prior_scale = 5.0                    )   fit <- sampling(stanmodel, data = data_train, seed = seed, refresh = 0)   gen_test <- gqs(stanmodel, draws = as.matrix(fit), data= data_test)   log_pd_kfold[, roaches$fold == k] <- extract_log_lik(gen_test) }"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-elpd.html","id":"computing-k-fold-elpd","dir":"Articles","previous_headings":"K-fold cross validation","what":"Computing K-fold elpd:","title":"Holdout validation and K-fold cross-validation of Stan programs with the loo package","text":"Now evaluate predictive performance model 10 folds using elpd(). one wants compare several models (loo_compare), one use folds different models.","code":"(elpd_kfold <- elpd(log_pd_kfold)) Computed from 4000 by 262 log-likelihood matrix using the generic elpd function       Estimate     SE elpd  -5549.7  726.3 ic    11099.4 1452.6"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-elpd.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Holdout validation and K-fold cross-validation of Stan programs with the loo package","text":"Gelman, ., Hill, J. (2007). Data Analysis Using Regression Multilevel Hierarchical Models. Cambridge University Press. Stan Development Team (2020) RStan: R interface Stan, Version 2.21.1 https://mc-stan.org Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. :10.1007/s11222-016-9696-4. Links: published | arXiv preprint.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-example.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using the loo package (version >= 2.0.0)","text":"vignette demonstrates use loo package carry Pareto smoothed importance-sampling leave-one-cross-validation (PSIS-LOO) purposes model checking model comparison. vignette can’t provide necessary background information PSIS-LOO diagnostics (Pareto kk effective sample size), encourage readers refer following papers details: Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. :10.1007/s11222-016-9696-4. Links: published | preprint arXiv. Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-example.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Using the loo package (version >= 2.0.0)","text":"addition loo package, ’ll also using rstanarm bayesplot:","code":"library(\"rstanarm\") library(\"bayesplot\") library(\"loo\")"},{"path":[]},{"path":"https://mc-stan.org/loo/dev/articles/loo2-example.html","id":"background-and-model-fitting","dir":"Articles","previous_headings":"Example: Poisson vs negative binomial for the roaches dataset","what":"Background and model fitting","title":"Using the loo package (version >= 2.0.0)","text":"Poisson negative binomial regression models used example, well stan_glm function used fit models, covered depth rstanarm vignette Estimating Generalized Linear Models Count Data rstanarm. rest vignette assume reader already familiar kinds models.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-example.html","id":"roaches-data","dir":"Articles","previous_headings":"Example: Poisson vs negative binomial for the roaches dataset > Background and model fitting","what":"Roaches data","title":"Using the loo package (version >= 2.0.0)","text":"example data ’ll use comes Chapter 8.3 Gelman Hill (2007). want make inferences efficacy certain pest management system reducing number roaches urban apartments. Gelman Hill describe experiment data (pg. 161): treatment control applied 160 104 apartments, respectively, outcome measurement yiy_i apartment ii number roaches caught set traps. Different apartments traps different numbers days addition intercept, regression predictors model roach1, pre-treatment number roaches (rescaled units hundreds), treatment indicator treatment, variable indicating whether apartment building restricted elderly residents senior. number days roach traps used apartments sample, use offset argument specify log(exposure2) added linear predictor.","code":"# the 'roaches' data frame is included with the rstanarm package data(roaches) str(roaches)  # rescale to units of hundreds of roaches roaches$roach1 <- roaches$roach1 / 100"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-example.html","id":"fit-poisson-model","dir":"Articles","previous_headings":"Example: Poisson vs negative binomial for the roaches dataset > Background and model fitting","what":"Fit Poisson model","title":"Using the loo package (version >= 2.0.0)","text":"’ll fit simple Poisson regression model using stan_glm function rstanarm package. Usually also run posterior predictive checks shown rstanarm vignette Estimating Generalized Linear Models Count Data rstanarm, focus methods provided loo package.","code":"fit1 <-   stan_glm(     formula = y ~ roach1 + treatment + senior,     offset = log(exposure2),     data = roaches,     family = poisson(link = \"log\"),     prior = normal(0, 2.5, autoscale = TRUE),     prior_intercept = normal(0, 5, autoscale = TRUE),     seed = 12345   )"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-example.html","id":"using-the-loo-package-for-model-checking-and-comparison","dir":"Articles","previous_headings":"Example: Poisson vs negative binomial for the roaches dataset","what":"Using the loo package for model checking and comparison","title":"Using the loo package (version >= 2.0.0)","text":"Although cross-validation mostly used model comparison, also useful model checking.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-example.html","id":"computing-psis-loo-and-checking-diagnostics","dir":"Articles","previous_headings":"Example: Poisson vs negative binomial for the roaches dataset > Using the loo package for model checking and comparison","what":"Computing PSIS-LOO and checking diagnostics","title":"Using the loo package (version >= 2.0.0)","text":"start computing PSIS-LOO loo function. Since fit model using rstanarm can use loo method stanreg objects (fitted model objects rstanarm), doesn’t require us first extract pointwise log-likelihood values. written Stan program instead using rstanarm pass array matrix log-likelihood values loo function (see, e.g. help(\"loo.array\", package = \"loo\")). ’ll also use argument save_psis = TRUE save intermediate results re-used later. loo gives us warnings Pareto diagnostics, indicate observations leave-one-posteriors different enough full posterior importance-sampling able correct difference. can see details printing loo object. table shows us summary Pareto kk diagnostic, used assess reliability estimates. addition proportion leave-one-folds kk values different intervals, minimum effective sample sizes category shown give idea higher kk values bad. Since k>1k>1, able compute estimate Monte Carlo standard error (SE) expected log predictive density (elpd_loo) NA displayed. (Full details interpretation Pareto kk diagnostics available Vehtari, Gelman, Gabry (2017) Vehtari, Simpson, Gelman, Yao, Gabry (2024) papers referenced top vignette.) case elpd_loo estimate considered reliable. well-specified model expect estimated effective number parameters (p_loo) smaller similar total number parameters model. p_loo almost 300, 70 times total number parameters model, indicating severe model misspecification.","code":"loo1 <- loo(fit1, save_psis = TRUE) print(loo1)"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-example.html","id":"plotting-pareto-k-diagnostics","dir":"Articles","previous_headings":"Example: Poisson vs negative binomial for the roaches dataset > Using the loo package for model checking and comparison","what":"Plotting Pareto kk diagnostics","title":"Using the loo package (version >= 2.0.0)","text":"Using plot method loo1 object produces plot kk values (order observations dataset used fit model) horizontal lines corresponding categories printed output . plot useful quickly see distribution kk values, ’s often also possible see structure respect data ordering. case mild, seems block data somewhat easier predict (indices around 90–150). Unfortunately even data points see high kk values.","code":"plot(loo1)"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-example.html","id":"marginal-posterior-predictive-checks","dir":"Articles","previous_headings":"Example: Poisson vs negative binomial for the roaches dataset > Using the loo package for model checking and comparison","what":"Marginal posterior predictive checks","title":"Using the loo package (version >= 2.0.0)","text":"loo package can used combination bayesplot package leave-one-cross-validation marginal posterior predictive checks Gabry et al (2018). LOO-PIT values cumulative probabilities yiy_i computed using LOO marginal predictive distributions p(yi|y−)p(y_i|y_{-}). good model, distribution LOO-PIT values uniform. following QQ-plot LOO-PIT values model (y-axi) compared standard uniform distribution (x-axis). excessive number LOO-PIT values close 0 indicates model -dispersed compared data, consider model allows greater dispersion.","code":"yrep <- posterior_predict(fit1)  ppc_loo_pit_qq(   y = roaches$y,   yrep = yrep,   lw = weights(loo1$psis_object) )"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-example.html","id":"try-alternative-model-with-more-flexibility","dir":"Articles","previous_headings":"Example: Poisson vs negative binomial for the roaches dataset","what":"Try alternative model with more flexibility","title":"Using the loo package (version >= 2.0.0)","text":"try negative binomial regression, commonly used overdispersed count data. Unlike Poisson distribution, negative binomial distribution allows conditional mean variance yy differ. Using label_points argument label kk values larger diagnostic threshold index corresponding data point. high values often result model misspecification frequently correspond data points considered ``outliers’’ data surprising according model Gabry et al (2019). Unfortunately, large kk values useful indicator model misspecification, small kk values guarantee model well-specified. small number problematic kk values can use feature rstanarm lets us refit model problematic observations. time model refit, one observations high kk value omitted LOO calculations performed exactly observation. results recombined approximate LOO calculations already carried observations without problematic kk values: print output can see Monte Carlo SE small compared uncertainties. hand, p_loo 7 still bit higher total number parameters model. indicates almost certainly still degree model misspecification, much better p_loo estimate Poisson model. model checking examine LOO-PIT values. plot negative binomial model looks better Poisson plot, still see model capturing essential features data.","code":"fit2 <- update(fit1, family = neg_binomial_2) loo2 <- loo(fit2, save_psis = TRUE, cores = 2) print(loo2) plot(loo2, label_points = TRUE) if (any(pareto_k_values(loo2) > 0.7)) {   loo2 <- loo(fit2, save_psis = TRUE, k_threshold = 0.7) } print(loo2) yrep <- posterior_predict(fit2) ppc_loo_pit_qq(roaches$y, yrep, lw = weights(loo2$psis_object))"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-example.html","id":"comparing-the-models-on-expected-log-predictive-density","dir":"Articles","previous_headings":"Example: Poisson vs negative binomial for the roaches dataset","what":"Comparing the models on expected log predictive density","title":"Using the loo package (version >= 2.0.0)","text":"can use loo_compare function compare two models expected log predictive density (ELPD) new data: difference ELPD much larger several times estimated standard error difference indicating negative-binomial model xpected better predictive performance Poisson model. However, according LOO-PIT checks still misspecification, reasonable guess hurdle zero-inflated model improvement (leave another case study).","code":"loo_compare(loo1, loo2)"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-example.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Using the loo package (version >= 2.0.0)","text":"Gabry, J., Simpson, D., Vehtari, ., Betancourt, M. Gelman, . (2019), Visualization Bayesian workflow. J. R. Stat. Soc. , 182: 389-402. :10.1111/rssa.12378. (journal version, arXiv preprint, code GitHub) Gelman, . Hill, J. (2007). Data Analysis Using Regression Multilevel/Hierarchical Models. Cambridge University Press, Cambridge, UK. Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. :10.1007/s11222-016-9696-4. online, arXiv preprint arXiv:1507.04544. Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-large-data.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using Leave-one-out cross-validation for large data","text":"vignette demonstrates leave-one-cross-validation large data using loo package Stan. two approaches covered: LOO subsampling LOO using approximations posterior distributions. sections vignette excerpted papers Magnusson, M., Riis Andersen, M., Jonasson, J. Vehtari, . (2020). Leave-One-Cross-Validation Model Comparison Large Data. Proceedings 23rd International Conference Artificial Intelligence Statistics (AISTATS), PMLR 108. arXiv preprint arXiv:2001.00980. Magnusson, M., Andersen, M., Jonasson, J. & Vehtari, . (2019). Bayesian leave-one-cross-validation large data. Proceedings 36th International Conference Machine Learning, PMLR 97:4244-4253 online, arXiv preprint arXiv:1904.10679. Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. :10.1007/s11222-016-9696-4. Links: published | arXiv preprint. Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF provide important background understanding methods implemented package.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-large-data.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Using Leave-one-out cross-validation for large data","text":"addition loo package, ’ll also using rstan:","code":"library(\"rstan\") library(\"loo\") set.seed(4711)"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-large-data.html","id":"example-well-water-in-bangladesh","dir":"Articles","previous_headings":"","what":"Example: Well water in Bangladesh","title":"Using Leave-one-out cross-validation for large data","text":"use example vignette Writing Stan programs use loo package. See vignette description problem data. sample size example N=3020N=3020, large enough require special methods large data described vignette, sufficient demonstration purposes tutorial.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-large-data.html","id":"coding-the-stan-model","dir":"Articles","previous_headings":"Example: Well water in Bangladesh","what":"Coding the Stan model","title":"Using Leave-one-out cross-validation for large data","text":"Stan code fitting logistic regression model, save file called logistic.stan: Importantly, unlike general approach recommended Writing Stan programs use loo package, compute log-likelihood observation generated quantities block Stan program. assuming large data set (larger one ’re actually using demonstration) preferable instead define function R compute log-likelihood data point needed rather storing log-likelihood values memory. log-likelihood R can coded follows: function llfun_logistic() needs arguments data_i draws. test function working using loo_i() function.","code":"// Note: some syntax used in this program requires RStan >= 2.26 (or CmdStanR) // To use an older version of RStan change the line declaring `y` to: //    int<lower=0,upper=1> y[N]; data {   int<lower=0> N;             // number of data points   int<lower=0> P;             // number of predictors (including intercept)   matrix[N,P] X;              // predictors (including 1s for intercept)   array[N] int<lower=0,upper=1> y;  // binary outcome } parameters {   vector[P] beta; } model {   beta ~ normal(0, 1);   y ~ bernoulli_logit(X * beta); } # we'll add an argument log to toggle whether this is a log-likelihood or  # likelihood function. this will be useful later in the vignette. llfun_logistic <- function(data_i, draws, log = TRUE) {   x_i <- as.matrix(data_i[, which(grepl(colnames(data_i), pattern = \"X\")), drop=FALSE])   logit_pred <- draws %*% t(x_i)   dbinom(x = data_i$y, size = 1, prob = 1/(1 + exp(-logit_pred)), log = log) }"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-large-data.html","id":"fitting-the-model-with-rstan","dir":"Articles","previous_headings":"Example: Well water in Bangladesh","what":"Fitting the model with RStan","title":"Using Leave-one-out cross-validation for large data","text":"Next fit model Stan using rstan package: move computing LOO can now test log-likelihood function wrote working . loo_i() function helper function can used test log-likelihood function single observation.","code":"# Prepare data url <- \"http://stat.columbia.edu/~gelman/arm/examples/arsenic/wells.dat\" wells <- read.table(url) wells$dist100 <- with(wells, dist / 100) X <- model.matrix(~ dist100 + arsenic, wells) standata <- list(y = wells$switch, X = X, N = nrow(X), P = ncol(X))  # Compile stan_mod <- stan_model(\"logistic.stan\")  # Fit model fit_1 <- sampling(stan_mod, data = standata, seed = 4711) print(fit_1, pars = \"beta\") mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat beta[1]  0.00       0 0.08 -0.15 -0.05  0.00  0.06  0.16  1933    1 beta[2] -0.89       0 0.10 -1.09 -0.96 -0.89 -0.82 -0.69  2332    1 beta[3]  0.46       0 0.04  0.38  0.43  0.46  0.49  0.54  2051    1 # used for draws argument to loo_i parameter_draws_1 <- extract(fit_1)$beta  # used for data argument to loo_i stan_df_1 <- as.data.frame(standata)  # compute relative efficiency (this is slow and optional but is recommended to allow  # for adjusting PSIS effective sample size based on MCMC effective sample size) r_eff <- relative_eff(llfun_logistic,                        log = FALSE, # relative_eff wants likelihood not log-likelihood values                       chain_id = rep(1:4, each = 1000),                        data = stan_df_1,                        draws = parameter_draws_1,                        cores = 2)  loo_i(i = 1, llfun_logistic, r_eff = r_eff, data = stan_df_1, draws = parameter_draws_1) $pointwise     elpd_loo mcse_elpd_loo        p_loo     looic influence_pareto_k 1 -0.3314552  0.0002887608 0.0003361772 0.6629103        -0.05679886 ..."},{"path":"https://mc-stan.org/loo/dev/articles/loo2-large-data.html","id":"approximate-loo-cv-using-psis-loo-and-subsampling","dir":"Articles","previous_headings":"","what":"Approximate LOO-CV using PSIS-LOO and subsampling","title":"Using Leave-one-out cross-validation for large data","text":"can use loo_subsample() function compute efficient PSIS-LOO approximation exact LOO-CV using subsampling: loo_subsample() function creates object class psis_loo_ss, inherits psis_loo, loo (classes regular loo objects). printed output shows estimates $\\widehat{\\mbox{elpd}}_{\\rm loo}$ (expected log predictive density), $\\widehat{p}_{\\rm loo}$ (effective number parameters), ${\\rm looic} =-2\\, \\widehat{\\mbox{elpd}}_{\\rm loo}$ (LOO information criterion). Unlike using loo(), using loo_subsample() additional column giving “subsampling SE”, reflects additional uncertainty due subsampling used. line bottom printed output provides information reliability LOO approximation (interpretation kk parameter explained help('pareto-k-diagnostic') greater detail Vehtari, Simpson, Gelman, Yao, Gabry (2019)). case, message tells us estimates kk fine given subsample.","code":"set.seed(4711) loo_ss_1 <-   loo_subsample(     llfun_logistic,     observations = 100, # take a subsample of size 100     cores = 2,     # these next objects were computed above     r_eff = r_eff,      draws = parameter_draws_1,     data = stan_df_1   ) print(loo_ss_1) Computed from 4000 by 100 subsampled log-likelihood values from 3020 total observations.           Estimate   SE subsampling SE elpd_loo  -1968.5 15.6            0.3 p_loo         3.1  0.1            0.4 looic      3936.9 31.2            0.6 ------ Monte Carlo SE of elpd_loo is 0.0. MCSE and ESS estimates assume MCMC draws (r_eff in [0.9, 1.0]).  All Pareto k estimates are good (k < 0.7). See help('pareto-k-diagnostic') for details."},{"path":"https://mc-stan.org/loo/dev/articles/loo2-large-data.html","id":"adding-additional-subsamples","dir":"Articles","previous_headings":"Approximate LOO-CV using PSIS-LOO and subsampling","what":"Adding additional subsamples","title":"Using Leave-one-out cross-validation for large data","text":"satisfied subsample size (.e., accuracy) can simply add samples satisfied using update() method.","code":"set.seed(4711) loo_ss_1b <-   update(     loo_ss_1,     observations = 200, # subsample 200 instead of 100     r_eff = r_eff,     draws = parameter_draws_1,     data = stan_df_1   )  print(loo_ss_1b) Computed from 4000 by 200 subsampled log-likelihood values from 3020 total observations.           Estimate   SE subsampling SE elpd_loo  -1968.3 15.6            0.2 p_loo         3.2  0.1            0.4 looic      3936.7 31.2            0.5 ------ Monte Carlo SE of elpd_loo is 0.0. MCSE and ESS estimates assume MCMC draws (r_eff in [0.9, 1.0]).  All Pareto k estimates are good (k < 0.7). See help('pareto-k-diagnostic') for details."},{"path":"https://mc-stan.org/loo/dev/articles/loo2-large-data.html","id":"specifying-estimator-and-sampling-method","dir":"Articles","previous_headings":"Approximate LOO-CV using PSIS-LOO and subsampling","what":"Specifying estimator and sampling method","title":"Using Leave-one-out cross-validation for large data","text":"performance relies two components: estimation method approximation used elpd. See documentation loo_subsample() information estimators approximations implemented. default implementation using point log predictive density evaluated mean posterior (loo_approximation=\"plpd\") difference estimator (estimator=\"diff_srs\"). combination focus fast inference. can easily use estimators well elpd approximations, example: See documentation references loo_subsample() details implemented approximations.","code":"set.seed(4711) loo_ss_1c <-   loo_subsample(     x = llfun_logistic,     r_eff = r_eff,     draws = parameter_draws_1,     data = stan_df_1,     observations = 100,     estimator = \"hh_pps\", # use Hansen-Hurwitz     loo_approximation = \"lpd\", # use lpd instead of plpd     loo_approximation_draws = 100,     cores = 2   ) print(loo_ss_1c) Computed from 4000 by 100 subsampled log-likelihood values from 3020 total observations.           Estimate   SE subsampling SE elpd_loo  -1968.9 15.4            0.5 p_loo         3.5  0.2            0.5 looic      3937.9 30.7            1.1 ------ Monte Carlo SE of elpd_loo is 0.0. MCSE and ESS estimates assume MCMC draws (r_eff in [0.9, 1.0]).  All Pareto k estimates are good (k < 0.7). See help('pareto-k-diagnostic') for details."},{"path":"https://mc-stan.org/loo/dev/articles/loo2-large-data.html","id":"approximate-loo-cv-using-psis-loo-with-posterior-approximations","dir":"Articles","previous_headings":"","what":"Approximate LOO-CV using PSIS-LOO with posterior approximations","title":"Using Leave-one-out cross-validation for large data","text":"Using posterior approximations, variational inference Laplace approximations, can speed-LOO-CV large data. demonstrate using Laplace approximation Stan. Using posterior approximation can LOO-CV correcting posterior approximation compute elpd. use loo_approximate_posterior() function. function creates class, psis_loo_ap inherits psis_loo, loo.","code":"fit_laplace <- optimizing(stan_mod, data = standata, draws = 2000,                            importance_resampling = TRUE) parameter_draws_laplace <- fit_laplace$theta_tilde # draws from approximate posterior log_p <- fit_laplace$log_p # log density of the posterior log_g <- fit_laplace$log_g # log density of the approximation set.seed(4711) loo_ap_1 <-   loo_approximate_posterior(     x = llfun_logistic,     draws = parameter_draws_laplace,     data = stan_df_1,     log_p = log_p,     log_g = log_g,     cores = 2   ) print(loo_ap_1) Computed from 2000 by 3020 log-likelihood matrix           Estimate   SE elpd_loo  -1968.4 15.6 p_loo         3.2  0.2 looic      3936.8 31.2 ------ Posterior approximation correction used. Monte Carlo SE of elpd_loo is 0.0. MCSE and ESS estimates assume independent draws (r_eff=1).  All Pareto k estimates are good (k < 0.7). See help('pareto-k-diagnostic') for details."},{"path":"https://mc-stan.org/loo/dev/articles/loo2-large-data.html","id":"combining-the-posterior-approximation-method-with-subsampling","dir":"Articles","previous_headings":"Approximate LOO-CV using PSIS-LOO with posterior approximations","what":"Combining the posterior approximation method with subsampling","title":"Using Leave-one-out cross-validation for large data","text":"posterior approximation correction can also used together subsampling: object created class psis_loo_ss, inherits psis_loo_ap class previously described.","code":"set.seed(4711) loo_ap_ss_1 <-   loo_subsample(     x = llfun_logistic,     draws = parameter_draws_laplace,     data = stan_df_1,     log_p = log_p,     log_g = log_g,     observations = 100,     cores = 2   ) print(loo_ap_ss_1) Computed from 2000 by 100 subsampled log-likelihood values from 3020 total observations.           Estimate   SE subsampling SE elpd_loo  -1968.2 15.6            0.4 p_loo         2.9  0.1            0.5 looic      3936.4 31.1            0.8 ------ Posterior approximation correction used. Monte Carlo SE of elpd_loo is 0.0. MCSE and ESS estimates assume independent draws (r_eff=1).  All Pareto k estimates are good (k < 0.7). See help('pareto-k-diagnostic') for details."},{"path":"https://mc-stan.org/loo/dev/articles/loo2-large-data.html","id":"comparing-models","dir":"Articles","previous_headings":"Approximate LOO-CV using PSIS-LOO with posterior approximations","what":"Comparing models","title":"Using Leave-one-out cross-validation for large data","text":"compare model alternative model data can use loo_compare() function just using loo() instead loo_subsample() loo_approximate_posterior(). First ’ll fit second model well-switching data, using log(arsenic) instead arsenic predictor: can now compare models LOO using loo_compare function: new object comp contains estimated difference expected leave-one-prediction errors two models, along standard error. warning indicates, different subsamples used comparison take correlations different observations account. see naive SE 22.5 see difference performance models. force subsampling use observations models can simply extract observations used loo_ss_1 use loo_ss_2 supplying loo_ss_1 object observations argument. also supply subsampling indices using obs_idx() helper function: results message indicating assume observations sampled simple random sampling, true used default \"diff_srs\" estimator loo_ss_1. can now compare models estimate difference based subsampled observations. First, notice now se_diff now around 4 (opposed 20 using different subsamples). first column shows difference ELPD relative model largest ELPD. case, difference elpd scale relative approximate standard error difference) indicates preference second model (model2). Since subsampling uncertainty small case can effectively ignored. need larger subsamples can simply add samples using update() method demonstrated earlier. also possible compare subsampled loo computation full loo object. comparing non-subsampled loo calculation subsampled calculation get message observations included loo calculations model1 model2 included computations comparison. actually see increase subsampling_se_diff, due technical detail elaborated . general, difference better negligible.","code":"standata$X[, \"arsenic\"] <- log(standata$X[, \"arsenic\"]) fit_2 <- sampling(stan_mod, data = standata)  parameter_draws_2 <- extract(fit_2)$beta stan_df_2 <- as.data.frame(standata)  # recompute subsampling loo for first model for demonstration purposes  # compute relative efficiency (this is slow and optional but is recommended to allow  # for adjusting PSIS effective sample size based on MCMC effective sample size) r_eff_1 <- relative_eff(   llfun_logistic,   log = FALSE, # relative_eff wants likelihood not log-likelihood values   chain_id = rep(1:4, each = 1000),   data = stan_df_1,   draws = parameter_draws_1,   cores = 2 )  set.seed(4711) loo_ss_1 <- loo_subsample(   x = llfun_logistic,   r_eff = r_eff_1,   draws = parameter_draws_1,   data = stan_df_1,   observations = 200,   cores = 2 )  # compute subsampling loo for a second model (with log-arsenic)  r_eff_2 <- relative_eff(   llfun_logistic,   log = FALSE, # relative_eff wants likelihood not log-likelihood values   chain_id = rep(1:4, each = 1000),   data = stan_df_2,   draws = parameter_draws_2,   cores = 2 ) loo_ss_2 <- loo_subsample(   x = llfun_logistic,   r_eff = r_eff_2,    draws = parameter_draws_2,   data = stan_df_2,   observations = 200,   cores = 2 )  print(loo_ss_2) Computed from 4000 by 100 subsampled log-likelihood values from 3020 total observations.           Estimate   SE subsampling SE elpd_loo  -1952.0 16.2            0.2 p_loo         2.6  0.1            0.3 looic      3903.9 32.4            0.4 ------ Monte Carlo SE of elpd_loo is 0.0. MCSE and ESS estimates assume MCMC draws (r_eff in [1.0, 1.1]).  All Pareto k estimates are good (k < 0.7). See help('pareto-k-diagnostic') for details. # Compare comp <- loo_compare(loo_ss_1, loo_ss_2) print(comp) Warning: Different subsamples in 'model2' and 'model1'. Naive diff SE is used.         elpd_diff se_diff subsampling_se_diff model2  0.0       0.0     0.0                model1 16.5      22.5     0.4 loo_ss_2 <-   loo_subsample(     x = llfun_logistic,     r_eff = r_eff_2,     draws = parameter_draws_2,     data = stan_df_2,     observations = loo_ss_1,     cores = 2   ) idx <- obs_idx(loo_ss_1) loo_ss_2 <- loo_subsample(   x = llfun_logistic,   r_eff = r_eff_2,    draws = parameter_draws_2,   data = stan_df_2,   observations = idx,   cores = 2 ) Simple random sampling with replacement assumed. comp <- loo_compare(loo_ss_1, loo_ss_2) print(comp) elpd_diff se_diff subsampling_se_diff model2  0.0       0.0     0.0                model1 16.1       4.4     0.1 # use loo() instead of loo_subsample() to compute full PSIS-LOO for model 2 loo_full_2 <- loo(   x = llfun_logistic,   r_eff = r_eff_2,   draws = parameter_draws_2,   data = stan_df_2,   cores = 2 ) loo_compare(loo_ss_1, loo_full_2) Estimated elpd_diff using observations included in loo calculations for all models. elpd_diff se_diff subsampling_se_diff model2  0.0       0.0     0.0                model1 16.3       4.4     0.3"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-large-data.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Using Leave-one-out cross-validation for large data","text":"Gelman, ., Hill, J. (2007). Data Analysis Using Regression Multilevel Hierarchical Models. Cambridge University Press. Stan Development Team (2017). Stan C++ Library, Version 2.17.0. https://mc-stan.org/ Stan Development Team (2018) RStan: R interface Stan, Version 2.17.3. https://mc-stan.org/ Magnusson, M., Riis Andersen, M., Jonasson, J. Vehtari, . (2020). Leave-One-Cross-Validation Model Comparison Large Data. Proceedings 23rd International Conference Artificial Intelligence Statistics (AISTATS), PMLR 108. arXiv preprint arXiv:2001.00980. Magnusson, M., Andersen, M., Jonasson, J. & Vehtari, . (2019). Bayesian leave-one-cross-validation large data. Proceedings 36th International Conference Machine Learning, PMLR 97:4244-4253 online, arXiv preprint arXiv:1904.10679. Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. :10.1007/s11222-016-9696-4. online, arXiv preprint arXiv:1507.04544. Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-lfo.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Approximate leave-future-out cross-validation for Bayesian time series models","text":"One common goals time series analysis use observed series inform predictions future observations. refer task predicting sequence MM future observations MM-step-ahead prediction (MM-SAP). Fortunately, fit model can sample posterior predictive distribution, straightforward generate predictions far future want. also straightforward evaluate MM-SAP performance time series model comparing predictions observed sequence MM future data points become available. Unfortunately, often position use model inform decisions can collect future observations required assessing predictive performance. many competing models may also need first decide models (combination models) rely predictions. situations best can use methods approximating expected predictive performance models using observations time series already . time dependence data focus assess non-time-dependent part model, use methods like leave-one-cross-validation (LOO-CV). data set NN observations, refit model NN times, time leaving one NN observations assessing well model predicts left-observation. LOO-CV expensive computationally realistic settings, Pareto smoothed importance sampling (PSIS, Vehtari et al, 2017, 2024) algorithm provided loo package allows approximating exact LOO-CV PSIS-LOO-CV. PSIS-LOO-CV requires single fit full model comes diagnostics assessing validity approximation. time series can something similar LOO-CV , except cases, make sense leave observations one time allowing information future influence predictions past (.e., times t+1,t+2,…t + 1, t+2, \\ldots used predict time tt). apply idea cross-validation MM-SAP case, instead leave-one-cross-validation need form leave-future-cross-validation (LFO-CV). demonstrate case study, LFO-CV refer one particular prediction task rather various possible cross-validation approaches involve form prediction new time series data. Like exact LOO-CV, exact LFO-CV requires refitting model many times different subsets data, computationally costly nontrivial examples, particular Bayesian analyses refitting model means estimating new posterior distribution rather point estimate. Although PSIS-LOO-CV provides efficient approximation exact LOO-CV, now analogous approximation exact LFO-CV drastically reduces computational burden also providing informative diagnostics quality approximation. case study present PSIS-LFO-CV, algorithm typically requires refitting time-series model small number times make LFO-CV tractable many realistic applications previously possible. details can found paper approximate LFO-CV (Bürkner, Gabry, & Vehtari, 2020), available preprint arXiv (https://arxiv.org/abs/1902.06281).","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-lfo.html","id":"m-step-ahead-predictions","dir":"Articles","previous_headings":"","what":"MM-step-ahead predictions","title":"Approximate leave-future-out cross-validation for Bayesian time series models","text":"Assume time series observations y=(y1,y2,…,yN)y = (y_1, y_2, \\ldots, y_N) let LL minimum number observations series require making predictions future data. Depending application informative data , may possible make reasonable predictions yi+1y_{+1} based (y1,…,yi)(y_1, \\dots, y_{}) ii large enough can learn enough time series predict future observations. Setting L=10L=10, example, means assess predictive performance starting observation y11y_{11}, always least 10 previous observations condition . order assess MM-SAP performance like compute predictive densities p(yi+1:M|y1:)=p(yi+1,…,yi+M|y1,...,yi) p(y_{+1:M} \\,|\\, y_{1:}) =    p(y_{+1}, \\ldots, y_{+ M} \\,|\\, y_{1},...,y_{}) ∈{L,…,N−M}\\\\{L, \\ldots, N - M\\}. quantities p(yi+1:M|y1:)p(y_{+1:M} \\,|\\, y_{1:}) can computed help posterior distribution p(θ|y1:)p(\\theta \\,|\\, y_{1:}) parameters θ\\theta conditional first ii observations time-series: p(yi+1:M|y1:)=∫p(yi+1:M|y1:,θ)p(θ|y1:)dθ. p(y_{+1:M} \\,| \\, y_{1:}) =    \\int p(y_{+1:M} \\,| \\, y_{1:}, \\theta) \\, p(\\theta\\,|\\,y_{1:}) \\,d\\theta. obtained SS draws (θ1:(1),…,θ1:(S))(\\theta_{1:}^{(1)}, \\ldots, \\theta_{1:}^{(S)}) posterior distribution p(θ|y1:)p(\\theta\\,|\\,y_{1:}), can estimate p(yi+1:M|y1:)p(y_{+1:M} | y_{1:}) p(yi+1:M|y1:)≈1S∑s=1Sp(yi+1:M|y1:,θ1:(s)). p(y_{+1:M} \\,|\\, y_{1:}) \\approx \\frac{1}{S}\\sum_{s=1}^S p(y_{+1:M} \\,|\\, y_{1:}, \\theta_{1:}^{(s)}).","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-lfo.html","id":"approximate_MSAP","dir":"Articles","previous_headings":"","what":"Approximate MM-SAP using importance-sampling","title":"Approximate leave-future-out cross-validation for Bayesian time series models","text":"Unfortunately, math makes use posterior distributions many different fits model different subsets data. , obtain predictive density p(yi+1:M|y1:)p(y_{+1:M} \\,|\\, y_{1:}) requires fitting model first ii data points, need every value ii consideration (∈{L,…,N−M}\\\\{L, \\ldots, N - M\\}). reduce number models need fit purpose obtaining densities p(yi+1:M|y1:)p(y_{+1:M} \\,|\\, y_{1:}), propose following algorithm. First, refit model using first LL observations time series perform single exact MM-step-ahead prediction step p(yL+1:M|y1:L)p(y_{L+1:M} \\,|\\, y_{1:L}). Recall LL minimum number observations deemed acceptable making predictions (setting L=0L=0 means first data point predicted based prior). define ⋆=Li^\\star = L current point refit. Next, starting =⋆+1i = ^\\star + 1, approximate p(yi+1:M|y1:)p(y_{+1:M} \\,|\\, y_{1:}) via p(yi+1:M|y1:)≈∑s=1Swi(s)p(yi+1:M|y1:,θ(s))∑s=1Swi(s),  p(y_{+1:M} \\,|\\, y_{1:}) \\approx    \\frac{ \\sum_{s=1}^S w_i^{(s)}\\, p(y_{+1:M} \\,|\\, y_{1:}, \\theta^{(s)})}         { \\sum_{s=1}^S w_i^{(s)}}, θ(s)=θ1:⋆(s)\\theta^{(s)} = \\theta^{(s)}_{1:^\\star} draws posterior distribution based first ⋆^\\star observations wi(s)w_i^{(s)} PSIS weights obtained two steps. First, compute raw importance ratios ri(s)=f1:(θ(s))f1:⋆(θ(s))∝∏j∈(⋆+1):ip(yj|y1:(j−1),θ(s)), r_i^{(s)} = \\frac{f_{1:}(\\theta^{(s)})}{f_{1:^\\star}(\\theta^{(s)})}  \\propto \\prod_{j \\(^\\star + 1):} p(y_j \\,|\\, y_{1:(j-1)}, \\theta^{(s)}), stabilize using PSIS. function f1:if_{1:} denotes posterior distribution based first ii observations, , f1:=p(θ|y1:)f_{1:} = p(\\theta \\,|\\, y_{1:}), f1:⋆f_{1:^\\star} defined analogously. index set (⋆+1):(^\\star + 1):indicates observations part data model f1:if_{1:} whose predictive performance trying approximate actually fitted model f1:⋆f_{1:^\\star}. proportional statement arises fact ignore normalizing constants p(y1:)p(y_{1:}) p(y1:⋆)p(y_{1:^\\star}) compared posteriors, leads self-normalized variant PSIS (see Vehtari et al, 2017). Continuing next observation, gradually increase ii 11 (move forward time) repeat process. observation ii, variability importance ratios ri(s)r_i^{(s)} become large importance sampling fail. refer particular value ii i1⋆^\\star_1. identify value i1⋆^\\star_1, check value ii estimated shape parameter kk generalized Pareto distribution first cross certain threshold τ\\tau (Vehtari et al, 2024). refit model using observations i1⋆^\\star_1 restart process setting θ(s)=θ1:i1⋆(s)\\theta^{(s)} = \\theta^{(s)}_{1:^\\star_1} ⋆=i1⋆^\\star = ^\\star_1 next refit. cases may need refit cases find value i2⋆^\\star_2 requires second refitting, maybe i3⋆^\\star_3 requires third refitting, . refit many times required (k>τk > \\tau) arrive observation =N−Mi = N - M. LOO, assuming posterior sample size 4000 larger, recommend use threshold τ=0.7\\tau = 0.7 (Vehtari et al, 2017, 2024) turns reasonable threshold LFO well (Bürkner et al. 2020).","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-lfo.html","id":"autoregressive-models","dir":"Articles","previous_headings":"","what":"Autoregressive models","title":"Approximate leave-future-out cross-validation for Bayesian time series models","text":"Autoregressive (AR) models commonly used time-series models. AR(p) model —autoregressive model order pp— can defined yi=ηi+∑k=1pφkyi−k+εi, y_i = \\eta_i + \\sum_{k = 1}^p \\varphi_k y_{- k} + \\varepsilon_i, ηi\\eta_i linear predictor iith observation, ϕk\\phi_k autoregressive parameters εi\\varepsilon_i pairwise independent errors, usually assumed normally distributed equal variance σ2\\sigma^2. model implies recursive formula allows computing right-hand side equation observation ii based values equations previous observations.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-lfo.html","id":"case-study-annual-measurements-of-the-level-of-lake-huron","dir":"Articles","previous_headings":"","what":"Case Study: Annual measurements of the level of Lake Huron","title":"Approximate leave-future-out cross-validation for Bayesian time series models","text":"illustrate application PSIS-LFO-CV estimating expected MM-SAP performance, fit model 98 annual measurements water level (feet) Lake Huron years 1875–1972. data set found datasets R package, installed automatically R. addition loo package, analysis use brms interface Stan generate Stan program fit model, also bayesplot ggplot2 packages plotting. fitting model, first put data data frame look time series.  plot shows rather strong autocorrelation time-series well trend towards lower levels later points time. can specify AR(4) model data using brms package follows: model implied predictions along observed values can plotted, reveals rather good fit data.  allow reasonable predictions future values, require least L=20L = 20 historical observations (20 years) make predictions. first perform approximate leave-one-cross-validation (LOO-CV) purpose later comparison exact approximate LFO-CV 1-SAP case.","code":"library(\"brms\") library(\"loo\") library(\"bayesplot\") library(\"ggplot2\") color_scheme_set(\"brightblue\") theme_set(theme_default())  CHAINS <- 4 SEED <- 5838296 set.seed(SEED) N <- length(LakeHuron) df <- data.frame(   y = as.numeric(LakeHuron),   year = as.numeric(time(LakeHuron)),   time = 1:N )  ggplot(df, aes(x = year, y = y)) +    geom_point(size = 1) +   labs(     y = \"Water Level (ft)\",      x = \"Year\",     title = \"Water Level in Lake Huron (1875-1972)\"   ) fit <- brm(   y ~ ar(time, p = 4),    data = df,    prior = prior(normal(0, 0.5), class = \"ar\"),   control = list(adapt_delta = 0.99),    seed = SEED,    chains = CHAINS ) preds <- posterior_predict(fit) preds <- cbind(   Estimate = colMeans(preds),    Q5 = apply(preds, 2, quantile, probs = 0.05),   Q95 = apply(preds, 2, quantile, probs = 0.95) )  ggplot(cbind(df, preds), aes(x = year, y = Estimate)) +   geom_smooth(aes(ymin = Q5, ymax = Q95), stat = \"identity\", linewidth = 0.5) +   geom_point(aes(y = y)) +    labs(     y = \"Water Level (ft)\",      x = \"Year\",     title = \"Water Level in Lake Huron (1875-1972)\",     subtitle = \"Mean (blue) and 90% predictive intervals (gray) vs. observed data (black)\"   ) L <- 20 loo_cv <- loo(log_lik(fit)[, (L + 1):N]) print(loo_cv) Computed from 4000 by 78 log-likelihood matrix.           Estimate   SE elpd_loo    -88.5  6.4 p_loo         4.7  1.0 looic       177.1 12.8 ------ MCSE of elpd_loo is 0.0. MCSE and ESS estimates assume independent draws (r_eff=1).  All Pareto k estimates are good (k < 0.7). See help('pareto-k-diagnostic') for details."},{"path":"https://mc-stan.org/loo/dev/articles/loo2-lfo.html","id":"step-ahead-predictions-leaving-out-all-future-values","dir":"Articles","previous_headings":"","what":"1-step-ahead predictions leaving out all future values","title":"Approximate leave-future-out cross-validation for Bayesian time series models","text":"basic version MM-SAP 1-SAP, predict one step ahead. case, yi+1:My_{+1:M} simplifies yiy_{} LFO-CV algorithm becomes considerably simpler larger values MM.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-lfo.html","id":"exact-1-step-ahead-predictions","dir":"Articles","previous_headings":"1-step-ahead predictions leaving out all future values","what":"Exact 1-step-ahead predictions","title":"Approximate leave-future-out cross-validation for Bayesian time series models","text":"compute approximate LFO-CV using PSIS first compute exact LFO-CV 1-SAP case can use benchmark later. initial step exact computation calculate log-predictive densities refitting model many times: compute exact expected log predictive density (ELPD): see ELPD LFO-CV 1-step-ahead predictions lower ELPD estimate LOO-CV, expected since LOO-CV making use time series. , since LFO-CV approach uses observations left-data point LOO-CV uses data points left-observation, expect see larger ELPD LOO-CV.","code":"loglik_exact <- matrix(nrow = ndraws(fit), ncol = N) for (i in L:(N - 1)) {   past <- 1:i   oos <- i + 1   df_past <- df[past, , drop = FALSE]   df_oos <- df[c(past, oos), , drop = FALSE]   fit_i <- update(fit, newdata = df_past, recompile = FALSE)   loglik_exact[, i + 1] <- log_lik(fit_i, newdata = df_oos, oos = oos)[, oos] } # some helper functions we'll use throughout  # more stable than log(sum(exp(x)))  log_sum_exp <- function(x) {   max_x <- max(x)     max_x + log(sum(exp(x - max_x))) }  # more stable than log(mean(exp(x))) log_mean_exp <- function(x) {   log_sum_exp(x) - log(length(x)) }  # compute log of raw importance ratios # sums over observations *not* over posterior samples sum_log_ratios <- function(loglik, ids = NULL) {   if (!is.null(ids)) loglik <- loglik[, ids, drop = FALSE]   rowSums(loglik) }  # for printing comparisons later rbind_print <- function(...) {   round(rbind(...), digits = 2) } exact_elpds_1sap <- apply(loglik_exact, 2, log_mean_exp) exact_elpd_1sap <- c(ELPD = sum(exact_elpds_1sap[-(1:L)]))  rbind_print(   \"LOO\" = loo_cv$estimates[\"elpd_loo\", \"Estimate\"],   \"LFO\" = exact_elpd_1sap ) ELPD LOO -88.53 LFO -92.48"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-lfo.html","id":"approximate-1-step-ahead-predictions","dir":"Articles","previous_headings":"1-step-ahead predictions leaving out all future values","what":"Approximate 1-step-ahead predictions","title":"Approximate leave-future-out cross-validation for Bayesian time series models","text":"compute approximate 1-SAP refit observations Pareto kk estimate exceeds threshold 0.70.7. code becomes little bit involved compared exact LFO-CV. Note can compute exact 1-SAP refitting points, comes additional computational costs since refit model anyway. see final Pareto-kk-estimates mostly well threshold needed refit model times:  approximate 1-SAP ELPD remarkably similar exact 1-SAP ELPD computed , indicates algorithm compute approximate 1-SAP worked well present data model. Plotting exact approximate predictions, see approximation value deviates far exact counterpart, providing evidence good quality approximation.  can also look maximum difference average difference approximate exact ELPD calculations, also indicate ver close approximation:","code":"k_thres <- 0.7 approx_elpds_1sap <- rep(NA, N)  # initialize the process for i = L past <- 1:L oos <- L + 1 df_past <- df[past, , drop = FALSE] df_oos <- df[c(past, oos), , drop = FALSE] fit_past <- update(fit, newdata = df_past, recompile = FALSE) loglik <- log_lik(fit_past, newdata = df_oos, oos = oos) approx_elpds_1sap[L + 1] <- log_mean_exp(loglik[, oos])  # iterate over i > L i_refit <- L refits <- L ks <- NULL for (i in (L + 1):(N - 1)) {   past <- 1:i   oos <- i + 1   df_past <- df[past, , drop = FALSE]   df_oos <- df[c(past, oos), , drop = FALSE]   loglik <- log_lik(fit_past, newdata = df_oos, oos = oos)      logratio <- sum_log_ratios(loglik, (i_refit + 1):i)   psis_obj <- suppressWarnings(psis(logratio))   k <- pareto_k_values(psis_obj)   ks <- c(ks, k)   if (k > k_thres) {     # refit the model based on the first i observations     i_refit <- i     refits <- c(refits, i)     fit_past <- update(fit_past, newdata = df_past, recompile = FALSE)     loglik <- log_lik(fit_past, newdata = df_oos, oos = oos)     approx_elpds_1sap[i + 1] <- log_mean_exp(loglik[, oos])   } else {     lw <- weights(psis_obj, normalize = TRUE)[, 1]     approx_elpds_1sap[i + 1] <- log_sum_exp(lw + loglik[, oos])   } } plot_ks <- function(ks, ids, thres = 0.6) {   dat_ks <- data.frame(ks = ks, ids = ids)   ggplot(dat_ks, aes(x = ids, y = ks)) +      geom_point(aes(color = ks > thres), shape = 3, show.legend = FALSE) +      geom_hline(yintercept = thres, linetype = 2, color = \"red2\") +      scale_color_manual(values = c(\"cornflowerblue\", \"darkblue\")) +      labs(x = \"Data point\", y = \"Pareto k\") +      ylim(-0.5, 1.5) } cat(\"Using threshold \", k_thres,      \", model was refit \", length(refits),      \" times, at observations\", refits) Using threshold  0.7 , model was refit  3  times, at observations 20 45 78 plot_ks(ks, (L + 1):(N - 1)) approx_elpd_1sap <- sum(approx_elpds_1sap, na.rm = TRUE) rbind_print(   \"approx LFO\" = approx_elpd_1sap,   \"exact LFO\" = exact_elpd_1sap ) ELPD approx LFO -92.48 exact LFO  -92.48 dat_elpd <- data.frame(   approx_elpd = approx_elpds_1sap,   exact_elpd = exact_elpds_1sap )  ggplot(dat_elpd, aes(x = approx_elpd, y = exact_elpd)) +   geom_abline(color = \"gray30\") +   geom_point(size = 2) +   labs(x = \"Approximate ELPDs\", y = \"Exact ELPDs\") max_diff <- with(dat_elpd, max(abs(approx_elpd - exact_elpd), na.rm = TRUE)) mean_diff <- with(dat_elpd, mean(abs(approx_elpd - exact_elpd), na.rm = TRUE))  rbind_print(   \"Max diff\" = round(max_diff, 2),    \"Mean diff\" =  round(mean_diff, 3) ) [,1] Max diff  0.09 Mean diff 0.01"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-lfo.html","id":"m-step-ahead-predictions-leaving-out-all-future-values","dir":"Articles","previous_headings":"","what":"MM-step-ahead predictions leaving out all future values","title":"Approximate leave-future-out cross-validation for Bayesian time series models","text":"illustrate application MM-SAP M>1M > 1, next compute exact approximate LFO-CV 4-SAP case.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-lfo.html","id":"exact-m-step-ahead-predictions","dir":"Articles","previous_headings":"MM-step-ahead predictions leaving out all future values","what":"Exact MM-step-ahead predictions","title":"Approximate leave-future-out cross-validation for Bayesian time series models","text":"necessary steps 1-SAP exception log-density values interest now sums log predictive densities four consecutive observations. , stability PSIS approximation actually stays MM depends number observations leave , number observations predict.","code":"M <- 4 loglikm <- matrix(nrow = ndraws(fit), ncol = N) for (i in L:(N - M)) {   past <- 1:i   oos <- (i + 1):(i + M)   df_past <- df[past, , drop = FALSE]   df_oos <- df[c(past, oos), , drop = FALSE]   fit_past <- update(fit, newdata = df_past, recompile = FALSE)   loglik <- log_lik(fit_past, newdata = df_oos, oos = oos)   loglikm[, i + 1] <- rowSums(loglik[, oos]) } exact_elpds_4sap <- apply(loglikm, 2, log_mean_exp) (exact_elpd_4sap <- c(ELPD = sum(exact_elpds_4sap, na.rm = TRUE))) ELPD  -405.0813"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-lfo.html","id":"approximate-m-step-ahead-predictions","dir":"Articles","previous_headings":"MM-step-ahead predictions leaving out all future values","what":"Approximate MM-step-ahead predictions","title":"Approximate leave-future-out cross-validation for Bayesian time series models","text":"Computing approximate PSIS-LFO-CV 4-SAP case little bit involved approximate version 1-SAP case, although underlying principles remain . , see final Pareto-kk-estimates mostly well threshold needed refit model times:  approximate ELPD computed 4-SAP case close exact counterpart 1-SAP case. general, larger MM, larger variation approximate ELPD around exact ELPD. turns ELPD estimates AR-models M>1M>1 show particular variation due predictions’ dependency predicted values. Bürkner et al. (2020) provide explanation simulations cases. Plotting exact approximate pointwise predictions confirms , specific data points, approximate predictions underestimate exact predictions.","code":"approx_elpds_4sap <- rep(NA, N)  # initialize the process for i = L past <- 1:L oos <- (L + 1):(L + M) df_past <- df[past, , drop = FALSE] df_oos <- df[c(past, oos), , drop = FALSE] fit_past <- update(fit, newdata = df_past, recompile = FALSE) loglik <- log_lik(fit_past, newdata = df_oos, oos = oos) loglikm <- rowSums(loglik[, oos]) approx_elpds_4sap[L + 1] <- log_mean_exp(loglikm)  # iterate over i > L i_refit <- L refits <- L ks <- NULL for (i in (L + 1):(N - M)) {   past <- 1:i   oos <- (i + 1):(i + M)   df_past <- df[past, , drop = FALSE]   df_oos <- df[c(past, oos), , drop = FALSE]   loglik <- log_lik(fit_past, newdata = df_oos, oos = oos)      logratio <- sum_log_ratios(loglik, (i_refit + 1):i)   psis_obj <- suppressWarnings(psis(logratio))   k <- pareto_k_values(psis_obj)   ks <- c(ks, k)   if (k > k_thres) {     # refit the model based on the first i observations     i_refit <- i     refits <- c(refits, i)     fit_past <- update(fit_past, newdata = df_past, recompile = FALSE)     loglik <- log_lik(fit_past, newdata = df_oos, oos = oos)     loglikm <- rowSums(loglik[, oos])     approx_elpds_4sap[i + 1] <- log_mean_exp(loglikm)   } else {     lw <- weights(psis_obj, normalize = TRUE)[, 1]     loglikm <- rowSums(loglik[, oos])     approx_elpds_4sap[i + 1] <- log_sum_exp(lw + loglikm)   } } cat(\"Using threshold \", k_thres,      \", model was refit \", length(refits),      \" times, at observations\", refits) Using threshold  0.7 , model was refit  3  times, at observations 20 50 90 plot_ks(ks, (L + 1):(N - M)) approx_elpd_4sap <- sum(approx_elpds_4sap, na.rm = TRUE) rbind_print(   \"Approx LFO\" = approx_elpd_4sap,   \"Exact LFO\" = exact_elpd_4sap ) ELPD Approx LFO -405.35 Exact LFO  -405.08 dat_elpd_4sap <- data.frame(   approx_elpd = approx_elpds_4sap,   exact_elpd = exact_elpds_4sap )  ggplot(dat_elpd_4sap, aes(x = approx_elpd, y = exact_elpd)) +   geom_abline(color = \"gray30\") +   geom_point(size = 2) +   labs(x = \"Approximate ELPDs\", y = \"Exact ELPDs\")"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-lfo.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Approximate leave-future-out cross-validation for Bayesian time series models","text":"case study shown carry exact approximate leave-future-cross-validation MM-step-ahead prediction tasks. data model used example, PSIS-LFO-CV algorithm provides reasonably stable accurate results despite requiring us refit model nearly many times. details approximate LFO-CV, refer Bürkner et al. (2020).","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-lfo.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Approximate leave-future-out cross-validation for Bayesian time series models","text":"Bürkner P. C., Gabry J., & Vehtari . (2020). Approximate leave-future-cross-validation time series models. Journal Statistical Computation Simulation, 90(14):2499-2523. :/10.1080/00949655.2020.1783262. Online. arXiv preprint. Vehtari ., Gelman ., & Gabry J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing, 27(5), 1413–1432. :10.1007/s11222-016-9696-4. Online. arXiv preprint arXiv:1507.04544. Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/articles/loo2-lfo.html","id":"appendix-session-information","dir":"Articles","previous_headings":"Appendix","what":"Appendix: Session information","title":"Approximate leave-future-out cross-validation for Bayesian time series models","text":"","code":"sessionInfo() R version 4.5.1 (2025-06-13 ucrt) Platform: x86_64-w64-mingw32/x64 Running under: Windows 11 x64 (build 26100)  Matrix products: default   LAPACK version 3.12.1  locale: [1] LC_COLLATE=English_United States.utf8  [2] LC_CTYPE=English_United States.utf8    [3] LC_MONETARY=English_United States.utf8 [4] LC_NUMERIC=C                           [5] LC_TIME=English_United States.utf8      time zone: America/Los_Angeles tzcode source: internal  attached base packages: [1] stats     graphics  grDevices utils     datasets  methods   base       other attached packages: [1] ggplot2_4.0.0.9000 bayesplot_1.13.0   loo_2.8.0.9000     brms_2.22.0        [5] Rcpp_1.1.0         knitr_1.50          loaded via a namespace (and not attached):  [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.53             [4] bslib_0.9.0          QuickJSR_1.8.0       htmlwidgets_1.6.4     [7] processx_3.8.6       inline_0.3.21        lattice_0.22-7       [10] callr_3.7.6          ps_1.9.1             vctrs_0.6.5          [13] tools_4.5.1          generics_0.1.4       stats4_4.5.1         [16] curl_7.0.0           parallel_4.5.1       tibble_3.3.0         [19] pkgconfig_2.0.3      Matrix_1.7-4         checkmate_2.3.3      [22] RColorBrewer_1.1-3   S7_0.2.0             desc_1.4.3           [25] distributional_0.5.0 RcppParallel_5.1.10  lifecycle_1.0.4      [28] compiler_4.5.1       farver_2.1.2         stringr_1.5.2        [31] textshaping_1.0.3    Brobdingnag_1.2-9    codetools_0.2-20     [34] htmltools_0.5.8.1    sass_0.4.10          yaml_2.3.10          [37] pillar_1.11.1        pkgdown_2.1.3        jquerylib_0.1.4      [40] cachem_1.1.0         StanHeaders_2.32.10  bridgesampling_1.1-2 [43] abind_1.4-8          nlme_3.1-168         posterior_1.6.1      [46] rstan_2.32.7         tidyselect_1.2.1     digest_0.6.37        [49] mvtnorm_1.3-3        stringi_1.8.7        dplyr_1.1.4.9000     [52] labeling_0.4.3       fastmap_1.2.0        grid_4.5.1           [55] colorspace_2.1-1     cli_3.6.5            magrittr_2.0.4       [58] pkgbuild_1.4.8       withr_3.0.2          scales_1.4.0         [61] backports_1.5.0      rmarkdown_2.29       matrixStats_1.5.0    [64] gridExtra_2.3        ragg_1.5.0           coda_0.19-4.1        [67] evaluate_1.0.5       V8_6.0.5             rstantools_2.4.0     [70] rlang_1.1.6          glue_1.8.0           jsonlite_2.0.0       [73] R6_2.6.1             systemfonts_1.2.3    fs_1.6.6"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-lfo.html","id":"appendix-licenses","dir":"Articles","previous_headings":"Appendix","what":"Appendix: Licenses","title":"Approximate leave-future-out cross-validation for Bayesian time series models","text":"Code © 2018, Paul Bürkner, Jonah Gabry, Aki Vehtari (licensed BSD-3). Text © 2018, Paul Bürkner, Jonah Gabry, Aki Vehtari (licensed CC--NC 4.0).","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-mixis.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Mixture IS leave-one-out cross-validation for high-dimensional Bayesian models","text":"vignette shows perform Bayesian leave-one-cross-validation (LOO-CV) using mixture estimators proposed paper Silva Zanella (2022). estimators shown useful presence outliers also, especially, high-dimensional settings model features many parameters. contexts can happen large portion observations lead high values Pareto-kk diagnostics potential instability PSIS-LOO estimators. illustration consider high-dimensional Bayesian Logistic regression model applied Voice dataset.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-mixis.html","id":"setup-load-packages-and-set-seed","dir":"Articles","previous_headings":"Introduction","what":"Setup: load packages and set seed","title":"Mixture IS leave-one-out cross-validation for high-dimensional Bayesian models","text":"","code":"library(\"rstan\") library(\"loo\") library(\"matrixStats\") options(mc.cores = parallel::detectCores(), parallel=FALSE) set.seed(24877)"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-mixis.html","id":"model","dir":"Articles","previous_headings":"Introduction","what":"Model","title":"Mixture IS leave-one-out cross-validation for high-dimensional Bayesian models","text":"Stan code logistic regression model regularized horseshoe prior. code includes statement include code line needed later MixIS approach.","code":"# Note: some syntax used in this program requires RStan >= 2.26 (or CmdStanR) # To use an older version of RStan change the line declaring `y` to: #    int<lower=0,upper=1> y[N]; stancode_horseshoe <- \" data {   int <lower=0> N;   int <lower=0> P;   array[N] int <lower=0, upper=1> y;   matrix [N,P] X;   real <lower=0> scale_global;   int <lower=0,upper=1> mixis; } transformed data {   real<lower=1> nu_global=1; // degrees of freedom for the half-t priors for tau   real<lower=1> nu_local=1;  // degrees of freedom for the half-t priors for lambdas                              // (nu_local = 1 corresponds to the horseshoe)   real<lower=0> slab_scale=2;// for the regularized horseshoe   real<lower=0> slab_df=100; // for the regularized horseshoe } parameters {   vector[P] z;                // for non-centered parameterization   real <lower=0> tau;         // global shrinkage parameter   vector <lower=0>[P] lambda; // local shrinkage parameter   real<lower=0> caux; } transformed parameters {   vector[P] beta;   {      vector[P] lambda_tilde;   // 'truncated' local shrinkage parameter     real c = slab_scale * sqrt(caux); // slab scale     lambda_tilde = sqrt( c^2 * square(lambda) ./ (c^2 + tau^2*square(lambda)));     beta = z .* lambda_tilde*tau;   } } model {   vector[N] means=X*beta;   vector[N] log_lik;   target += std_normal_lpdf(z);   target += student_t_lpdf(lambda | nu_local, 0, 1);   target += student_t_lpdf(tau | nu_global, 0, scale_global);   target += inv_gamma_lpdf(caux | 0.5*slab_df, 0.5*slab_df);   for (n in 1:N) {     log_lik[n]= bernoulli_logit_lpmf(y[n] | means[n]);   }   target += sum(log_lik);   if (mixis) {     target += log_sum_exp(-log_lik);   } } generated quantities {   vector[N] means=X*beta;   vector[N] log_lik;   for (n in 1:N) {     log_lik[n] = bernoulli_logit_lpmf(y[n] | means[n]);   } } \""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-mixis.html","id":"dataset","dir":"Articles","previous_headings":"Introduction","what":"Dataset","title":"Mixture IS leave-one-out cross-validation for high-dimensional Bayesian models","text":"LSVT Voice Rehabilitation Data Set (see link details) p=312p=312 covariates n=126n=126 observations binary response. construct data list Stan. Note prior specification divide prior variance number covariates pp. often done high-dimensional contexts prior variance linear predictors XβX\\beta remains bounded pp increases.","code":"data(voice) y <- voice$y X <- voice[2:length(voice)] n <- dim(X)[1] p <- dim(X)[2] p0 <- 10 scale_global <- 2*p0/(p-p0)/sqrt(n-1) standata <- list(N = n, P = p, X = as.matrix(X), y = c(y), scale_global = scale_global, mixis = 0)"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-mixis.html","id":"psis-estimators-and-pareto-k-diagnostics","dir":"Articles","previous_headings":"Introduction","what":"PSIS estimators and Pareto-kk diagnostics","title":"Mixture IS leave-one-out cross-validation for high-dimensional Bayesian models","text":"LOO-CV computations challenging context due high-dimensionality parameter space. show , compute PSIS-LOO estimators, require sampling posterior distribution, inspect associated Pareto-kk diagnostics. can see diagnostics signal either “bad” “bad” Pareto-kk values roughly 15−30%15-30\\% observations significant portion dataset.","code":"chains <- 4 n_iter <- 2000 warm_iter <- 1000 stanmodel <- stan_model(model_code = stancode_horseshoe) WARNING: Rtools is required to build R packages, but is not currently installed.  Please download and install the appropriate version of Rtools for 4.5.1 from https://cran.r-project.org/bin/windows/Rtools/. Trying to compile a simple C file WARNING: Rtools is required to build R packages, but is not currently installed.  Please download and install the appropriate version of Rtools for 4.5.1 from https://cran.r-project.org/bin/windows/Rtools/. fit_post <- sampling(stanmodel, data = standata, chains = chains, iter = n_iter, warmup = warm_iter, refresh = 0) loo_post <-loo(fit_post) print(loo_post) Computed from 4000 by 126 log-likelihood matrix.           Estimate   SE elpd_loo    -42.2  6.9 p_loo        23.8  5.0 looic        84.4 13.9 ------ MCSE of elpd_loo is NA. MCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 1.0]).  Pareto k diagnostic values:                          Count Pct.    Min. ESS (-Inf, 0.7]   (good)     96    76.2%   204         (0.7, 1]   (bad)      21    16.7%   <NA>        (1, Inf)   (very bad)  9     7.1%   <NA>     See help('pareto-k-diagnostic') for details."},{"path":"https://mc-stan.org/loo/dev/articles/loo2-mixis.html","id":"mixture-estimators","dir":"Articles","previous_headings":"Introduction","what":"Mixture estimators","title":"Mixture IS leave-one-out cross-validation for high-dimensional Bayesian models","text":"now compute mixture estimators proposed Silva Zanella (2022). require sample following mixture leave-one-posteriors qmix(θ)=∑=1np(y−|θ)p(θ)∑=1np(y−)∝p(θ|y)⋅(∑=1np(yi|θ)−1).\\begin{equation} q_{mix}(\\theta) =  \\frac{\\sum_{=1}^n p(y_{-}|\\theta)p(\\theta)}{\\sum_{=1}^np(y_{-})}\\propto p(\\theta|y)\\cdot \\left(\\sum_{=1}^np(y_i|\\theta)^{-1}\\right). \\end{equation} code generate Stan model mixture distribution one posterior, just enabling one line code LogSumExp contribution account last term equation . sample mixture collect log-likelihoods term. now compute mixture estimators, following numerically stable implementation Appendix .2 Silva Zanella (2022). code makes use package “matrixStats”.","code":"if (mixis) {     target += log_sum_exp(-log_lik);   } standata$mixis <- 1 fit_mix <- sampling(stanmodel, data = standata, chains = chains, iter = n_iter, warmup = warm_iter, refresh = 0, pars = \"log_lik\") log_lik_mix <- extract(fit_mix)$log_lik l_common_mix <- rowLogSumExps(-log_lik_mix) log_weights <- -log_lik_mix - l_common_mix elpd_mixis <- logSumExp(-l_common_mix) - rowLogSumExps(t(log_weights))"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-mixis.html","id":"comparison-with-benchmark-values-obtained-with-long-simulations","dir":"Articles","previous_headings":"Introduction","what":"Comparison with benchmark values obtained with long simulations","title":"Mixture IS leave-one-out cross-validation for high-dimensional Bayesian models","text":"evaluate performance mixture estimators (MixIS) also generate benchmark values, .e. accurate approximations LOO predictives {p(yi|y−)}=1,…,n\\{p(y_i|y_{-})\\}_{=1,\\dots,n}, obtained brute-force sampling leave-one-posteriors directly, getting 90k90k samples discarding first 10k10k warmup. computationally heavy, hence saved results just load current vignette. can compute root mean squared error (RMSE) PSIS mixture estimators relative benchmark values. mixture estimator provides reduction RMSE. Note value increase number samples drawn posterior mixture, since example RMSE MixIS exhibit CLT-type decay one PSIS converge slower rate (can verified running code larger sample size; see also Figure 3 Silva Zanella (2022) analogous results). compare overall ELPD estimates brute force one. example, MixIS provides accurate ELPD estimate closer brute force estimate, PSIS severely overestimates ELPD. Note low accuracy PSIS ELPD estimate expected example given large number large Pareto-kk values. example, accuracy MixIS estimate also improve bigger MCMC sample size. generally, mixture estimators can useful situations standard PSIS estimators struggle return many large Pareto-kk values. contexts MixIS often provides accurate LOO-CV ELPD estimates single sampling routine (.e. cost comparable sampling original posterior).","code":"data(voice_loo) elpd_loo <- voice_loo$elpd_loo elpd_psis <- loo_post$pointwise[,1] print(paste(\"RMSE(PSIS) =\",round( sqrt(mean((elpd_loo-elpd_psis)^2)) ,2))) [1] \"RMSE(PSIS) = 0.09\" print(paste(\"RMSE(MixIS) =\",round( sqrt(mean((elpd_loo-elpd_mixis)^2)) ,2))) [1] \"RMSE(MixIS) = 0.04\" elpd_psis <- loo_post$pointwise[,1] print(paste(\"ELPD (PSIS)=\",round(sum(elpd_psis),2))) [1] \"ELPD (PSIS)= -42.21\" print(paste(\"ELPD (MixIS)=\",round(sum(elpd_mixis),2))) [1] \"ELPD (MixIS)= -45.02\" print(paste(\"ELPD (brute force)=\",round(sum(elpd_loo),2))) [1] \"ELPD (brute force)= -45.63\""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-mixis.html","id":"references","dir":"Articles","previous_headings":"Introduction","what":"References","title":"Mixture IS leave-one-out cross-validation for high-dimensional Bayesian models","text":"Silva L. Zanella G. (2022). Robust leave-one-cross-validation high-dimensional Bayesian models. Preprint arXiv:2209.09190 Vehtari ., Gelman ., Gabry J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing, 27(5), 1413–1432. Preprint arXiv:1507.04544 Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-moment-matching.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Avoiding model refits in leave-one-out cross-validation with moment matching","text":"vignette demonstrates improve Monte Carlo sampling accuracy leave-one-cross-validation loo package Stan. loo package automatically monitors sampling accuracy using Pareto kk diagnostics observation. , present method quickly improving accuracy Pareto diagnostics indicate problems. done performing additional computations using existing posterior sample. successful, decrease Pareto kk values, making model assessment reliable. loo also stores original Pareto kk values name influence_pareto_k changed. can used diagnostic much observation influences posterior distribution. methodology presented based paper Paananen, T., Piironen, J., Buerkner, P.-C., Vehtari, . (2020). Implicitly Adaptive Importance Sampling. arXiv preprint arXiv:1906.08850. information Pareto kk diagnostics given following papers Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. :10.1007/s11222-016-9696-4. Links: published | arXiv preprint. Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-moment-matching.html","id":"example-eradication-of-roaches","dir":"Articles","previous_headings":"","what":"Example: Eradication of Roaches","title":"Avoiding model refits in leave-one-out cross-validation with moment matching","text":"use example vignette Using loo package (version >= 2.0.0). See demo description problem data. use Poisson regression model case study.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-moment-matching.html","id":"coding-the-stan-model","dir":"Articles","previous_headings":"Example: Eradication of Roaches","what":"Coding the Stan model","title":"Avoiding model refits in leave-one-out cross-validation with moment matching","text":"Stan code fitting Poisson regression model, use modeling number roaches. Following usual approach recommended Writing Stan programs use loo package, compute log-likelihood observation generated quantities block Stan program.","code":"# Note: some syntax used in this Stan program requires RStan >= 2.26 (or CmdStanR) # To use an older version of RStan change the line declaring `y` to: int y[N]; stancode <- \" data {   int<lower=1> K;   int<lower=1> N;   matrix[N,K] x;   array[N] int y;   vector[N] offset;    real beta_prior_scale;   real alpha_prior_scale; } parameters {   vector[K] beta;   real intercept; } model {   y ~ poisson(exp(x * beta + intercept + offset));   beta ~ normal(0,beta_prior_scale);   intercept ~ normal(0,alpha_prior_scale); } generated quantities {   vector[N] log_lik;   for (n in 1:N)     log_lik[n] = poisson_lpmf(y[n] | exp(x[n] * beta + intercept + offset[n])); } \""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-moment-matching.html","id":"setup","dir":"Articles","previous_headings":"Example: Eradication of Roaches","what":"Setup","title":"Avoiding model refits in leave-one-out cross-validation with moment matching","text":"addition loo, load rstan package fitting model, rstanarm package data.","code":"library(\"rstan\") library(\"loo\") seed <- 9547 set.seed(seed)"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-moment-matching.html","id":"fitting-the-model-with-rstan","dir":"Articles","previous_headings":"Example: Eradication of Roaches","what":"Fitting the model with RStan","title":"Avoiding model refits in leave-one-out cross-validation with moment matching","text":"Next fit model Stan using rstan package: Let us now evaluate predictive performance model using loo(). loo() function output warnings observations highly influential, thus accuracy importance sampling compromised indicated large Pareto kk diagnostic values (> 0.7). discussed vignette Using loo package (version >= 2.0.0), may indication model misspecification. Despite , still beneficial able evaluate predictive performance model accurately.","code":"# Prepare data data(roaches, package = \"rstanarm\") roaches$roach1 <- sqrt(roaches$roach1) y <- roaches$y x <- roaches[, c(\"roach1\", \"treatment\", \"senior\")] offset <- log(roaches[, \"exposure2\"]) n <- dim(x)[1] k <- dim(x)[2]  standata <- list(   N = n,   K = k,   x = as.matrix(x),   y = y,   offset = offset,   beta_prior_scale = 2.5,   alpha_prior_scale = 5.0 )  # Compile stanmodel <- stan_model(model_code = stancode)  # Fit model fit <- sampling(stanmodel, data = standata, seed = seed, refresh = 0) print(fit, pars = \"beta\") loo1 <- loo(fit) loo1"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-moment-matching.html","id":"moment-matching-correction-for-importance-sampling","dir":"Articles","previous_headings":"Example: Eradication of Roaches","what":"Moment matching correction for importance sampling","title":"Avoiding model refits in leave-one-out cross-validation with moment matching","text":"improve accuracy loo() result , perform leave-one-cross-validation explicitly leaving single observations refitting model using MCMC repeatedly. However, Pareto kk diagnostics indicate 19 observations problematic. require 19 model refits may require lot computation time. Instead refitting MCMC, can perform faster moment matching correction importance sampling problematic observations. can done loo_moment_match() function loo package, takes existing loo object input modifies . moment matching requires evaluations model posterior density. models fitted rstan, can conveniently done using existing stanfit object. First, show moment matching can used model fitted using rstan. requires setting argument moment_match TRUE loo() function. Optionally, can also set argument k_threshold determines Pareto kk threshold, moment matching used. default, operates observations whose Pareto kk value larger sample size (SS) specific threshold min(1−1/log10(S),0.7)\\min(1 - 1 / \\log_{10}(S), 0.7) (0.70.7 S>2200S>2200). moment matching, observations diagnostic Pareto kk less 0.7, meaning estimates now reliable. total elpd_loo estimate also changed -5457.8 -5478.5, showing moment matching, loo() overestimated predictive performance model. updated Pareto kk values stored loo2$diagnostics$pareto_k considered algorithmic diagnostic values indicate sampling accuracy. original Pareto kk values stored loo2$pointwise[,\"influence_pareto_k\"] modified moment matching. can considered diagnostics big influence observation posterior distribution. addition Pareto kk diagnostics, moment matching also updates effective sample size estimates.","code":"# available in rstan >= 2.21 loo2 <- loo(fit, moment_match = TRUE) loo2"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-moment-matching.html","id":"using-loo_moment_match-directly","dir":"Articles","previous_headings":"","what":"Using loo_moment_match() directly","title":"Avoiding model refits in leave-one-out cross-validation with moment matching","text":"moment matching can also performed explicitly calling function loo_moment_match(). enables use also models using rstan another package built-support loo_moment_match(). use loo_moment_match(), user must give model object x, loo object, 5 helper functions arguments loo_moment_match(). helper functions function takes x first argument returns matrix posterior draws model parameters, pars. function takes x returns matrix (one column per chain) vector (chains stacked) log-likeliood draws ith observation based model x. draws obtained using MCMC, matrix MCMC chains separated preferred. function takes arguments x pars, returns posterior draws unconstrained space based posterior draws constrained space passed via pars. function takes arguments x upars, returns matrix log-posterior density values unconstrained posterior draws passed via upars. function takes arguments x, upars, returns vector log-likelihood draws ith observation based unconstrained posterior draws passed via upars. Next, show helper functions look like RStan objects, show example using loo_moment_match() directly. stanfit objects rstan objects, functions look like : Using function, can call loo_moment_match() update existing loo object. expected, result identical previous result loo2 <- loo(fit, moment_match = TRUE).","code":"# create a named list of draws for use with rstan methods .rstan_relist <- function(x, skeleton) {   out <- utils::relist(x, skeleton)   for (i in seq_along(skeleton)) {     dim(out[[i]]) <- dim(skeleton[[i]])   }   out }  # rstan helper function to get dims of parameters right .create_skeleton <- function(pars, dims) {   out <- lapply(seq_along(pars), function(i) {     len_dims <- length(dims[[i]])     if (len_dims < 1) {       return(0)     }     return(array(0, dim = dims[[i]]))   })   names(out) <- pars   out }  # extract original posterior draws post_draws_stanfit <- function(x, ...) {   as.matrix(x) }  # compute a matrix of log-likelihood values for the ith observation # matrix contains information about the number of MCMC chains log_lik_i_stanfit <- function(x, i, parameter_name = \"log_lik\", ...) {   loo::extract_log_lik(x, parameter_name, merge_chains = FALSE)[,, i] }  # transform parameters to the unconstraint space unconstrain_pars_stanfit <- function(x, pars, ...) {   skeleton <- .create_skeleton(x@sim$pars_oi, x@par_dims[x@sim$pars_oi])   upars <- apply(pars, 1, FUN = function(theta) {     rstan::unconstrain_pars(x, .rstan_relist(theta, skeleton))   })   # for one parameter models   if (is.null(dim(upars))) {     dim(upars) <- c(1, length(upars))   }   t(upars) }  # compute log_prob for each posterior draws on the unconstrained space log_prob_upars_stanfit <- function(x, upars, ...) {   apply(     upars,     1,     rstan::log_prob,     object = x,     adjust_transform = TRUE,     gradient = FALSE   ) }  # compute log_lik values based on the unconstrained parameters log_lik_i_upars_stanfit <- function(   x,   upars,   i,   parameter_name = \"log_lik\",   ... ) {   S <- nrow(upars)   out <- numeric(S)   for (s in seq_len(S)) {     out[s] <- rstan::constrain_pars(x, upars = upars[s, ])[[parameter_name]][i]   }   out } loo3 <- loo::loo_moment_match.default(   x = fit,   loo = loo1,   post_draws = post_draws_stanfit,   log_lik_i = log_lik_i_stanfit,   unconstrain_pars = unconstrain_pars_stanfit,   log_prob_upars = log_prob_upars_stanfit,   log_lik_i_upars = log_lik_i_upars_stanfit ) loo3"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-moment-matching.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Avoiding model refits in leave-one-out cross-validation with moment matching","text":"Gelman, ., Hill, J. (2007). Data Analysis Using Regression Multilevel Hierarchical Models. Cambridge University Press. Stan Development Team (2020) RStan: R interface Stan, Version 2.21.1 https://mc-stan.org Paananen, T., Piironen, J., Buerkner, P.-C., Vehtari, . (2021). Implicitly adaptive importance sampling. Statistics Computing, 31, 16. :10.1007/s11222-020-09982-2. arXiv preprint arXiv:1906.08850. Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. :10.1007/s11222-016-9696-4. Links: published | arXiv preprint. Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-non-factorized.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Leave-one-out cross-validation for non-factorized models","text":"computing ELPD-based LOO-CV Bayesian model need compute log leave-one-predictive densities logp(yi|y−)\\log{p(y_i | y_{-})} every response value yi,=1,…,Ny_i, \\: = 1, \\ldots, N, y−iy_{-} denotes response values except observation ii. obtain p(yi|y−)p(y_i | y_{-}), need access pointwise likelihood p(yi|y−,θ)p(y_i\\,|\\, y_{-}, \\theta) integrate model parameters θ\\theta: p(yi|y−)=∫p(yi|y−,θ)p(θ|y−)dθ p(y_i\\,|\\,y_{-}) =   \\int p(y_i\\,|\\, y_{-}, \\theta) \\, p(\\theta\\,|\\, y_{-}) \\,d \\theta , p(θ|y−)p(\\theta\\,|\\, y_{-}) leave-one-posterior distribution θ\\theta, , posterior distribution θ\\theta obtained fitting model holding iith observation (later show refitting model data y−iy_{-} can avoided). observation model formulated directly product pointwise observation models, call factorized model. case, likelihood also product pointwise likelihood contributions p(yi|y−,θ)p(y_i\\,|\\, y_{-}, \\theta). better illustrate possible structures observation models, formally divide θ\\theta two parts, observation-specific latent variables f=(f1,…,fN)f = (f_1, \\ldots, f_N) hyperparameters ψ\\psi, p(yi|y−,θ)=p(yi|y−,fi,ψ)p(y_i\\,|\\, y_{-}, \\theta) = p(y_i\\,|\\, y_{-}, f_i, \\psi). Depending model, one two parts θ\\theta may also empty. simple models, linear regression models, latent variables explicitly presented response values conditionally independent given ψ\\psi, p(yi|y−,fi,ψ)=p(yi|ψ)p(y_i\\,|\\, y_{-}, f_i, \\psi) = p(y_i \\,|\\, \\psi). full likelihood can written familiar form p(y|ψ)=∏=1Np(yi|ψ), p(y \\,|\\, \\psi) = \\prod_{=1}^N p(y_i \\,|\\, \\psi), y=(y1,…,yN)y = (y_1, \\ldots, y_N) denotes vector responses. likelihood factorizes way, conditional pointwise log-likelihood can obtained easily computing p(yi|ψ)p(y_i\\,|\\, \\psi) ii computational cost O(n)O(n). Yet, several reasons non-factorized observation model may necessary preferred. non-factorized models, joint likelihood response values p(y|θ)p(y \\,|\\, \\theta) factorized observation-specific components, rather given directly one joint expression. models, analytic factorized formulation simply available case speak non-factorizable model. Even models whose observation model can factorized principle, may still preferable use non-factorized form reasons efficiency numerical stability (Bürkner et al. 2020). Whether non-factorized model used necessity efficiency stability, comes cost direct access leave-one-predictive densities thus overall leave-one-predictive accuracy. theory, can express observation-specific likelihoods terms joint likelihood via p(yi|yi−1,θ)=p(y|θ)p(y−|θ)=p(y|θ)∫p(y|θ)dyi, p(y_i \\,|\\, y_{-1}, \\theta) =    \\frac{p(y \\,|\\, \\theta)}{p(y_{-} \\,|\\, \\theta)} =    \\frac{p(y \\,|\\, \\theta)}{\\int p(y \\,|\\, \\theta) \\, d y_i}, expression right-hand side may always analytical solution. Computing logp(yi|y−,θ)\\log p(y_i \\,|\\, y_{-}, \\theta) non-factorized models therefore often impossible, least inefficient numerically unstable. However, large class multivariate normal Student-tt models efficient analytical solutions available. details can found paper LOO-CV non-factorized models (Bürkner, Gabry, & Vehtari, 2020), available preprint arXiv (https://arxiv.org/abs/1810.10559).","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-non-factorized.html","id":"loo-cv-for-multivariate-normal-models","dir":"Articles","previous_headings":"","what":"LOO-CV for multivariate normal models","title":"Leave-one-out cross-validation for non-factorized models","text":"vignette, focus non-factorized multivariate normal models. Based results Sundararajan Keerthi (2001), Bürkner et al. (2020) show , multivariate normal models coriance matrix CC, LOO predictive mean standard deviation can computed follows: μỹ,−=yi−c‾ii−1giσỹ,−=c‾ii−1,\\begin{align}   \\mu_{\\tilde{y},-} &= y_i-\\bar{c}_{ii}^{-1} g_i \\nonumber \\\\   \\sigma_{\\tilde{y},-} &= \\sqrt{\\bar{c}_{ii}^{-1}}, \\end{align} gig_i c‾ii\\bar{c}_{ii} gi=[C−1y]ic‾ii=[C−1]ii.\\begin{align}   g_i &= \\left[C^{-1} y\\right]_i \\nonumber \\\\   \\bar{c}_{ii} &= \\left[C^{-1}\\right]_{ii}. \\end{align} Using results, log predictive density iith observation computed logp(yi|y−,θ)=−12log(2π)−12logσ−i2−12(yi−μ−)2σ−i2.   \\log p(y_i \\,|\\, y_{-},\\theta)   = - \\frac{1}{2}\\log(2\\pi)   - \\frac{1}{2}\\log \\sigma^2_{-}   - \\frac{1}{2}\\frac{(y_i-\\mu_{-})^2}{\\sigma^2_{-}}. Expressing equation terms gig_i c‾ii\\bar{c}_{ii}, log predictive density becomes: logp(yi|y−,θ)=−12log(2π)+12logc‾ii−12gi2c‾ii.   \\log p(y_i \\,|\\, y_{-},\\theta)   = - \\frac{1}{2}\\log(2\\pi)   + \\frac{1}{2}\\log \\bar{c}_{ii}   - \\frac{1}{2}\\frac{g_i^2}{\\bar{c}_{ii}}.  (Note Vehtari et al. (2016) typo corresponding Equation 34.) equations can now derive recipe obtaining conditional pointwise log-likelihood models can expressed conditionally terms multivariate normal invertible covariance matrix CC.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-non-factorized.html","id":"approximate-loo-cv-using-integrated-importance-sampling","dir":"Articles","previous_headings":"LOO-CV for multivariate normal models","what":"Approximate LOO-CV using integrated importance-sampling","title":"Leave-one-out cross-validation for non-factorized models","text":"LOO equations multivariate normal models conditional parameters θ\\theta. Therefore, obtain leave-one-predictive density p(yi|y−)p(y_i \\,|\\, y_{-}) need integrate θ\\theta, p(yi|y−)=∫p(yi|y−,θ)p(θ|y−)dθ. p(y_i\\,|\\,y_{-}) =   \\int p(y_i\\,|\\,y_{-}, \\theta) \\, p(\\theta\\,|\\,y_{-}) \\,d\\theta. , p(θ|y−)p(\\theta\\,|\\,y_{-}) leave-one-posterior distribution θ\\theta, , posterior distribution θ\\theta obtained fitting model holding iith observation. avoid cost sampling NN leave-one-posteriors, possible take posterior draws θ(s),s=1,…,S\\theta^{(s)}, \\, s=1,\\ldots,S, posterior p(θ|y)p(\\theta\\,|\\,y), approximate integral using integrated importance sampling (Vehtari et al., 2016, Section 3.6.1): p(yi|y−)≈∑s=1Sp(yi|y−,θ(s))wi(s)∑s=1Swi(s),  p(y_i\\,|\\,y_{-}) \\approx    \\frac{ \\sum_{s=1}^S p(y_i\\,|\\,y_{-},\\,\\theta^{(s)}) \\,w_i^{(s)}}{ \\sum_{s=1}^S w_i^{(s)}}, wi(s)w_i^{(s)} importance weights. First compute raw importance ratios ri(s)∝1p(yi|y−,θ(s)),   r_i^{(s)} \\propto \\frac{1}{p(y_i \\,|\\, y_{-}, \\,\\theta^{(s)})}, stabilize using Pareto smoothed importance sampling (PSIS, Vehtari et al, 2019) obtain weights wi(s)w_i^{(s)}. resulting approximation referred PSIS-LOO (Vehtari et al, 2017).","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-non-factorized.html","id":"exact-loo-cv-with-re-fitting","dir":"Articles","previous_headings":"LOO-CV for multivariate normal models","what":"Exact LOO-CV with re-fitting","title":"Leave-one-out cross-validation for non-factorized models","text":"order validate approximate LOO procedure, also order allow exact computations made small number leave-one-folds Pareto kk diagnostic (Vehtari et al, 2024) indicates unstable approximation, need consider might exact leave-one-CV non-factorized model. case Gaussian process marginalization property, just drop one row column CC corresponding held observation. hold general multivariate normal models, however, keep original prior may need maintain full covariance matrix CC even one observations left . solution model yiy_i missing observation estimate along model parameters. conditional multivariate normal model, logp(yi|y−)\\log p(y_i\\,|\\,y_{-}) can computed follows. First, model yiy_i missing denote corresponding parameter yimisy_i^{\\mathrm{mis}}. , define ymis()=(y1,…,yi−1,yimis,yi+1,…,yN). y_{\\mathrm{mis}()} = (y_1, \\ldots, y_{-1}, y_i^{\\mathrm{mis}}, y_{+1}, \\ldots, y_N).  full set observations yy, except replacing yiy_i parameter yimisy_i^{\\mathrm{mis}}. Second, compute LOO predictive mean standard deviations , replace yy ymis()y_{\\mathrm{mis}()} computation μỹ,−\\mu_{\\tilde{y},-}: μỹ,−=ymis()−c‾ii−1gi, \\mu_{\\tilde{y},-} = y_{{\\mathrm{mis}}()}-\\bar{c}_{ii}^{-1}g_i, case gi=[C−1ymis()]. g_i = \\left[ C^{-1} y_{\\mathrm{mis}()} \\right]_i. conditional log predictive density computed μỹ,−\\mu_{\\tilde{y},-} left observation yiy_i: logp(yi|y−,θ)=−12log(2π)−12logσỹ,−i2−12(yi−μỹ,−)2σỹ,−i2.   \\log p(y_i\\,|\\,y_{-},\\theta)   = - \\frac{1}{2}\\log(2\\pi)   - \\frac{1}{2}\\log \\sigma^2_{\\tilde{y},-}   - \\frac{1}{2}\\frac{(y_i-\\mu_{\\tilde{y},-})^2}{\\sigma^2_{\\tilde{y},-}}. Finally, leave-one-predictive distribution can estimated p(yi|y−)≈∑s=1Sp(yi|y−,θ−(s)),  p(y_i\\,|\\,y_{-}) \\approx \\sum_{s=1}^S p(y_i\\,|\\,y_{-}, \\theta_{-}^{(s)}), θ−(s)\\theta_{-}^{(s)} draws posterior distribution p(θ|ymis())p(\\theta\\,|\\,y_{\\mathrm{mis}()}).","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-non-factorized.html","id":"lagged-sar-models","dir":"Articles","previous_headings":"","what":"Lagged SAR models","title":"Leave-one-out cross-validation for non-factorized models","text":"common non-factorized multivariate normal model simultaneously autoregressive (SAR) model, frequently used spatially correlated data. lagged SAR model defined y=ρWy+η+ϵ y = \\rho Wy + \\eta + \\epsilon  equivalently (−ρW)y=η+ϵ, (- \\rho W)y = \\eta + \\epsilon,  ρ\\rho spatial correlation parameter WW user-defined weight matrix. matrix WW entries wii=0w_{ii} = 0 along diagonal -diagonal entries wijw_{ij} larger areas ii jj closer . linear model, predictor term η\\eta given η=Xβ\\eta = X \\beta design matrix XX regression coefficients β\\beta. However, since equation holds arbitrary η\\eta, results restricted linear models. ϵ∼N(0,σ2I)\\epsilon \\sim {\\mathrm N}(0, \\,\\sigma^2 ), follows (−ρW)y∼N(η,σ2I), (- \\rho W)y \\sim {\\mathrm N}(\\eta, \\sigma^2 ),  corresponds following log PDF coded Stan: purpose computing LOO-CV, makes sense rewrite SAR model slightly different form. Conditional ρ\\rho, η\\eta, σ\\sigma, write y−(−ρW)−1η∼N(0,σ2(−ρW)−1(−ρW)−T),\\begin{align} y-(-\\rho W)^{-1}\\eta &\\sim {\\mathrm N}(0, \\sigma^2(-\\rho W)^{-1}(-\\rho W)^{-T}), \\end{align} compactly, W̃=(−ρW)\\widetilde{W}=(-\\rho W), y−W̃−1η∼N(0,σ2(W̃TW̃)−1),\\begin{align} y-\\widetilde{W}^{-1}\\eta &\\sim {\\mathrm N}(0, \\sigma^2(\\widetilde{W}^{T}\\widetilde{W})^{-1}), \\end{align} form zero mean Gaussian process . Accordingly, can compute leave-one-predictive densities equations Sundararajan Keerthi (2001), replacing yy (y−W̃−1η)(y-\\widetilde{W}^{-1}\\eta) taking covariance matrix CC σ2(W̃TW̃)−1\\sigma^2(\\widetilde{W}^{T}\\widetilde{W})^{-1}.","code":"/**   * Normal log-pdf for spatially lagged responses  *   * @param y Vector of response values.  * @param mu Mean parameter vector.  * @param sigma Positive scalar residual standard deviation.  * @param rho Positive scalar autoregressive parameter.  * @param W Spatial weight matrix.  *  * @return A scalar to be added to the log posterior.  */ real normal_lagsar_lpdf(vector y, vector mu, real sigma,                          real rho, matrix W) {   int N = rows(y);   real inv_sigma2 = 1 / square(sigma);   matrix[N, N] W_tilde = -rho * W;   vector[N] half_pred;      for (n in 1:N) W_tilde[n,n] += 1;      half_pred = W_tilde * (y - mdivide_left(W_tilde, mu));      return 0.5 * log_determinant(crossprod(W_tilde) * inv_sigma2) -          0.5 * dot_self(half_pred) * inv_sigma2; }"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-non-factorized.html","id":"case-study-neighborhood-crime-in-columbus-ohio","dir":"Articles","previous_headings":"Lagged SAR models","what":"Case Study: Neighborhood Crime in Columbus, Ohio","title":"Leave-one-out cross-validation for non-factorized models","text":"order demonstrate carry computations implied equations, first fit lagged SAR model data crime 49 different neighborhoods Columbus, Ohio year 1980. data originally described Aneslin (1988) ships spdep R package. addition loo package, analysis use brms interface Stan generate Stan program fit model, also bayesplot ggplot2 packages plotting. three variables data set relevant example : CRIME: number residential burglaries vehicle thefts per thousand households neighbood HOVAL: housing value units $1000 USD INC: household income units $1000 USD also use object COL.nb, list containing information neighborhoods border . list able construct weight matrix used help account spatial dependency among observations.","code":"library(\"loo\") library(\"brms\") library(\"bayesplot\") library(\"ggplot2\") color_scheme_set(\"brightblue\") theme_set(theme_default())   SEED <- 10001  set.seed(SEED) # only sets seed for R (seed for Stan set later)  # loads COL.OLD data frame and COL.nb neighbor list data(oldcol, package = \"spdep\") str(COL.OLD[, c(\"CRIME\", \"HOVAL\", \"INC\")]) 'data.frame':   49 obs. of  3 variables:  $ CRIME: num  18.802 32.388 38.426 0.178 15.726 ...  $ HOVAL: num  44.6 33.2 37.1 75 80.5 ...  $ INC  : num  21.23 4.48 11.34 8.44 19.53 ..."},{"path":"https://mc-stan.org/loo/dev/articles/loo2-non-factorized.html","id":"fit-lagged-sar-model","dir":"Articles","previous_headings":"Lagged SAR models > Case Study: Neighborhood Crime in Columbus, Ohio","what":"Fit lagged SAR model","title":"Leave-one-out cross-validation for non-factorized models","text":"model predicting CRIME INC HOVAL, accounting spatial dependency via SAR structure, can specified brms follows. code fits model Stan using log PDF equivalent normal_lagsar_lpdf function defined . summary output see higher income higher housing value predict lower crime rates neighborhood. Moreover, seems substantial spatial correlation adjacent neighborhoods, indicated posterior distribution lagsar parameter.","code":"fit <- brm(   CRIME ~ INC + HOVAL + sar(COL.nb, type = \"lag\"),    data = COL.OLD,   data2 = list(COL.nb = COL.nb),   chains = 4,   seed = SEED ) lagsar <- as.matrix(fit, pars = \"lagsar\") estimates <- quantile(lagsar, probs = c(0.25, 0.5, 0.75)) mcmc_hist(lagsar) +    vline_at(estimates, linetype = 2, size = 1) +   ggtitle(\"lagsar: posterior median and 50% central interval\")"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-non-factorized.html","id":"approximate-loo-cv","dir":"Articles","previous_headings":"Lagged SAR models > Case Study: Neighborhood Crime in Columbus, Ohio","what":"Approximate LOO-CV","title":"Leave-one-out cross-validation for non-factorized models","text":"fitting model, next step compute pointwise log-likelihood values needed approximate LOO-CV. use recipe laid previous sections. quality PSIS-LOO approximation can investigated graphically plotting Pareto-k estimate observation. approximation robust values 0.70.7 (Vehtari et al, 2017, 2024). plot , see fourth observation problematic may reduce accuracy LOO-CV approximation.  can also check conditional leave-one-predictive distribution equations work correctly, instance, using last posterior draw:  Finally, use PSIS-LOO approximate expected log predictive density (ELPD) new data, validate using exact LOO-CV upcoming section.","code":"posterior <- as.data.frame(fit) y <- fit$data$CRIME N <- length(y) S <- nrow(posterior) loglik <- yloo <- sdloo <- matrix(nrow = S, ncol = N)  for (s in 1:S) {   p <- posterior[s, ]   eta <- p$b_Intercept + p$b_INC * fit$data$INC + p$b_HOVAL * fit$data$HOVAL   W_tilde <- diag(N) - p$lagsar * spdep::nb2mat(COL.nb)   Cinv <- t(W_tilde) %*% W_tilde / p$sigma^2   g <- Cinv %*% (y - solve(W_tilde, eta))   cbar <- diag(Cinv)   yloo[s, ] <- y - g / cbar   sdloo[s, ] <- sqrt(1 / cbar)   loglik[s, ] <- dnorm(y, yloo[s, ], sdloo[s, ], log = TRUE) }  # use loo for psis smoothing log_ratios <- -loglik psis_result <- psis(log_ratios) plot(psis_result, label_points = TRUE) yloo_sub <- yloo[S, ] sdloo_sub <- sdloo[S, ] df <- data.frame(   y = y,    yloo = yloo_sub,   ymin = yloo_sub - sdloo_sub * 2,   ymax = yloo_sub + sdloo_sub * 2 ) ggplot(data=df, aes(x = y, y = yloo, ymin = ymin, ymax = ymax)) +   geom_errorbar(     width = 1,      color = \"skyblue3\",      position = position_jitter(width = 0.25)   ) +   geom_abline(color = \"gray30\", size = 1.2) +   geom_point() (psis_loo <- loo(loglik)) Computed from 4000 by 49 log-likelihood matrix.           Estimate   SE elpd_loo   -187.4 11.3 p_loo         8.6  5.7 looic       374.8 22.7 ------ MCSE of elpd_loo is NA. MCSE and ESS estimates assume independent draws (r_eff=1).  Pareto k diagnostic values:                          Count Pct.    Min. ESS (-Inf, 0.7]   (good)     48    98.0%   650         (0.7, 1]   (bad)       0     0.0%   <NA>        (1, Inf)   (very bad)  1     2.0%   <NA>     See help('pareto-k-diagnostic') for details."},{"path":"https://mc-stan.org/loo/dev/articles/loo2-non-factorized.html","id":"exact-loo-cv","dir":"Articles","previous_headings":"Lagged SAR models > Case Study: Neighborhood Crime in Columbus, Ohio","what":"Exact LOO-CV","title":"Leave-one-out cross-validation for non-factorized models","text":"Exact LOO-CV example somewhat involved, need re-fit model NN times time model held-data point parameter. First, create empty dummy model update loop observations. Next, fit model NN times, time leaving single observation computing log predictive density observation. obvious reasons, takes much longer approximation computed , necessary order validate approximate LOO-CV method. Thanks PSIS-LOO approximation, general slow exact computations can avoided. first step validation pointwise predictive density compare distribution implied response values left-observation distribution yimisy_i^{\\mathrm{mis}} posterior-predictive values estimated part model. pointwise predictive density correct, two distributions match closely (sampling error). plot , overlay two distributions first four observations see match closely (case 4949 observations example).  final step, compute ELPD based exact LOO-CV compare approximate PSIS-LOO result computed earlier. results approximate exact LOO-CV similar close expect problematic observations. can investigate issue closely plotting approximate exact pointwise ELPD values.  plot fourth data point —observation flagged problematic PSIS-LOO approximation— colored red clear outlier. Otherwise, correspondence exact approximate values strong. fact, summing pointwise ELPD values leaving fourth observation yields practically equivalent results approximate exact LOO-CV: can conclude difference found including observations indicate bug implementation approximate LOO-CV rather violation assumptions.","code":"# see help(\"mi\", \"brms\") for details on the mi() usage fit_dummy <- brm(   CRIME | mi() ~ INC + HOVAL + sar(COL.nb, type = \"lag\"),    data = COL.OLD,   data2 = list(COL.nb = COL.nb),   chains = 0 ) S <- 500 res <- vector(\"list\", N) loglik <- matrix(nrow = S, ncol = N) for (i in seq_len(N)) {   dat_mi <- COL.OLD   dat_mi$CRIME[i] <- NA   fit_i <- update(fit_dummy, newdata = dat_mi,                    # just for vignette                   chains = 1, iter = S * 2)   posterior <- as.data.frame(fit_i)   yloo <- sdloo <- rep(NA, S)   for (s in seq_len(S)) {     p <- posterior[s, ]     y_miss_i <- y     y_miss_i[i] <- p$Ymi     eta <- p$b_Intercept + p$b_INC * fit_i$data$INC + p$b_HOVAL * fit_i$data$HOVAL     W_tilde <- diag(N) - p$lagsar * spdep::nb2mat(COL.nb)     Cinv <- t(W_tilde) %*% W_tilde / p$sigma^2     g <- Cinv %*% (y_miss_i - solve(W_tilde, eta))     cbar <- diag(Cinv);     yloo[s] <- y_miss_i[i] - g[i] / cbar[i]     sdloo[s] <- sqrt(1 / cbar[i])     loglik[s, i] <- dnorm(y[i], yloo[s], sdloo[s], log = TRUE)   }   ypred <- rnorm(S, yloo, sdloo)   res[[i]] <- data.frame(y = c(posterior$Ymi, ypred))   res[[i]]$type <- rep(c(\"pp\", \"loo\"), each = S)   res[[i]]$obs <- i } res <- do.call(rbind, res) res_sub <- res[res$obs %in% 1:4, ] ggplot(res_sub, aes(y, fill = type)) +   geom_density(alpha = 0.6) +   facet_wrap(\"obs\", scales = \"fixed\", ncol = 4) log_mean_exp <- function(x) {   # more stable than log(mean(exp(x)))   max_x <- max(x)   max_x + log(sum(exp(x - max_x))) - log(length(x)) } exact_elpds <- apply(loglik, 2, log_mean_exp) exact_elpd <- sum(exact_elpds) round(exact_elpd, 1) [1] -189.2 df <- data.frame(   approx_elpd = psis_loo$pointwise[, \"elpd_loo\"],   exact_elpd = exact_elpds ) ggplot(df, aes(x = approx_elpd, y = exact_elpd)) +   geom_abline(color = \"gray30\") +   geom_point(size = 2) +   geom_point(data = df[4, ], size = 3, color = \"red3\") +   xlab(\"Approximate elpds\") +   ylab(\"Exact elpds\") +   coord_fixed(xlim = c(-16, -3), ylim = c(-16, -3)) without_pt_4 <- c(   approx = sum(psis_loo$pointwise[-4, \"elpd_loo\"]),   exact = sum(exact_elpds[-4])   ) round(without_pt_4, 1) approx  exact  -173.0 -173.2"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-non-factorized.html","id":"working-with-stan-directly","dir":"Articles","previous_headings":"","what":"Working with Stan directly","title":"Leave-one-out cross-validation for non-factorized models","text":"far, specified models brms used Stan implicitely behind scenes. allowed us focus primary purpose validating approximate LOO-CV non-factorized models. However, also like show everything can set Stan directly. Stan code brms generates human readable can use learn essential aspects Stan particular model implementing. Stan program slightly modified version code extracted via stancode(fit_dummy): want focus two aspects Stan code. First, built-function Stan calculates log-likelihood lag-SAR model, define new normal_lagsar_lpdf function functions block Stan program. function showed earlier vignette can used compute log-likelihood efficient numerically stable way. _lpdf suffix used function name informs Stan log probability density function. Second, Stan program nicely illustrates set missing value imputation. Instead just computing log-likelihood observed responses Y, define new variable Yl equal Y reponse observed equal Ymi response missing. latter turn defined parameter thus estimated along paramters model. details missing value imputation Stan can found Missing Data & Partially Known Parameters section Stan manual. Stan code extracted brms helpful learning Stan, can also drastically speed specification models support brms. brms can fit model similar identical desired model, can let brms generate Stan program similar model mold program implements model actually want fit. Rather calling stancode(), requires existing fitted model object, recommend using make_stancode() specifying save_model argument write Stan program file. corresponding data can prepared make_standata() manually amended needed. code data edited, can passed RStan’s stan() function via file data arguments.","code":"// generated with brms 2.2.0 functions { /**   * Normal log-pdf for spatially lagged responses  *   * @param y Vector of response values.  * @param mu Mean parameter vector.  * @param sigma Positive scalar residual standard deviation.  * @param rho Positive scalar autoregressive parameter.  * @param W Spatial weight matrix.  *  * @return A scalar to be added to the log posterior.  */   real normal_lagsar_lpdf(vector y, vector mu, real sigma,                           real rho, matrix W) {     int N = rows(y);     real inv_sigma2 = 1 / square(sigma);     matrix[N, N] W_tilde = -rho * W;     vector[N] half_pred;     for (n in 1:N) W_tilde[n, n] += 1;     half_pred = W_tilde * (y - mdivide_left(W_tilde, mu));     return 0.5 * log_determinant(crossprod(W_tilde) * inv_sigma2) -            0.5 * dot_self(half_pred) * inv_sigma2;   } } data {   int<lower=1> N;  // total number of observations   vector[N] Y;  // response variable   int<lower=0> Nmi;  // number of missings   int<lower=1> Jmi[Nmi];  // positions of missings   int<lower=1> K;  // number of population-level effects   matrix[N, K] X;  // population-level design matrix   matrix[N, N] W;  // spatial weight matrix   int prior_only;  // should the likelihood be ignored? } transformed data {   int Kc = K - 1;   matrix[N, K - 1] Xc;  // centered version of X   vector[K - 1] means_X;  // column means of X before centering   for (i in 2:K) {     means_X[i - 1] = mean(X[, i]);     Xc[, i - 1] = X[, i] - means_X[i - 1];   } } parameters {   vector[Nmi] Ymi;  // estimated missings   vector[Kc] b;  // population-level effects   real temp_Intercept;  // temporary intercept   real<lower=0> sigma;  // residual SD   real<lower=0,upper=1> lagsar;  // SAR parameter } transformed parameters { } model {   vector[N] Yl = Y;   vector[N] mu = Xc * b + temp_Intercept;   Yl[Jmi] = Ymi;   // priors including all constants   target += student_t_lpdf(temp_Intercept | 3, 34, 17);   target += student_t_lpdf(sigma | 3, 0, 17)     - 1 * student_t_lccdf(0 | 3, 0, 17);   // likelihood including all constants   if (!prior_only) {     target += normal_lagsar_lpdf(Yl | mu, sigma, lagsar, W);   } } generated quantities {   // actual population-level intercept   real b_Intercept = temp_Intercept - dot_product(means_X, b); }"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-non-factorized.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Leave-one-out cross-validation for non-factorized models","text":"summary, shown set validate approximate exact LOO-CV non-factorized multivariate normal models using Stan brms loo packages. Although focused particular example spatial SAR model, presented recipe applies generally models can expressed terms multivariate normal likelihood.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-non-factorized.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Leave-one-out cross-validation for non-factorized models","text":"Anselin L. (1988). Spatial econometrics: methods models. Dordrecht: Kluwer Academic. Bürkner P. C., Gabry J., & Vehtari . (2020). Efficient leave-one-cross-validation Bayesian non-factorized normal Student-t models. Computational Statistics, :10.1007/s00180-020-01045-4. ArXiv preprint. Sundararajan S. & Keerthi S. S. (2001). Predictive approaches choosing hyperparameters Gaussian processes. Neural Computation, 13(5), 1103–1118. Vehtari ., Mononen T., Tolvanen V., Sivula T., & Winther O. (2016). Bayesian leave-one-cross-validation approximations Gaussian latent variable models. Journal Machine Learning Research, 17(103), 1–38. Online. Vehtari ., Gelman ., & Gabry J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing, 27(5), 1413–1432. :10.1007/s11222-016-9696-4. Online. arXiv preprint arXiv:1507.04544. Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-weights.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Bayesian Stacking and Pseudo-BMA weights using the loo package","text":"vignette demonstrates new functionality loo v2.0.0 Bayesian stacking Pseudo-BMA weighting. vignette can’t provide necessary background topic, encourage readers refer paper Yao, Y., Vehtari, ., Simpson, D., Gelman, . (2018). Using stacking average Bayesian predictive distributions. Bayesian Analysis, :10.1214/17-BA1091. Online provides important details methods demonstrated vignette. just quote abstract paper: Abstract: Bayesian model averaging flawed ℳ\\mathcal{M}-open setting true data-generating process one candidate models fit. take idea stacking point estimation literature generalize combination predictive distributions. extend utility function proper scoring rule use Pareto smoothed importance sampling efficiently compute required leave-one-posterior distributions. compare stacking predictive distributions several alternatives: stacking means, Bayesian model averaging (BMA), Pseudo-BMA, variant Pseudo-BMA stabilized using Bayesian bootstrap. Based simulations real-data applications, recommend stacking predictive distributions, bootstrapped-Pseudo-BMA approximate alternative computation cost issue. Ideally, avoid Bayesian model combination problem extending model include separate models special cases, preferably continuous expansion model space. example, instead model averaging different covariate combinations, potentially relevant covariates included predictive model (causal analysis care needed) prior assumption covariates relevant can presented regularized horseshoe prior (Piironen Vehtari, 2017a). variable selection recommend projective predictive variable selection (Piironen Vehtari, 2017a; projpred package). demonstrate use loo package compute Bayesian stacking Pseudo-BMA weights, repeat two simple model averaging examples Chapters 6 10 Statistical Rethinking Richard McElreath. Statistical Rethinking WAIC used form weights similar classical “Akaike weights”. Pseudo-BMA weighting using PSIS-LOO computation close WAIC weights, named Pseudo Bayes Factor Geisser Eddy (1979). discussed , general prefer using stacking rather WAIC weights similar pseudo-BMA weights.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-weights.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Bayesian Stacking and Pseudo-BMA weights using the loo package","text":"addition loo package also load rstanarm package fitting models.","code":"library(rstanarm) library(loo)"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-weights.html","id":"example-primate-milk","dir":"Articles","previous_headings":"","what":"Example: Primate milk","title":"Bayesian Stacking and Pseudo-BMA weights using the loo package","text":"Statistical Rethinking, McElreath describes data primate milk example follows: popular hypothesis primates larger brains produce energetic milk, brains can grow quickly. … question extent energy content milk, measured kilocalories, related percent brain mass neocortex. … ’ll end needing female body mass well, see masking hides relationships among variables. repeat analysis Chapter 6 Statistical Rethinking using following four models (use default weakly informative priors rstanarm, flat priors used Statistical Rethinking). McElreath uses WAIC model comparison averaging, ’ll start also computing WAIC models can compare results options presented later vignette. loo package provides waic methods log-likelihood arrays, matrices functions. Since fit model rstanarm can use waic method provided rstanarm package (wrapper around waic loo package), allows us just pass fitted model objects instead first extracting log-likelihood values. get warnings computing WAIC models 3 4, indicating shouldn’t trust WAIC weights compute later. Following recommendation warning, next use loo methods compute PSIS-LOO instead. loo package provides loo methods log-likelihood arrays, matrices, functions, since fit model rstanarm can just pass fitted model objects directly rstanarm extract needed values pass loo package. (Like rstanarm, R packages fitting Stan models, e.g. brms, also provide similar methods interfacing loo package.) loo don’t get warnings models 3 4, illustration good results, display diagnostic details models anyway. One benefit PSIS-LOO WAIC better diagnostics. models 3 4 k<0.7k<0.7 Monte Carlo SE elpd_loo 0.1 less, can expect model comparison reliable. Next compute compare 1) WAIC weights, 2) Pseudo-BMA weights without Bayesian bootstrap, 3) Pseudo-BMA+ weights Bayesian bootstrap, 4) Bayesian stacking weights. approaches Model 4 neocortex log(mass) gets weight. Based theory, Pseudo-BMA weights without Bayesian bootstrap close WAIC weights, can also see . Pseudo-BMA+ weights Bayesian bootstrap provide cautious weights away 0 1 (see Yao et al. (2018) discussion can beneficial results related experiments). particular example, Bayesian stacking weights much different weights. One benefits stacking manages well many similar models. Consider example many irrelevant covariates included produce similar model one existing models. emulate situation simply copy first model bunch times, can imagine instead ten alternative models predictive performance. WAIC weights scenario close following: Notice much weight model 4 lowered now models similar model 1 (case identical) added. WAIC weights Pseudo-BMA approaches first estimate predictive performance separately model compute weights based estimated relative predictive performances. Similar models share similar weights weights models must reduced total sum weights remain . hand, stacking optimizes weights jointly, allowing similar models (toy example repeated models) share weight unique models keep original weights. example can see difference clearly: Using stacking, weight best model stays essentially unchanged.","code":"data(milk) d <- milk[complete.cases(milk),] d$neocortex <- d$neocortex.perc /100 str(d) 'data.frame':   17 obs. of  9 variables:  $ clade         : Factor w/ 4 levels \"Ape\",\"New World Monkey\",..: 4 2 2 2 2 2 2 2 3 3 ...  $ species       : Factor w/ 29 levels \"A palliata\",\"Alouatta seniculus\",..: 11 2 1 6 27 5 3 4 21 19 ...  $ kcal.per.g    : num  0.49 0.47 0.56 0.89 0.92 0.8 0.46 0.71 0.68 0.97 ...  $ perc.fat      : num  16.6 21.2 29.7 53.4 50.6 ...  $ perc.protein  : num  15.4 23.6 23.5 15.8 22.3 ...  $ perc.lactose  : num  68 55.2 46.9 30.8 27.1 ...  $ mass          : num  1.95 5.25 5.37 2.51 0.68 0.12 0.47 0.32 1.55 3.24 ...  $ neocortex.perc: num  55.2 64.5 64.5 67.6 68.8 ...  $ neocortex     : num  0.552 0.645 0.645 0.676 0.688 ... fit1 <- stan_glm(kcal.per.g ~ 1, data = d, seed = 2030) fit2 <- update(fit1, formula = kcal.per.g ~ neocortex) fit3 <- update(fit1, formula = kcal.per.g ~ log(mass)) fit4 <- update(fit1, formula = kcal.per.g ~ neocortex + log(mass)) waic1 <- waic(fit1) waic2 <- waic(fit2) waic3 <- waic(fit3) Warning:  1 (5.9%) p_waic estimates greater than 0.4. We recommend trying loo instead. waic4 <- waic(fit4) Warning:  2 (11.8%) p_waic estimates greater than 0.4. We recommend trying loo instead. waics <- c(   waic1$estimates[\"elpd_waic\", 1],   waic2$estimates[\"elpd_waic\", 1],   waic3$estimates[\"elpd_waic\", 1],   waic4$estimates[\"elpd_waic\", 1] ) # note: the loo function accepts a 'cores' argument that we recommend specifying # when working with bigger datasets  loo1 <- loo(fit1) loo2 <- loo(fit2) loo3 <- loo(fit3) loo4 <- loo(fit4) lpd_point <- cbind(   loo1$pointwise[,\"elpd_loo\"],    loo2$pointwise[,\"elpd_loo\"],   loo3$pointwise[,\"elpd_loo\"],    loo4$pointwise[,\"elpd_loo\"] ) print(loo3) Computed from 4000 by 17 log-likelihood matrix.           Estimate  SE elpd_loo      4.5 2.3 p_loo         2.1 0.5 looic        -9.1 4.6 ------ MCSE of elpd_loo is 0.0. MCSE and ESS estimates assume MCMC draws (r_eff in [0.5, 1.0]).  All Pareto k estimates are good (k < 0.7). See help('pareto-k-diagnostic') for details. print(loo4) Computed from 4000 by 17 log-likelihood matrix.           Estimate  SE elpd_loo      8.4 2.8 p_loo         3.3 0.9 looic       -16.8 5.5 ------ MCSE of elpd_loo is 0.1. MCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 1.0]).  All Pareto k estimates are good (k < 0.7). See help('pareto-k-diagnostic') for details. waic_wts <- exp(waics) / sum(exp(waics)) pbma_wts <- pseudobma_weights(lpd_point, BB=FALSE) pbma_BB_wts <- pseudobma_weights(lpd_point) # default is BB=TRUE stacking_wts <- stacking_weights(lpd_point) round(cbind(waic_wts, pbma_wts, pbma_BB_wts, stacking_wts), 2) waic_wts pbma_wts pbma_BB_wts stacking_wts model1     0.01     0.02        0.07         0.01 model2     0.01     0.01        0.04         0.00 model3     0.02     0.02        0.04         0.00 model4     0.96     0.95        0.86         0.99 waic_wts_demo <-    exp(waics[c(1,1,1,1,1,1,1,1,1,1,2,3,4)]) /   sum(exp(waics[c(1,1,1,1,1,1,1,1,1,1,2,3,4)])) round(waic_wts_demo, 3) [1] 0.013 0.013 0.013 0.013 0.013 0.013 0.013 0.013 0.013 0.013 0.006 0.016 [13] 0.847 stacking_weights(lpd_point[,c(1,1,1,1,1,1,1,1,1,1,2,3,4)]) Method: stacking ------         weight model1  0.001  model2  0.001  model3  0.001  model4  0.001  model5  0.001  model6  0.001  model7  0.001  model8  0.001  model9  0.001  model10 0.001  model11 0.000  model12 0.000  model13 0.987"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-weights.html","id":"example-oceanic-tool-complexity","dir":"Articles","previous_headings":"","what":"Example: Oceanic tool complexity","title":"Bayesian Stacking and Pseudo-BMA weights using the loo package","text":"Another example consider Kline oceanic tool complexity data, McElreath describes follows: Different historical island populations possessed tool kits different size. kits include fish hooks, axes, boats, hand plows, many types tools. number theories predict larger populations develop sustain complex tool kits. … ’s also suggested contact rates among populations effectively increases population [sic, probably tool kit] size, ’s relevant technological evolution. build models predicting total number tools given log population size contact rate (high vs. low). start Poisson regression model log population size, contact rate, interaction term (priors informative priors Statistical Rethinking). running models, check whether Poisson good choice conditional observation model. get least one observation k>0.7k>0.7 estimated effective number parameters p_loo larger total number parameters model. indicates Poisson might narrow. negative binomial model might better, observations clear. can compute LOO accurately running Stan leave-one-folds high kk estimates. using rstanarm can done specifying k_threshold argument: case see much difference, thus relatively safe continue. comparison also compute WAIC: WAIC computation giving warnings estimated ELPD slightly optimistic. recommend using PSIS-LOO results instead. assess whether contact rate interaction term useful, can make comparison models without terms. comparison ’ll also compute WAIC values additional models: WAIC computation gives warnings, recommend using PSIS-LOO instead. Finally, compute 1) WAIC weights, 2) Pseudo-BMA weights without Bayesian bootstrap, 3) Pseudo-BMA+ weights Bayesian bootstrap, 4) Bayesian stacking weights. weights favor second model log population contact rate. WAIC weights Pseudo-BMA weights (without Bayesian bootstrap) similar, Pseudo-BMA+ cautious closer stacking weights. may seem surprising Bayesian stacking giving zero weight first model, likely due fact estimated effect interaction term close zero thus models 1 2 give similar predictions. words, incorporating model interaction (model 1) model average doesn’t improve predictions model 1 given weight 0. hand, models 2 3 giving slightly different predictions thus combination may slightly better either alone. behavior related repeated similar model illustration milk example .","code":"data(Kline) d <- Kline d$log_pop <- log(d$population) d$contact_high <- ifelse(d$contact==\"high\", 1, 0) str(d) 'data.frame':   10 obs. of  7 variables:  $ culture     : Factor w/ 10 levels \"Chuuk\",\"Hawaii\",..: 4 7 6 10 3 9 1 5 8 2  $ population  : int  1100 1500 3600 4791 7400 8000 9200 13000 17500 275000  $ contact     : Factor w/ 2 levels \"high\",\"low\": 2 2 2 1 1 1 1 2 1 2  $ total_tools : int  13 22 24 43 33 19 40 28 55 71  $ mean_TU     : num  3.2 4.7 4 5 5 4 3.8 6.6 5.4 6.6  $ log_pop     : num  7 7.31 8.19 8.47 8.91 ...  $ contact_high: num  0 0 0 1 1 1 1 0 1 0 fit10 <-   stan_glm(     total_tools ~ log_pop + contact_high + log_pop * contact_high,     family = poisson(link = \"log\"),     data = d,     prior = normal(0, 1, autoscale = FALSE),     prior_intercept = normal(0, 100, autoscale = FALSE),     seed = 2030   ) loo10 <- loo(fit10) Warning: Found 3 observation(s) with a pareto_k > 0.7. We recommend calling 'loo' again with argument 'k_threshold = 0.7' in order to calculate the ELPD without the assumption that these observations are negligible. This will refit the model 3 times to compute the ELPDs for the problematic observations directly. print(loo10) Computed from 4000 by 10 log-likelihood matrix.           Estimate   SE elpd_loo    -40.6  6.1 p_loo         5.4  1.9 looic        81.3 12.1 ------ MCSE of elpd_loo is NA. MCSE and ESS estimates assume MCMC draws (r_eff in [0.5, 0.8]).  Pareto k diagnostic values:                          Count Pct.    Min. ESS (-Inf, 0.7]   (good)     7     70.0%   327         (0.7, 1]   (bad)      3     30.0%   <NA>        (1, Inf)   (very bad) 0      0.0%   <NA>     See help('pareto-k-diagnostic') for details. loo10 <- loo(fit10, k_threshold=0.7) 3 problematic observation(s) found. Model will be refit 3 times. Fitting model 1 out of 3 (leaving out observation 4) Fitting model 2 out of 3 (leaving out observation 6) Fitting model 3 out of 3 (leaving out observation 10) print(loo10) Computed from 4000 by 10 log-likelihood matrix.           Estimate   SE elpd_loo    -40.8  5.9 p_loo         5.6  1.9 looic        81.6 11.9 ------ MCSE of elpd_loo is 0.2. MCSE and ESS estimates assume MCMC draws (r_eff in [0.5, 0.8]).  All Pareto k estimates are good (k < 0.7). See help('pareto-k-diagnostic') for details. waic10 <- waic(fit10) Warning:  4 (40.0%) p_waic estimates greater than 0.4. We recommend trying loo instead. print(waic10) Computed from 4000 by 10 log-likelihood matrix.            Estimate   SE elpd_waic    -40.1  6.0 p_waic         4.9  1.8 waic          80.2 11.9  4 (40.0%) p_waic estimates greater than 0.4. We recommend trying loo instead. fit11 <- update(fit10, formula = total_tools ~ log_pop + contact_high) fit12 <- update(fit10, formula = total_tools ~ log_pop) (loo11 <- loo(fit11)) Computed from 4000 by 10 log-likelihood matrix.           Estimate   SE elpd_loo    -39.7  5.8 p_loo         4.4  1.6 looic        79.4 11.6 ------ MCSE of elpd_loo is 0.1. MCSE and ESS estimates assume MCMC draws (r_eff in [0.5, 1.0]).  All Pareto k estimates are good (k < 0.7). See help('pareto-k-diagnostic') for details. (loo12 <- loo(fit12)) Warning: Found 1 observation(s) with a pareto_k > 0.7. We recommend calling 'loo' again with argument 'k_threshold = 0.7' in order to calculate the ELPD without the assumption that these observations are negligible. This will refit the model 1 times to compute the ELPDs for the problematic observations directly. Computed from 4000 by 10 log-likelihood matrix.           Estimate  SE elpd_loo    -42.5 4.7 p_loo         4.1 1.1 looic        85.0 9.4 ------ MCSE of elpd_loo is NA. MCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 0.6]).  Pareto k diagnostic values:                          Count Pct.    Min. ESS (-Inf, 0.7]   (good)     9     90.0%   653         (0.7, 1]   (bad)      1     10.0%   <NA>        (1, Inf)   (very bad) 0      0.0%   <NA>     See help('pareto-k-diagnostic') for details. loo11 <- loo(fit11, k_threshold=0.7) All pareto_k estimates below user-specified threshold of 0.7.  Returning loo object. loo12 <- loo(fit12, k_threshold=0.7) 1 problematic observation(s) found. Model will be refit 1 times. Fitting model 1 out of 1 (leaving out observation 10) lpd_point <- cbind(   loo10$pointwise[, \"elpd_loo\"],    loo11$pointwise[, \"elpd_loo\"],    loo12$pointwise[, \"elpd_loo\"] ) waic11 <- waic(fit11) Warning:  3 (30.0%) p_waic estimates greater than 0.4. We recommend trying loo instead. waic12 <- waic(fit12) Warning:  5 (50.0%) p_waic estimates greater than 0.4. We recommend trying loo instead. waics <- c(   waic10$estimates[\"elpd_waic\", 1],    waic11$estimates[\"elpd_waic\", 1],    waic12$estimates[\"elpd_waic\", 1] ) waic_wts <- exp(waics) / sum(exp(waics)) pbma_wts <- pseudobma_weights(lpd_point, BB=FALSE) pbma_BB_wts <- pseudobma_weights(lpd_point) # default is BB=TRUE stacking_wts <- stacking_weights(lpd_point) round(cbind(waic_wts, pbma_wts, pbma_BB_wts, stacking_wts), 2) waic_wts pbma_wts pbma_BB_wts stacking_wts model1     0.34     0.24        0.22          0.0 model2     0.62     0.75        0.63          0.8 model3     0.04     0.02        0.15          0.2"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-weights.html","id":"simpler-coding-using-loo_model_weights-function","dir":"Articles","previous_headings":"","what":"Simpler coding using loo_model_weights function","title":"Bayesian Stacking and Pseudo-BMA weights using the loo package","text":"Although examples called stacking_weights pseudobma_weights functions directly, can also use loo_model_weights wrapper, takes input either list pointwise log-likelihood matrices list precomputed loo objects. also loo_model_weights methods stanreg objects (fitted model objects rstanarm) well fitted model objects packages (e.g. brms) preparation work user (see, e.g., examples help(\"loo_model_weights\", package = \"rstanarm\")).","code":"# using list of loo objects loo_list <- list(loo10, loo11, loo12) loo_model_weights(loo_list) Method: stacking ------       weight fit10 0.000  fit11 0.802  fit12 0.198 loo_model_weights(loo_list, method = \"pseudobma\") Method: pseudo-BMA+ with Bayesian bootstrap ------       weight fit10 0.210  fit11 0.640  fit12 0.150 loo_model_weights(loo_list, method = \"pseudobma\", BB = FALSE) Method: pseudo-BMA ------       weight fit10 0.237  fit11 0.745  fit12 0.018"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-weights.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Bayesian Stacking and Pseudo-BMA weights using the loo package","text":"McElreath, R. (2016). Statistical rethinking: Bayesian course examples R Stan. Chapman & Hall/CRC. http://xcelab.net/rm/statistical-rethinking/ Piironen, J. Vehtari, . (2017a). Sparsity information regularization horseshoe shrinkage priors. Electronic Journal Statistics, 11(2):5018-5051. Online. Piironen, J. Vehtari, . (2017b). Comparison Bayesian predictive methods model selection. Statistics Computing, 27(3):711-735. :10.1007/s11222-016-9649-y. Online. Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. :10.1007/s11222-016-9696-4. online, arXiv preprint arXiv:1507.04544. Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF Yao, Y., Vehtari, ., Simpson, D., Gelman, . (2018). Using stacking average Bayesian predictive distributions. Bayesian Analysis, :10.1214/17-BA1091. Online.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-with-rstan.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Writing Stan programs for use with the loo package","text":"vignette demonstrates write Stan program computes stores pointwise log-likelihood required using loo package. vignettes included package demonstrate additional functionality. sections vignette excerpted papers Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. :10.1007/s11222-016-9696-4. Links: published | arXiv preprint. Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF provide important background understanding methods implemented package.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-with-rstan.html","id":"example-well-water-in-bangladesh","dir":"Articles","previous_headings":"","what":"Example: Well water in Bangladesh","title":"Writing Stan programs for use with the loo package","text":"example comes survey residents small area Bangladesh affected arsenic drinking water. Respondents elevated arsenic levels wells asked interested getting water neighbor’s well, series logistic regressions fit predict binary response given various information households (Gelman Hill, 2007). fit model well-switching response given two predictors: arsenic level water resident’s home, distance house nearest safe well. sample size example N=3020N=3020, huge large enough important computational method LOO fast data point. plus side, large dataset, influence given observation small, computations stable.","code":""},{"path":"https://mc-stan.org/loo/dev/articles/loo2-with-rstan.html","id":"coding-the-stan-model","dir":"Articles","previous_headings":"Example: Well water in Bangladesh","what":"Coding the Stan model","title":"Writing Stan programs for use with the loo package","text":"Stan code fitting logistic regression model, save file called logistic.stan: defined log likelihood vector named log_lik generated quantities block individual terms saved Stan. running Stan, log_lik can extracted (using extract_log_lik function provided loo package) S×NS \\times N matrix, SS number simulations (posterior draws) NN number data points.","code":"// Note: some syntax used in this program requires RStan >= 2.26 (or CmdStanR) // To use an older version of RStan change the line declaring `y` to: //    int<lower=0,upper=1> y[N]; data {   int<lower=0> N;                   // number of data points   int<lower=0> P;                   // number of predictors (including intercept)   matrix[N,P] X;                    // predictors (including 1s for intercept)   array[N] int<lower=0,upper=1> y;  // binary outcome } parameters {   vector[P] beta; } model {   beta ~ normal(0, 1);   y ~ bernoulli_logit(X * beta); } generated quantities {   vector[N] log_lik;   for (n in 1:N) {     log_lik[n] = bernoulli_logit_lpmf(y[n] | X[n] * beta);   } }"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-with-rstan.html","id":"fitting-the-model-with-rstan","dir":"Articles","previous_headings":"Example: Well water in Bangladesh","what":"Fitting the model with RStan","title":"Writing Stan programs for use with the loo package","text":"Next fit model Stan using rstan package:","code":"library(\"rstan\")  # Prepare data  url <- \"http://stat.columbia.edu/~gelman/arm/examples/arsenic/wells.dat\" wells <- read.table(url) wells$dist100 <- with(wells, dist / 100) X <- model.matrix(~ dist100 + arsenic, wells) standata <- list(y = wells$switch, X = X, N = nrow(X), P = ncol(X))  # Fit model fit_1 <- stan(\"logistic.stan\", data = standata) print(fit_1, pars = \"beta\") mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat beta[1]  0.00       0 0.08 -0.16 -0.05  0.00  0.05  0.15  1964    1 beta[2] -0.89       0 0.10 -1.09 -0.96 -0.89 -0.82 -0.68  2048    1 beta[3]  0.46       0 0.04  0.38  0.43  0.46  0.49  0.54  2198    1"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-with-rstan.html","id":"computing-approximate-leave-one-out-cross-validation-using-psis-loo","dir":"Articles","previous_headings":"Example: Well water in Bangladesh","what":"Computing approximate leave-one-out cross-validation using PSIS-LOO","title":"Writing Stan programs for use with the loo package","text":"can use loo package compute efficient PSIS-LOO approximation exact LOO-CV: printed output loo function shows estimates $\\widehat{\\mbox{elpd}}_{\\rm loo}$ (expected log predictive density), $\\widehat{p}_{\\rm loo}$ (effective number parameters), ${\\rm looic} =-2\\, \\widehat{\\mbox{elpd}}_{\\rm loo}$ (LOO information criterion). line bottom printed output provides information reliability LOO approximation (interpretation kk parameter explained help('pareto-k-diagnostic') greater detail Vehtari, Simpson, Gelman, Yao, Gabry (2019)). case message tells us estimates kk fine.","code":"library(\"loo\")  # Extract pointwise log-likelihood # using merge_chains=FALSE returns an array, which is easier to  # use with relative_eff() log_lik_1 <- extract_log_lik(fit_1, merge_chains = FALSE)  # as of loo v2.0.0 we can optionally provide relative effective sample sizes # when calling loo, which allows for better estimates of the PSIS effective # sample sizes and Monte Carlo error r_eff <- relative_eff(exp(log_lik_1), cores = 2)   # preferably use more than 2 cores (as many cores as possible) # will use value of 'mc.cores' option if cores is not specified loo_1 <- loo(log_lik_1, r_eff = r_eff, cores = 2) print(loo_1) Computed from 4000 by 3020 log-likelihood matrix           Estimate   SE elpd_loo  -1968.5 15.6 p_loo         3.2  0.1 looic      3937.0 31.2 ------ Monte Carlo SE of elpd_loo is 0.0. MCSE and ESS estimates assume MCMC draws (r_eff in [0.5, 1.3]).  All Pareto k estimates are good (k < 0.7). See help('pareto-k-diagnostic') for details."},{"path":"https://mc-stan.org/loo/dev/articles/loo2-with-rstan.html","id":"comparing-models","dir":"Articles","previous_headings":"Example: Well water in Bangladesh","what":"Comparing models","title":"Writing Stan programs for use with the loo package","text":"compare model alternative model data can use loo_compare function loo package. First ’ll fit second model well-switching data, using log(arsenic) instead arsenic predictor: can now compare models LOO using loo_compare function: new object, comp, contains estimated difference expected leave-one-prediction errors two models, along standard error: first column shows difference ELPD relative model largest ELPD. case, difference elpd scale relative approximate standard error difference) indicates preference second model (model2).","code":"standata$X[, \"arsenic\"] <- log(standata$X[, \"arsenic\"]) fit_2 <- stan(fit = fit_1, data = standata)   log_lik_2 <- extract_log_lik(fit_2, merge_chains = FALSE) r_eff_2 <- relative_eff(exp(log_lik_2)) loo_2 <- loo(log_lik_2, r_eff = r_eff_2, cores = 2) print(loo_2) Computed from 4000 by 3020 log-likelihood matrix           Estimate   SE elpd_loo  -1952.3 16.2 p_loo         3.1  0.1 looic      3904.6 32.4 ------ Monte Carlo SE of elpd_loo is 0.0. MCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 1.2]).  All Pareto k estimates are good (k < 0.7). See help('pareto-k-diagnostic') for details. # Compare comp <- loo_compare(loo_1, loo_2) print(comp) # can set simplify=FALSE for more detailed print output elpd_diff se_diff model2   0.0       0.0   model1 -16.3       4.4"},{"path":"https://mc-stan.org/loo/dev/articles/loo2-with-rstan.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"Writing Stan programs for use with the loo package","text":"Gelman, ., Hill, J. (2007). Data Analysis Using Regression Multilevel Hierarchical Models. Cambridge University Press. Stan Development Team (2017). Stan C++ Library, Version 2.17.0. https://mc-stan.org/ Stan Development Team (2018) RStan: R interface Stan, Version 2.17.3. https://mc-stan.org/ Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. :10.1007/s11222-016-9696-4. online, arXiv preprint arXiv:1507.04544. Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF","code":""},{"path":"https://mc-stan.org/loo/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Aki Vehtari. Author. Jonah Gabry. Maintainer, author. Måns Magnusson. Author. Yuling Yao. Author. Paul-Christian Bürkner. Author. Topi Paananen. Author. Andrew Gelman. Author. Ben Goodrich. Contributor. Juho Piironen. Contributor. Bruno Nicenboim. Contributor. Leevi Lindgren. Contributor.","code":""},{"path":"https://mc-stan.org/loo/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"(2024). “loo: Efficient leave-one-cross-validation WAIC Bayesian models.” R package version 2.8.0.9000, https://mc-stan.org/loo/. Vehtari , Gelman , Gabry J (2017). “Practical Bayesian model evaluation using leave-one-cross-validation WAIC.” Statistics Computing, 27, 1413–1432. doi:10.1007/s11222-016-9696-4. Yao Y, Vehtari , Simpson D, Gelman (2018). “Using stacking average Bayesian predictive distributions.” Bayesian Analysis, 13, 917–1007. doi:10.1214/17-BA1091.","code":"@Misc{,   title = {loo: Efficient leave-one-out cross-validation and WAIC for Bayesian models},   year = {2024},   note = {R package version 2.8.0.9000},   url = {https://mc-stan.org/loo/}, } @Article{,   title = {Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC},   author = {Aki Vehtari and Andrew Gelman and Jonah Gabry},   year = {2017},   journal = {Statistics and Computing},   volume = {27},   issue = {5},   pages = {1413--1432},   doi = {10.1007/s11222-016-9696-4}, } @Article{,   title = {Using stacking to average Bayesian predictive distributions},   author = {Yuling Yao and Aki Vehtari and Daniel Simpson and Andrew Gelman},   journal = {Bayesian Analysis},   year = {2018},   volume = {13},   issue = {3},   pages = {917--1007},   doi = {10.1214/17-BA1091}, }"},{"path":"https://mc-stan.org/loo/dev/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to loo","title":"Contributing to loo","text":"outlines propose change loo based similar instructions tidyverse packages, including contributing guidelines generated usethis::use_tidy_contributing().","code":""},{"path":"https://mc-stan.org/loo/dev/CONTRIBUTING.html","id":"fixing-typos","dir":"","previous_headings":"","what":"Fixing typos","title":"Contributing to loo","text":"can fix typos, spelling mistakes, grammatical errors documentation directly using GitHub web interface, long changes made source file. generally means ’ll need edit roxygen2 comments .R, .Rd file. can find .R file generates .Rd reading comment first line.","code":""},{"path":"https://mc-stan.org/loo/dev/CONTRIBUTING.html","id":"bigger-changes","dir":"","previous_headings":"","what":"Bigger changes","title":"Contributing to loo","text":"want make bigger change, ’s good idea first file issue make sure someone team agrees ’s needed. ’ve found bug, please file issue illustrates bug minimal reproducible example (see e.g. tidyverse reprex instructions). tidyverse guide create great issue advice.","code":""},{"path":"https://mc-stan.org/loo/dev/CONTRIBUTING.html","id":"pull-request-process","dir":"","previous_headings":"Bigger changes","what":"Pull request process","title":"Contributing to loo","text":"new creating pull requests tips. Using functions usethis package required can helpful process new . Fork package clone onto computer. haven’t done , recommend using usethis::create_from_github(\"stan-dev/loo\", fork = TRUE). Install development dependencies devtools::install_dev_deps(), make sure package passes R CMD check running devtools::check(). R CMD check doesn’t pass cleanly, ’s good idea ask help continuing. Create Git branch pull request (PR). recommend using usethis::pr_init(\"brief-description--change\"). Make changes, commit git, create PR running usethis::pr_push(), following prompts browser. title PR briefly describe change. body PR contain Fixes #issue-number. user-facing changes, add bullet top NEWS.md (.e. just first header). Follow style already used NEWS.md.","code":""},{"path":"https://mc-stan.org/loo/dev/CONTRIBUTING.html","id":"code-style","dir":"","previous_headings":"Bigger changes","what":"Code style","title":"Contributing to loo","text":"New code attempt follow style used package. doubt follow tidyverse style guide. use roxygen2, Markdown syntax, documentation. use testthat unit tests. Contributions test cases included easier accept.","code":""},{"path":"https://mc-stan.org/loo/dev/CONTRIBUTING.html","id":"code-of-conduct","dir":"","previous_headings":"","what":"Code of Conduct","title":"Contributing to loo","text":"Please note loo project follows Stan project’s Code Conduct. contributing project agree abide terms.","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/index.html","id":"efficient-approximate-leave-one-out-cross-validation-for-fitted-bayesian-models","dir":"","previous_headings":"","what":"Efficient approximate leave-one-out cross-validation for fitted Bayesian models","title":"Efficient Leave-One-Out Cross-Validation and WAIC for Bayesian Models","text":"loo R package allows users compute efficient approximate leave-one-cross-validation fitted Bayesian models, well model weights can used average predictive distributions. loo package package implements fast stable computations approximate LOO-CV WAIC Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. doi:10.1007/s11222-016-9696-4. Online, arXiv preprint arXiv:1507.04544. computes model weights described Yao, Y., Vehtari, ., Simpson, D., Gelman, . (2018). Using stacking average Bayesian predictive distributions. Bayesian Analysis, doi:10.1214/17-BA1091. Online, arXiv preprint arXiv:1704.02030. existing posterior simulation draws, compute approximate LOO-CV using Pareto smoothed importance sampling (PSIS), new procedure regularizing importance weights. byproduct calculations, also obtain approximate standard errors estimated predictive errors comparing predictive errors two models. recommend PSIS-LOO-CV instead WAIC, PSIS provides useful diagnostics effective sample size Monte Carlo standard error estimates.","code":""},{"path":"https://mc-stan.org/loo/dev/index.html","id":"resources","dir":"","previous_headings":"","what":"Resources","title":"Efficient Leave-One-Out Cross-Validation and WAIC for Bayesian Models","text":"mc-stan.org/loo (online documentation, vignettes) Ask question (Stan Forums Discourse) Open issue (GitHub issues bug reports, feature requests)","code":""},{"path":"https://mc-stan.org/loo/dev/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Efficient Leave-One-Out Cross-Validation and WAIC for Bayesian Models","text":"Install latest release CRAN: Install latest development version GitHub: recommend setting build_vignettes=TRUE installing GitHub vignettes take long time build always available online mc-stan.org/loo/articles/.","code":"install.packages(\"loo\") # install.packages(\"remotes\") remotes::install_github(\"stan-dev/loo\")"},{"path":"https://mc-stan.org/loo/dev/index.html","id":"python-and-matlaboctave-code","dir":"","previous_headings":"","what":"Python and Matlab/Octave Code","title":"Efficient Leave-One-Out Cross-Validation and WAIC for Bayesian Models","text":"Corresponding Python Matlab/Octave code can found avehtari/PSIS repository.","code":""},{"path":"https://mc-stan.org/loo/dev/index.html","id":"contributing-to-loo","dir":"","previous_headings":"","what":"Contributing to loo","title":"Efficient Leave-One-Out Cross-Validation and WAIC for Bayesian Models","text":"Contributions welcome! loo active development pull requests always appreciated. Bugs, ideas (without implementations) noted opening issue. Please read CONTRIBUTING.md details.","code":""},{"path":"https://mc-stan.org/loo/dev/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Efficient Leave-One-Out Cross-Validation and WAIC for Bayesian Models","text":"code distributed GPL 3 license. documentation distributed CC 4.0 license.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/ap_psis.html","id":null,"dir":"Reference","previous_headings":"","what":"Pareto smoothed importance sampling (PSIS) using approximate posteriors — ap_psis","title":"Pareto smoothed importance sampling (PSIS) using approximate posteriors — ap_psis","text":"Pareto smoothed importance sampling (PSIS) using approximate posteriors","code":""},{"path":"https://mc-stan.org/loo/dev/reference/ap_psis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pareto smoothed importance sampling (PSIS) using approximate posteriors — ap_psis","text":"","code":"ap_psis(log_ratios, log_p, log_g, ...)  # S3 method for class 'array' ap_psis(log_ratios, log_p, log_g, ..., cores = getOption(\"mc.cores\", 1))  # S3 method for class 'matrix' ap_psis(log_ratios, log_p, log_g, ..., cores = getOption(\"mc.cores\", 1))  # Default S3 method ap_psis(log_ratios, log_p, log_g, ...)"},{"path":"https://mc-stan.org/loo/dev/reference/ap_psis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pareto smoothed importance sampling (PSIS) using approximate posteriors — ap_psis","text":"log_ratios log-likelihood ratios (ie -log_liks) log_p log-posterior (target) evaluated S samples proposal distribution (g). vector length S. log_g log-density (proposal) evaluated S samples proposal distribution (g). vector length S. ... Currently use. cores number cores use parallelization. defaults option mc.cores can set entire R session options(mc.cores = NUMBER). old option loo.cores now deprecated given precedence mc.cores loo.cores removed future release. version 2.0.0 default now 1 core mc.cores set, recommend using many (close many) cores possible. Note Windows 10 users: strongly recommended avoid using .Rprofile file set mc.cores (using cores argument setting mc.cores interactively script fine).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/ap_psis.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Pareto smoothed importance sampling (PSIS) using approximate posteriors — ap_psis","text":"ap_psis(array): \\(\\) \\(C\\) \\(N\\) array, \\(\\) number MCMC iterations per chain, \\(C\\) number chains, \\(N\\) number data points. ap_psis(matrix): \\(S\\) \\(N\\) matrix, \\(S\\) size posterior sample (chains merged) \\(N\\) number data points. ap_psis(default): vector length \\(S\\) (posterior sample size).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/compare.html","id":null,"dir":"Reference","previous_headings":"","what":"Model comparison (deprecated, old version) — compare","title":"Model comparison (deprecated, old version) — compare","text":"function deprecated. Please use new loo_compare() function instead.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model comparison (deprecated, old version) — compare","text":"","code":"compare(..., x = list())"},{"path":"https://mc-stan.org/loo/dev/reference/compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model comparison (deprecated, old version) — compare","text":"... least two objects returned loo() (waic()). x list least two objects returned loo() (waic()). argument can used alternative specifying objects ....","code":""},{"path":"https://mc-stan.org/loo/dev/reference/compare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model comparison (deprecated, old version) — compare","text":"vector matrix class 'compare.loo' print method. exactly two objects provided ... x, difference expected predictive accuracy standard error difference returned. two objects provided matrix summary information returned (see Details).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/compare.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model comparison (deprecated, old version) — compare","text":"comparing two fitted models, can estimate difference expected predictive accuracy difference elpd_loo elpd_waic (multiplied -2, desired, deviance scale). difference, elpd_diff, positive expected predictive accuracy second model higher. negative elpd_diff favors first model. using compare() two models, values elpd_diff se_diff columns returned matrix computed making pairwise comparisons model model best ELPD (.e., model first row). Although elpd_diff column equal difference elpd_loo, expect se_diff column equal difference se_elpd_loo. compute standard error difference ELPD use paired estimate take advantage fact set N data points used fit models. calculations useful N large, non-normality distribution issue estimating uncertainty sums. standard errors, flaws, give better sense uncertainty obtained using current standard approach comparing differences deviances Chi-squared distribution, practice derived Gaussian linear models asymptotically, applies nested models case.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/compare.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Model comparison (deprecated, old version) — compare","text":"Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. doi:10.1007/s11222-016-9696-4 (journal version, preprint arXiv:1507.04544). Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF","code":""},{"path":"https://mc-stan.org/loo/dev/reference/compare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model comparison (deprecated, old version) — compare","text":"","code":"# \\dontrun{ loo1 <- loo(log_lik1) #> Error: object 'log_lik1' not found loo2 <- loo(log_lik2) #> Error: object 'log_lik2' not found print(compare(loo1, loo2), digits = 3) #> Warning: 'compare' is deprecated. #> Use 'loo_compare' instead. #> See help(\"Deprecated\") #> Error: object 'loo1' not found print(compare(x = list(loo1, loo2))) #> Warning: 'compare' is deprecated. #> Use 'loo_compare' instead. #> See help(\"Deprecated\") #> Error: object 'loo1' not found  waic1 <- waic(log_lik1) #> Error: object 'log_lik1' not found waic2 <- waic(log_lik2) #> Error: object 'log_lik2' not found compare(waic1, waic2) #> Warning: 'compare' is deprecated. #> Use 'loo_compare' instead. #> See help(\"Deprecated\") #> Error: object 'waic1' not found # }"},{"path":"https://mc-stan.org/loo/dev/reference/crps.html","id":null,"dir":"Reference","previous_headings":"","what":"Continuously ranked probability score — crps","title":"Continuously ranked probability score — crps","text":"crps() scrps() functions loo_*() counterparts can used compute continuously ranked probability score (CRPS) scaled CRPS (SCRPS) (see Bolin Wallin, 2022). CRPS proper scoring rule, strictly proper first moment predictive distribution finite. can expressed terms samples form predictive distribution. See e.g. Gneiting Raftery (2007) comprehensive discussion CRPS.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/crps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Continuously ranked probability score — crps","text":"","code":"crps(x, ...)  scrps(x, ...)  loo_crps(x, ...)  loo_scrps(x, ...)  # S3 method for class 'matrix' crps(x, x2, y, ..., permutations = 1)  # S3 method for class 'numeric' crps(x, x2, y, ..., permutations = 1)  # S3 method for class 'matrix' loo_crps(   x,   x2,   y,   log_lik,   ...,   permutations = 1,   r_eff = 1,   cores = getOption(\"mc.cores\", 1) )  # S3 method for class 'matrix' scrps(x, x2, y, ..., permutations = 1)  # S3 method for class 'numeric' scrps(x, x2, y, ..., permutations = 1)  # S3 method for class 'matrix' loo_scrps(   x,   x2,   y,   log_lik,   ...,   permutations = 1,   r_eff = 1,   cores = getOption(\"mc.cores\", 1) )"},{"path":"https://mc-stan.org/loo/dev/reference/crps.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Continuously ranked probability score — crps","text":"x S N matrix (draws observations), vector length S single observation provided y. ... Passed E_loo() loo_*() version functions. x2 Independent draws distribution draws x. identical dimension. y vector observations single value. permutations integer, default value 1,  specifying many times expected value  |X - X'| (|x - x2|) computed. row order x2 shuffled elements x x2 typically drawn given values parameters. happens, e.g., one calls posterior_predict() twice fitted rstanarm brms model. Generating permutations expected decrease variance computed expected value. log_lik log-likelihood matrix size x. r_eff optional vector relative effective sample size estimates containing one element per observation. See psis() details. cores number cores use parallelization [psis()]. See psis() details.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/crps.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Continuously ranked probability score — crps","text":"list containing two elements: estimates pointwise. former reports estimator standard error latter pointwise values.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/crps.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Continuously ranked probability score — crps","text":"compute (S)CRPS, user needs provide two sets draws, x x2, predictive distribution. due fact formulas used compute CRPS involve expectation absolute difference x x2, distribution. See permutations argument, well Gneiting Raftery (2007) details.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/crps.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Continuously ranked probability score — crps","text":"Bolin, D., & Wallin, J. (2022). Local scale invariance robustness proper scoring rules. arXiv. doi:10.48550/arXiv.1912.05642 Gneiting, T., & Raftery, . E. (2007). Strictly Proper Scoring Rules, Prediction, Estimation. Journal American Statistical Association, 102(477), 359–378.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/crps.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Continuously ranked probability score — crps","text":"","code":"# \\dontrun{ # An example using rstanarm library(rstanarm) #> Loading required package: Rcpp #> This is rstanarm version 2.32.1 #> - See https://mc-stan.org/rstanarm/articles/priors for changes to default priors! #> - Default priors may change, so it's safest to specify priors, even if equivalent to the defaults. #> - For execution on a local, multicore CPU with excess RAM we recommend calling #>   options(mc.cores = parallel::detectCores()) data(\"kidiq\") fit <- stan_glm(kid_score ~ mom_hs + mom_iq, data = kidiq) #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 6.9e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.69 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.034 seconds (Warm-up) #> Chain 1:                0.046 seconds (Sampling) #> Chain 1:                0.08 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 1.2e-05 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.027 seconds (Warm-up) #> Chain 2:                0.046 seconds (Sampling) #> Chain 2:                0.073 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 1.2e-05 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.025 seconds (Warm-up) #> Chain 3:                0.046 seconds (Sampling) #> Chain 3:                0.071 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 1e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.032 seconds (Warm-up) #> Chain 4:                0.046 seconds (Sampling) #> Chain 4:                0.078 seconds (Total) #> Chain 4:  ypred1 <- posterior_predict(fit) ypred2 <- posterior_predict(fit) crps(ypred1, ypred2, y = fit$y) #> $estimates #>    Estimate          SE  #> -10.2113280   0.3452861  #>  #> $pointwise #>          1          2          3          4          5          6          7  #> -25.080998  -9.451630  -7.032505  -4.834308 -20.617540  -6.942011 -30.410739  #>          8          9         10         11         12         13         14  #>  -4.622516 -15.728789  -6.015832  -6.120895 -17.965870  -4.135782 -10.868082  #>         15         16         17         18         19         20         21  #> -11.680704  -6.878199  -4.659481  -4.667273  -4.279419 -12.222031  -5.814171  #>         22         23         24         25         26         27         28  #>  -7.011771  -7.756119  -4.452176 -11.286533  -4.546946  -9.108771  -5.755004  #>         29         30         31         32         33         34         35  #>  -4.397575  -4.322560 -15.417102 -30.924763  -6.923233 -11.297619  -5.325440  #>         36         37         38         39         40         41         42  #>  -9.684736 -12.989320  -4.709808  -5.833868 -18.577356 -10.284927  -5.737035  #>         43         44         45         46         47         48         49  #>  -7.891967  -4.148946 -19.538492  -5.847880 -24.919441  -4.835943 -18.245044  #>         50         51         52         53         54         55         56  #>  -5.014193  -6.324553  -5.802155 -20.251630 -14.511835  -5.258031  -8.571707  #>         57         58         59         60         61         62         63  #>  -6.011356  -5.131186  -5.337120  -5.468727  -9.193302  -8.718036  -4.603999  #>         64         65         66         67         68         69         70  #>  -5.972276 -22.462436 -25.077824 -13.463871  -4.316185  -5.014923  -5.371786  #>         71         72         73         74         75         76         77  #>  -6.140999  -5.108479  -4.396792 -14.618315 -11.886201 -16.339281  -4.292753  #>         78         79         80         81         82         83         84  #>  -4.475025 -19.881915  -4.774612 -12.161977 -15.516494  -8.436998 -10.294111  #>         85         86         87         88         89         90         91  #>  -6.398166  -4.639109 -35.451736  -5.777562  -4.438445  -7.827445  -6.953254  #>         92         93         94         95         96         97         98  #>  -9.863674  -8.428302  -4.989248 -11.780545  -4.740869  -4.598697  -5.952982  #>         99        100        101        102        103        104        105  #> -14.146896 -16.215742  -5.298148 -15.577882 -10.838004  -4.882596  -8.920022  #>        106        107        108        109        110        111        112  #>  -4.660786 -13.726284  -7.467925  -5.592099  -8.204212 -29.887276 -12.544108  #>        113        114        115        116        117        118        119  #> -26.820106  -7.806140  -5.399127  -4.895657 -24.751682 -29.900656  -4.947918  #>        120        121        122        123        124        125        126  #> -15.636202 -11.804218  -5.297550  -4.643541  -4.796901 -19.425815 -13.473973  #>        127        128        129        130        131        132        133  #>  -9.972911  -5.708829  -4.372449  -9.173817 -23.824115  -9.024591  -5.858332  #>        134        135        136        137        138        139        140  #>  -5.448083  -7.352588 -27.687587 -12.650962  -8.367683  -4.261944  -6.659672  #>        141        142        143        144        145        146        147  #>  -4.332135  -4.736795  -4.283087  -5.504850  -4.327135  -4.124078  -6.614462  #>        148        149        150        151        152        153        154  #> -22.795625 -15.096653 -12.868187  -5.111096 -29.034212  -4.475638  -9.149121  #>        155        156        157        158        159        160        161  #>  -9.042017  -4.244817  -7.247188  -7.523779  -9.836598  -4.949749  -5.918175  #>        162        163        164        165        166        167        168  #>  -7.016222  -5.840061  -5.859026  -5.044104  -8.074171  -8.630319  -4.453102  #>        169        170        171        172        173        174        175  #> -16.021092  -7.031835  -4.977188  -5.403745  -5.542130  -7.436551 -12.193586  #>        176        177        178        179        180        181        182  #>  -4.121067  -4.606587  -6.392982  -5.281779  -4.714082  -5.314728  -5.332651  #>        183        184        185        186        187        188        189  #>  -4.403049 -14.467408 -19.598250 -14.637617  -4.765937 -20.642758  -4.328793  #>        190        191        192        193        194        195        196  #>  -9.810997  -8.410184  -4.163801  -7.091897  -6.789304  -7.376336  -4.808048  #>        197        198        199        200        201        202        203  #>  -7.174566 -11.291893  -7.052485  -4.249686  -5.062316  -4.913684  -7.236253  #>        204        205        206        207        208        209        210  #>  -4.158237  -8.227878  -7.565504  -7.426899  -4.449874 -15.860040  -4.552797  #>        211        212        213        214        215        216        217  #>  -7.830361 -13.561837 -38.876603 -18.775062 -11.486260  -7.182914  -6.180782  #>        218        219        220        221        222        223        224  #>  -8.350578  -4.615153  -6.252668  -7.890597 -23.563690  -4.753762  -5.208956  #>        225        226        227        228        229        230        231  #>  -5.629749  -4.530473  -4.791798  -6.681882 -15.707852 -10.053890  -4.963071  #>        232        233        234        235        236        237        238  #>  -4.033396  -8.686277  -6.845777  -6.242358  -4.345950  -7.751851  -4.240597  #>        239        240        241        242        243        244        245  #>  -4.427453  -6.035207  -4.469124 -20.851362  -4.176149 -13.481150  -6.941415  #>        246        247        248        249        250        251        252  #> -15.661092  -4.593300 -26.300410  -7.434373  -4.965382  -5.165929  -8.038316  #>        253        254        255        256        257        258        259  #> -11.422060  -4.797534  -4.241954  -5.737511 -10.964576 -11.033162  -8.554696  #>        260        261        262        263        264        265        266  #>  -4.507626  -5.278355  -6.865963  -6.981914 -14.530247  -6.370278  -6.236394  #>        267        268        269        270        271        272        273  #>  -5.902551 -21.563674 -19.371569  -8.657527  -4.625383 -27.529753 -42.736602  #>        274        275        276        277        278        279        280  #> -10.400026  -5.801339  -7.857526 -16.327973  -4.402325 -17.402581  -5.938908  #>        281        282        283        284        285        286        287  #> -13.894295 -19.641677 -22.116919  -4.259192  -4.300118 -42.809457 -18.622280  #>        288        289        290        291        292        293        294  #> -22.193746  -4.524162 -17.796680  -9.409902 -11.090451 -21.927040  -5.606374  #>        295        296        297        298        299        300        301  #>  -7.870535 -22.247621  -4.757671 -17.544938  -7.544863 -14.977608  -5.579995  #>        302        303        304        305        306        307        308  #> -22.763600  -4.560955  -5.857795  -4.246768  -4.382081 -36.260821  -5.734173  #>        309        310        311        312        313        314        315  #>  -4.599692 -29.039712 -11.846338 -30.050540 -11.495183  -4.564480  -4.610358  #>        316        317        318        319        320        321        322  #>  -4.223167  -5.607621  -6.729745  -9.731792  -6.921288  -4.937925  -4.526542  #>        323        324        325        326        327        328        329  #> -12.273722 -18.001459  -8.522588  -8.973992  -6.970929 -26.747082  -4.434134  #>        330        331        332        333        334        335        336  #>  -5.967421  -4.296045 -18.847237 -27.024160 -15.108723  -6.845622 -12.336727  #>        337        338        339        340        341        342        343  #> -15.243157 -19.648375  -9.019229  -6.462288 -21.313791  -4.497504 -12.403348  #>        344        345        346        347        348        349        350  #>  -4.218086 -17.475992 -16.227100 -28.515420 -17.317732  -5.379848  -6.991371  #>        351        352        353        354        355        356        357  #>  -9.603393 -10.107897 -11.334036  -4.212355 -20.630253 -26.179888 -15.912360  #>        358        359        360        361        362        363        364  #> -19.765824  -4.247855  -5.464218  -4.492617 -10.579909  -4.611649  -4.570584  #>        365        366        367        368        369        370        371  #> -11.292585  -4.315309 -13.123810 -30.390611 -11.857469  -4.528244  -8.796184  #>        372        373        374        375        376        377        378  #>  -4.323948  -8.967097  -4.911669 -15.163639 -16.297513 -18.376531  -4.252610  #>        379        380        381        382        383        384        385  #>  -4.561836  -6.698356 -13.671719  -9.111586  -7.572393 -10.324509 -11.426053  #>        386        387        388        389        390        391        392  #> -13.057291 -10.867718  -4.681080  -5.719465  -9.951926  -8.989932  -5.197236  #>        393        394        395        396        397        398        399  #> -19.474684 -20.648603  -4.035167  -5.192236 -21.074978 -24.003179  -4.271056  #>        400        401        402        403        404        405        406  #>  -6.704670  -4.309987  -4.346449  -5.953599  -4.437362 -14.174036  -5.560304  #>        407        408        409        410        411        412        413  #> -16.451202  -5.126825 -27.273763  -3.736663  -4.194992 -12.696201  -9.696706  #>        414        415        416        417        418        419        420  #>  -4.751436  -6.375112  -7.037680  -4.102974 -18.212686  -4.778871 -17.787461  #>        421        422        423        424        425        426        427  #> -19.081260  -4.715740 -11.785169 -10.041032 -23.516472  -3.926584  -4.628795  #>        428        429        430        431        432        433        434  #>  -7.156882 -16.368853 -12.770441  -5.864849 -20.097189  -4.398931  -7.945911  #>  loo_crps(ypred1, ypred2, y = fit$y, log_lik = log_lik(fit)) #> $estimates #>    Estimate          SE  #> -10.2796379   0.3492078  #>  #> $pointwise #>   [1] -25.455753  -9.658418  -7.012824  -4.733712 -20.846625  -7.182662 #>   [7] -31.215385  -4.628825 -15.783705  -6.014386  -6.129374 -18.069126 #>  [13]  -4.456137 -10.965099 -11.921909  -6.800941  -4.728823  -4.507756 #>  [19]  -4.467576 -12.592056  -5.786442  -7.009465  -7.704315  -4.626119 #>  [25] -11.341323  -4.449888  -9.073814  -5.873776  -4.320621  -4.288847 #>  [31] -15.530269 -31.202270  -6.803574 -11.439905  -5.196075  -9.788992 #>  [37] -13.044350  -4.799147  -6.151699 -18.708444 -10.273446  -5.840672 #>  [43]  -7.821913  -4.158862 -20.059783  -5.830327 -25.262492  -4.721983 #>  [49] -18.452987  -4.723074  -6.222021  -5.979402 -20.183387 -14.623008 #>  [55]  -5.264010  -8.686336  -6.063654  -5.068455  -5.224969  -5.676744 #>  [61]  -8.940471  -8.861075  -4.544586  -6.209771 -22.731764 -24.918821 #>  [67] -13.429586  -4.288627  -5.150959  -5.461970  -6.036364  -5.103178 #>  [73]  -4.536679 -14.766538 -11.932726 -16.293863  -4.262667  -4.415211 #>  [79] -19.980126  -4.826051 -12.278658 -15.716559  -8.672152 -10.406474 #>  [85]  -6.332828  -4.657532 -35.933193  -5.878789  -4.346938  -7.833743 #>  [91]  -6.729302  -9.782092  -8.363304  -5.326565 -11.925477  -4.845458 #>  [97]  -4.314592  -6.126474 -14.290697 -16.396048  -5.378384 -15.586449 #> [103] -10.896704  -5.026903  -8.950818  -4.621924 -13.660579  -7.612048 #> [109]  -5.794312  -8.414950 -30.312137 -12.506898 -26.834743  -7.833108 #> [115]  -5.644532  -4.921191 -24.678256 -30.230612  -4.745589 -15.935290 #> [121] -11.738820  -5.331332  -4.596059  -4.654801 -19.443971 -13.691252 #> [127]  -9.963675  -5.725553  -4.437595  -9.332408 -23.980367  -8.972226 #> [133]  -6.142320  -5.512834  -7.327477 -28.206330 -12.960975  -8.345328 #> [139]  -4.185593  -6.559731  -4.397819  -4.559091  -4.337658  -5.750916 #> [145]  -4.342824  -4.412741  -6.583738 -22.930929 -15.348680 -13.168345 #> [151]  -5.151926 -29.360199  -4.365580  -9.089601  -9.149383  -4.137144 #> [157]  -7.127787  -7.589994  -9.748960  -4.935924  -5.920890  -7.173087 #> [163]  -5.938478  -6.011918  -5.112068  -8.036265  -8.572916  -4.596314 #> [169] -16.413479  -6.926466  -4.804001  -5.569136  -5.784432  -7.399526 #> [175] -12.357116  -4.077970  -4.374981  -6.127870  -5.148251  -4.703815 #> [181]  -5.305467  -5.259976  -4.219317 -14.352280 -19.905185 -14.631507 #> [187]  -4.870604 -20.817683  -4.197105  -9.809568  -8.418171  -4.360083 #> [193]  -7.229761  -7.127471  -7.700063  -5.127424  -7.212281 -11.686330 #> [199]  -7.082284  -4.025404  -5.036205  -5.138808  -7.186800  -4.236139 #> [205]  -8.475287  -7.757120  -7.299187  -4.695598 -15.944018  -4.555124 #> [211]  -7.982843 -13.550811 -39.743748 -18.599238 -11.631618  -7.036285 #> [217]  -6.078186  -8.472417  -4.622418  -6.266159  -8.031620 -23.789264 #> [223]  -4.905590  -5.269281  -5.492323  -4.633603  -4.814640  -6.646302 #> [229] -15.591585 -10.100774  -5.049970  -4.076007  -8.683545  -6.823836 #> [235]  -6.593626  -4.375189  -7.705831  -4.252371  -4.463133  -5.905571 #> [241]  -4.604391 -21.016280  -4.104514 -13.572307  -6.986990 -15.882828 #> [247]  -4.462817 -26.440369  -7.386119  -4.989670  -5.445504  -8.212745 #> [253] -11.207217  -4.849611  -4.177930  -5.698470 -11.053119 -11.253395 #> [259]  -8.720740  -4.420830  -5.284163  -7.007109  -7.003676 -14.824397 #> [265]  -6.436150  -6.316500  -6.108248 -21.590342 -19.855473  -8.669839 #> [271]  -4.328182 -27.840302 -43.046038 -10.331497  -5.980800  -7.923257 #> [277] -16.410092  -4.133029 -17.545236  -5.971919 -13.756730 -19.827489 #> [283] -22.313154  -4.065414  -4.392677 -43.103276 -18.636969 -22.080179 #> [289]  -4.521098 -17.968976  -9.530832 -11.185150 -22.221755  -5.566805 #> [295]  -7.672534 -22.396989  -4.714487 -17.696675  -7.705987 -15.113407 #> [301]  -5.448139 -23.018059  -4.493355  -5.973562  -4.353693  -4.447346 #> [307] -36.388177  -5.815195  -4.465974 -29.607213 -11.936291 -30.209173 #> [313] -11.352301  -4.650765  -4.457449  -4.201531  -5.820073  -6.710326 #> [319]  -9.616163  -6.780469  -5.170553  -4.594193 -12.457013 -18.199613 #> [325]  -8.349009  -8.961120  -7.045585 -26.743120  -4.588973  -6.000488 #> [331]  -4.319547 -18.908724 -27.342736 -15.323849  -6.856582 -12.437558 #> [337] -15.404300 -19.940909  -8.937237  -6.289998 -21.367168  -4.563387 #> [343] -12.392630  -4.149504 -17.726893 -16.444145 -29.091585 -17.284693 #> [349]  -5.480653  -7.279224  -9.562158 -10.053389 -11.491672  -4.336304 #> [355] -20.703801 -26.509800 -15.972133 -20.233898  -4.309954  -5.447642 #> [361]  -4.356426 -10.637745  -4.411632  -4.731482 -11.321587  -4.316495 #> [367] -13.082167 -30.789027 -11.955995  -4.358868  -8.681127  -4.328482 #> [373]  -8.931525  -4.771905 -15.272582 -16.368869 -18.403111  -4.335686 #> [379]  -4.417030  -6.718160 -13.541803  -9.340345  -7.442118 -10.318295 #> [385] -11.662897 -13.131656 -10.735863  -4.753335  -5.773108 -10.153661 #> [391]  -8.901151  -5.348945 -19.629140 -20.939506  -3.970254  -5.373141 #> [397] -21.204061 -24.053170  -4.451357  -6.608635  -4.266231  -4.151057 #> [403]  -5.961571  -4.381530 -14.319324  -5.693749 -16.461220  -5.167442 #> [409] -27.369134  -3.969379  -4.132610 -12.671810  -9.927297  -4.778575 #> [415]  -6.548745  -7.008327  -4.220765 -18.276775  -4.759848 -18.066941 #> [421] -19.218994  -4.723577 -11.934159 -10.046107 -24.174956  -4.083224 #> [427]  -4.648706  -7.255464 -16.547110 -12.901084  -5.777781 -20.211708 #> [433]  -4.231769  -7.995680 #>  # }"},{"path":"https://mc-stan.org/loo/dev/reference/dot-compute_point_estimate.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute a point estimate from a draws object — .compute_point_estimate","title":"Compute a point estimate from a draws object — .compute_point_estimate","text":"Compute point estimate draws object","code":""},{"path":"https://mc-stan.org/loo/dev/reference/dot-compute_point_estimate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute a point estimate from a draws object — .compute_point_estimate","text":"","code":".compute_point_estimate(draws)  # S3 method for class 'matrix' .compute_point_estimate(draws)  # Default S3 method .compute_point_estimate(draws)"},{"path":"https://mc-stan.org/loo/dev/reference/dot-compute_point_estimate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute a point estimate from a draws object — .compute_point_estimate","text":"draws draws object draws posterior.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/dot-compute_point_estimate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute a point estimate from a draws object — .compute_point_estimate","text":"1 P matrix point estimates draws object.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/dot-compute_point_estimate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute a point estimate from a draws object — .compute_point_estimate","text":"generic function compute point estimates draws objects. function internal used developers enable loo_subsample() arbitrary draws objects.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/dot-ndraws.html","id":null,"dir":"Reference","previous_headings":"","what":"The number of posterior draws in a draws object. — .ndraws","title":"The number of posterior draws in a draws object. — .ndraws","text":"number posterior draws draws object.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/dot-ndraws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The number of posterior draws in a draws object. — .ndraws","text":"","code":".ndraws(x)  # S3 method for class 'matrix' .ndraws(x)  # Default S3 method .ndraws(x)"},{"path":"https://mc-stan.org/loo/dev/reference/dot-ndraws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The number of posterior draws in a draws object. — .ndraws","text":"x draws object posterior draws.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/dot-ndraws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The number of posterior draws in a draws object. — .ndraws","text":"integer number draws.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/dot-ndraws.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"The number of posterior draws in a draws object. — .ndraws","text":"generic function return total number draws arbitrary draws objects. function internal used developers enable loo_subsample() arbitrary draws objects.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/dot-thin_draws.html","id":null,"dir":"Reference","previous_headings":"","what":"Thin a draws object — .thin_draws","title":"Thin a draws object — .thin_draws","text":"Thin draws object","code":""},{"path":"https://mc-stan.org/loo/dev/reference/dot-thin_draws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Thin a draws object — .thin_draws","text":"","code":".thin_draws(draws, loo_approximation_draws)  # S3 method for class 'matrix' .thin_draws(draws, loo_approximation_draws)  # S3 method for class 'numeric' .thin_draws(draws, loo_approximation_draws)  # Default S3 method .thin_draws(draws, loo_approximation_draws)"},{"path":"https://mc-stan.org/loo/dev/reference/dot-thin_draws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Thin a draws object — .thin_draws","text":"draws draws object posterior draws. loo_approximation_draws number posterior draws return (ie thinning).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/dot-thin_draws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Thin a draws object — .thin_draws","text":"thinned draws object.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/dot-thin_draws.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Thin a draws object — .thin_draws","text":"generic function thin draws arbitrary draws objects. function internal used developers enable loo_subsample() arbitrary draws objects.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/elpd.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic (expected) log-predictive density — elpd","title":"Generic (expected) log-predictive density — elpd","text":"elpd() methods arrays matrices can compute expected log pointwise predictive density new dataset log pointwise predictive density observed data (overestimate elpd).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/elpd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic (expected) log-predictive density — elpd","text":"","code":"elpd(x, ...)  # S3 method for class 'array' elpd(x, ...)  # S3 method for class 'matrix' elpd(x, ...)"},{"path":"https://mc-stan.org/loo/dev/reference/elpd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic (expected) log-predictive density — elpd","text":"x log-likelihood array matrix. Methods (class) section, , detailed descriptions specify inputs method. ... Currently ignored.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/elpd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generic (expected) log-predictive density — elpd","text":"elpd() function S3 generic methods provided 3-D pointwise log-likelihood arrays matrices.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/elpd.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Generic (expected) log-predictive density — elpd","text":"elpd(array): \\(\\) \\(C\\) \\(N\\) array, \\(\\) number MCMC iterations per chain, \\(C\\) number chains, \\(N\\) number data points. elpd(matrix): \\(S\\) \\(N\\) matrix, \\(S\\) size posterior sample (chains merged) \\(N\\) number data points.","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/elpd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generic (expected) log-predictive density — elpd","text":"","code":"# Calculate the lpd of the observed data LLarr <- example_loglik_array() elpd(LLarr) #>  #> Computed from 1000 by 32 log-likelihood matrix using the generic elpd function #>  #>      Estimate  SE #> elpd    -80.3 3.2 #> ic      160.5 6.5"},{"path":"https://mc-stan.org/loo/dev/reference/example_loglik_array.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects to use in examples and tests — example_loglik_array","title":"Objects to use in examples and tests — example_loglik_array","text":"Example pointwise log-likelihood objects use demonstrations tests. See Value Examples sections .","code":""},{"path":"https://mc-stan.org/loo/dev/reference/example_loglik_array.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Objects to use in examples and tests — example_loglik_array","text":"","code":"example_loglik_array()  example_loglik_matrix()"},{"path":"https://mc-stan.org/loo/dev/reference/example_loglik_array.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Objects to use in examples and tests — example_loglik_array","text":"example_loglik_array() returns 500 (draws) x 2 (chains) x 32 (observations) pointwise log-likelihood array. example_loglik_matrix() returns pointwise log-likelihood values example_loglik_array() reshaped 1000 (draws*chains) x 32 (observations) matrix.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/example_loglik_array.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Objects to use in examples and tests — example_loglik_array","text":"","code":"LLarr <- example_loglik_array() (dim_arr <- dim(LLarr)) #> [1] 500   2  32 LLmat <- example_loglik_matrix() (dim_mat <- dim(LLmat)) #> [1] 1000   32  all.equal(dim_mat[1], dim_arr[1] * dim_arr[2]) #> [1] TRUE all.equal(dim_mat[2], dim_arr[3]) #> [1] TRUE  all.equal(LLarr[, 1, ], LLmat[1:500, ]) #> [1] TRUE all.equal(LLarr[, 2, ], LLmat[501:1000, ]) #> [1] TRUE"},{"path":"https://mc-stan.org/loo/dev/reference/extract_log_lik.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract pointwise log-likelihood from a Stan model — extract_log_lik","title":"Extract pointwise log-likelihood from a Stan model — extract_log_lik","text":"Convenience function extracting pointwise log-likelihood matrix array stanfit object rstan package. Note: recent versions rstan now include loo() method stanfit objects handles internally.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/extract_log_lik.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract pointwise log-likelihood from a Stan model — extract_log_lik","text":"","code":"extract_log_lik(stanfit, parameter_name = \"log_lik\", merge_chains = TRUE)"},{"path":"https://mc-stan.org/loo/dev/reference/extract_log_lik.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract pointwise log-likelihood from a Stan model — extract_log_lik","text":"stanfit stanfit object (rstan package). parameter_name character string naming parameter (generated quantity) Stan model corresponding log-likelihood. merge_chains TRUE (default), Markov chains merged together (.e., stacked) matrix returned. FALSE kept separate array returned.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/extract_log_lik.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract pointwise log-likelihood from a Stan model — extract_log_lik","text":"merge_chains=TRUE, \\(S\\) \\(N\\) matrix (post-warmup) extracted draws, \\(S\\) size posterior sample \\(N\\) number data points. merge_chains=FALSE, \\(\\) \\(C\\) \\(N\\) array, \\(\\times C = S\\).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/extract_log_lik.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract pointwise log-likelihood from a Stan model — extract_log_lik","text":"Stan automatically compute store log-likelihood. user incorporate Stan program extracted fitting model. Stan model, pointwise log likelihood can coded vector transformed parameters block (summed model block) can coded entirely generated quantities block. recommend using generated quantities block computations carried per iteration rather per HMC leapfrog step. example, following generated quantities block computing saving log-likelihood linear regression model N data points, outcome y, predictor matrix X, coefficients beta, standard deviation sigma: vector[N] log_lik; (n 1:N) log_lik[n] = normal_lpdf(y[n] | X[n, ] * beta, sigma);","code":""},{"path":"https://mc-stan.org/loo/dev/reference/extract_log_lik.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Extract pointwise log-likelihood from a Stan model — extract_log_lik","text":"Stan Development Team (2017). Stan C++ Library, Version 2.16.0. https://mc-stan.org/ Stan Development Team (2017). RStan: R interface Stan, Version 2.16.1. https://mc-stan.org/","code":""},{"path":"https://mc-stan.org/loo/dev/reference/E_loo.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute weighted expectations — E_loo","title":"Compute weighted expectations — E_loo","text":"E_loo() function computes weighted expectations (means, variances, quantiles) using importance weights obtained PSIS smoothing procedure. expectations estimated E_loo() function assume PSIS approximation working well. small Pareto k estimate necessary, sufficient, E_loo() give reliable estimates. Additional diagnostic checks gauging reliability estimates development added future release.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/E_loo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute weighted expectations — E_loo","text":"","code":"E_loo(x, psis_object, ...)  # Default S3 method E_loo(   x,   psis_object,   ...,   type = c(\"mean\", \"variance\", \"sd\", \"quantile\"),   probs = NULL,   log_ratios = NULL )  # S3 method for class 'matrix' E_loo(   x,   psis_object,   ...,   type = c(\"mean\", \"variance\", \"sd\", \"quantile\"),   probs = NULL,   log_ratios = NULL )"},{"path":"https://mc-stan.org/loo/dev/reference/E_loo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute weighted expectations — E_loo","text":"x numeric vector matrix. psis_object object returned psis(). ... Arguments passed individual methods. type type expectation compute. options \"mean\", \"variance\", \"sd\", \"quantile\". probs computing quantiles, vector probabilities. log_ratios Optionally, vector matrix (dimensions x) raw (smoothed) log ratios. working log-likelihood values, log ratios negative values. log_ratios specified able compute accurate Pareto k diagnostics specific E_loo().","code":""},{"path":"https://mc-stan.org/loo/dev/reference/E_loo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute weighted expectations — E_loo","text":"named list following components: value result computation. matrix method, value vector ncol(x) elements, one exception: type=\"quantile\" multiple values specified probs value component returned object length(probs) ncol(x) matrix. default/vector method value component scalar, one exception: type=\"quantile\" multiple values specified probs value component vector length(probs) elements. pareto_k Function-specific diagnostic. matrix method vector length ncol(x) containing estimates shape parameter \\(k\\) generalized Pareto distribution. default/vector method, estimate scalar. log_ratios specified calling E_loo(), smoothed log-weights used estimate Pareto-k's, may produce optimistic estimates. type=\"mean\", type=\"var\", type=\"sd\", returned Pareto-k usually maximum Pareto-k's left right tail \\(hr\\) right tail \\(r\\), \\(r\\) importance ratio \\(h=x\\) type=\"mean\" \\(h=x^2\\) type=\"var\" type=\"sd\". \\(h\\) binary, constant, finite, type=\"quantile\", returned Pareto-k Pareto-k right tail \\(r\\).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/E_loo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute weighted expectations — E_loo","text":"","code":"# \\donttest{ if (requireNamespace(\"rstanarm\", quietly = TRUE)) { # Use rstanarm package to quickly fit a model and get both a log-likelihood # matrix and draws from the posterior predictive distribution library(\"rstanarm\")  # data from help(\"lm\") ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14) trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69) d <- data.frame(   weight = c(ctl, trt),   group = gl(2, 10, 20, labels = c(\"Ctl\",\"Trt\")) ) fit <- stan_glm(weight ~ group, data = d, refresh = 0) yrep <- posterior_predict(fit) dim(yrep)  log_ratios <- -1 * log_lik(fit) dim(log_ratios)  r_eff <- relative_eff(exp(-log_ratios), chain_id = rep(1:4, each = 1000)) psis_object <- psis(log_ratios, r_eff = r_eff, cores = 2)  E_loo(yrep, psis_object, type = \"mean\") E_loo(yrep, psis_object, type = \"var\") E_loo(yrep, psis_object, type = \"sd\") E_loo(yrep, psis_object, type = \"quantile\", probs = 0.5) # median E_loo(yrep, psis_object, type = \"quantile\", probs = c(0.1, 0.9))  # We can get more accurate Pareto k diagnostic if we also provide # the log_ratios argument E_loo(yrep, psis_object, type = \"mean\", log_ratios = log_ratios) } #> $value #>  [1] 5.138343 4.977074 5.003910 4.934799 5.106227 5.054057 5.021758 5.107148 #>  [9] 4.986780 5.021601 4.632789 4.738509 4.695477 4.788853 4.492651 4.763751 #> [17] 4.500139 4.636341 4.704360 4.677666 #>  #> $pareto_k #>  [1]  0.233399989  0.073664298  0.117702427  0.328056902  0.180429212 #>  [6]  0.150664794 -0.023508396  0.161947959  0.102910565  0.006427037 #> [11]  0.090717927  0.230447557  0.232173035  0.413687601  0.332522606 #> [16]  0.341583757  0.469863165  0.143520946  0.252265048  0.065325564 #>  # }"},{"path":"https://mc-stan.org/loo/dev/reference/find_model_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the model names associated with ","title":"Find the model names associated with ","text":"Find model names associated \"loo\" objects","code":""},{"path":"https://mc-stan.org/loo/dev/reference/find_model_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the model names associated with ","text":"","code":"find_model_names(x)"},{"path":"https://mc-stan.org/loo/dev/reference/find_model_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the model names associated with ","text":"x List \"loo\" objects.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/find_model_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the model names associated with ","text":"Character vector model names length x.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/gpdfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate parameters of the Generalized Pareto distribution — gpdfit","title":"Estimate parameters of the Generalized Pareto distribution — gpdfit","text":"Given sample \\(x\\), Estimate parameters \\(k\\) \\(\\sigma\\) generalized Pareto distribution (GPD), assuming location parameter 0. default fit uses prior \\(k\\), stabilize estimates small sample sizes (low effective sample sizes case MCMC samples). weakly informative prior Gaussian prior centered 0.5.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/gpdfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate parameters of the Generalized Pareto distribution — gpdfit","text":"","code":"gpdfit(x, wip = TRUE, min_grid_pts = 30, sort_x = TRUE)"},{"path":"https://mc-stan.org/loo/dev/reference/gpdfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate parameters of the Generalized Pareto distribution — gpdfit","text":"x numeric vector. sample estimate parameters. wip Logical indicating whether adjust \\(k\\) based weakly informative Gaussian prior centered 0.5. Defaults TRUE. min_grid_pts minimum number grid points used fitting algorithm. actual number used min_grid_pts + floor(sqrt(length(x))). sort_x TRUE (default), first step fitting algorithm sort elements x. x already sorted ascending order sort_x can set FALSE skip initial sorting step.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/gpdfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate parameters of the Generalized Pareto distribution — gpdfit","text":"named list components k sigma.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/gpdfit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate parameters of the Generalized Pareto distribution — gpdfit","text":"parameter \\(k\\) negative \\(k\\) Zhang & Stephens (2009).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/gpdfit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate parameters of the Generalized Pareto distribution — gpdfit","text":"Zhang, J., Stephens, M. . (2009). new efficient estimation method generalized Pareto distribution. Technometrics 51, 316-325.","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/importance_sampling.html","id":null,"dir":"Reference","previous_headings":"","what":"A parent class for different importance sampling methods. — importance_sampling","title":"A parent class for different importance sampling methods. — importance_sampling","text":"parent class different importance sampling methods.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/importance_sampling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A parent class for different importance sampling methods. — importance_sampling","text":"","code":"importance_sampling(log_ratios, method, ...)  # S3 method for class 'array' importance_sampling(   log_ratios,   method,   ...,   r_eff = 1,   cores = getOption(\"mc.cores\", 1) )  # S3 method for class 'matrix' importance_sampling(   log_ratios,   method,   ...,   r_eff = 1,   cores = getOption(\"mc.cores\", 1) )  # Default S3 method importance_sampling(log_ratios, method, ..., r_eff = 1)"},{"path":"https://mc-stan.org/loo/dev/reference/importance_sampling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A parent class for different importance sampling methods. — importance_sampling","text":"log_ratios array, matrix, vector importance ratios log scale (PSIS-LOO negative log-likelihood values). See Methods (class) section detailed description specify inputs method. method importance sampling method use. following methods implemented: \"psis\": Pareto-Smoothed Importance Sampling (PSIS). Default method. \"tis\": Truncated Importance Sampling (TIS) truncation sqrt(S), S number posterior draws. \"sis\": Standard Importance Sampling (SIS). ... Arguments passed various methods. r_eff Vector relative effective sample size estimates containing one element per observation. values provided relative effective sample sizes 1/exp(log_ratios) (.e., 1/ratios). related relative efficiency estimating normalizing term self-normalizing importance sampling. r_eff provided reported PSIS effective sample sizes Monte Carlo error estimates can -optimistic. posterior draws (near) independent r_eff=1 can used. r_eff scalar (value used observations) vector length equal number observations. default value 1. See relative_eff() helper function computing r_eff. cores number cores use parallelization. defaults option mc.cores can set entire R session options(mc.cores = NUMBER). old option loo.cores now deprecated given precedence mc.cores loo.cores removed future release. version 2.0.0 default now 1 core mc.cores set, recommend using many (close many) cores possible. Note Windows 10 users: strongly recommended avoid using .Rprofile file set mc.cores (using cores argument setting mc.cores interactively script fine).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/kfold-generic.html","id":null,"dir":"Reference","previous_headings":"","what":"Generic function for K-fold cross-validation for developers — kfold-generic","title":"Generic function for K-fold cross-validation for developers — kfold-generic","text":"developers Bayesian modeling packages, loo includes generic function kfold() methods may defined K-fold CV without name conflicts packages. See, example, kfold() methods rstanarm brms packages. Value section describes objects kfold() methods return order compatible loo_compare() loo package print methods.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/kfold-generic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generic function for K-fold cross-validation for developers — kfold-generic","text":"","code":"kfold(x, ...)  is.kfold(x)"},{"path":"https://mc-stan.org/loo/dev/reference/kfold-generic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generic function for K-fold cross-validation for developers — kfold-generic","text":"x fitted model object. ... Arguments pass specific methods.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/kfold-generic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generic function for K-fold cross-validation for developers — kfold-generic","text":"developers defining kfold() method class \"foo\", kfold.foo() function return list class c(\"kfold\", \"loo\") least following named elements: \"estimates\": 1x2 matrix containing ELPD estimate standard error. matrix must row name \"elpd_kfold\" column names \"Estimate\" \"SE\". \"pointwise\": Nx1 matrix column name \"elpd_kfold\" containing pointwise contributions data point. important object least classes components compatible functions like loo_compare() print() methods.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/kfold-helpers.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper functions for K-fold cross-validation — kfold-helpers","title":"Helper functions for K-fold cross-validation — kfold-helpers","text":"functions can used generate indexes use K-fold cross-validation. See Details section explanations.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/kfold-helpers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper functions for K-fold cross-validation — kfold-helpers","text":"","code":"kfold_split_random(K = 10, N = NULL)  kfold_split_stratified(K = 10, x = NULL)  kfold_split_grouped(K = 10, x = NULL)"},{"path":"https://mc-stan.org/loo/dev/reference/kfold-helpers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper functions for K-fold cross-validation — kfold-helpers","text":"K number folds use. N number observations data. x discrete variable length N least K levels (unique values). coerced factor.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/kfold-helpers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper functions for K-fold cross-validation — kfold-helpers","text":"integer vector length N element index 1:K.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/kfold-helpers.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Helper functions for K-fold cross-validation — kfold-helpers","text":"kfold_split_random() splits data K groups equal size (roughly equal size). categorical variable x kfold_split_stratified() splits observations K groups ensuring relative category frequencies approximately preserved. grouping variable x, kfold_split_grouped() places observations x group/level together fold. selection groups/levels go fold (relevant groups folds) randomized.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/kfold-helpers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Helper functions for K-fold cross-validation — kfold-helpers","text":"","code":"ids <- kfold_split_random(K = 5, N = 20) print(ids) #>  [1] 2 3 1 1 4 3 2 5 4 4 5 2 1 4 3 5 1 5 3 2 table(ids) #> ids #> 1 2 3 4 5  #> 4 4 4 4 4    x <- sample(c(0, 1), size = 200, replace = TRUE, prob = c(0.05, 0.95)) table(x) #> x #>   0   1  #>  10 190  ids <- kfold_split_stratified(K = 5, x = x) print(ids) #>   [1] 5 4 5 5 5 3 5 3 1 5 3 2 2 1 2 3 2 5 5 2 5 4 4 1 1 4 5 4 2 4 4 4 5 1 5 2 1 #>  [38] 2 5 5 4 1 4 2 1 2 1 3 3 1 1 2 3 5 2 2 1 2 3 1 2 1 3 3 1 4 3 1 1 4 4 1 5 4 #>  [75] 1 5 5 5 4 4 3 3 5 5 3 5 2 4 1 5 3 1 5 5 3 5 5 5 4 4 2 2 3 3 2 2 4 1 5 4 2 #> [112] 1 4 5 3 5 1 3 4 2 5 1 1 1 2 3 3 2 5 4 5 4 2 5 2 2 3 1 3 2 3 2 1 1 3 2 1 1 #> [149] 2 1 2 4 4 4 3 4 4 4 3 2 2 3 2 3 2 1 1 4 2 4 5 3 3 3 3 1 4 2 5 4 3 5 4 5 3 #> [186] 3 1 1 3 1 4 2 4 5 3 4 3 2 4 1 table(ids, x) #>    x #> ids  0  1 #>   1  2 38 #>   2  2 38 #>   3  2 38 #>   4  2 38 #>   5  2 38  grp <- gl(n = 50, k = 15, labels = state.name) length(grp) #> [1] 750 head(table(grp)) #> grp #>    Alabama     Alaska    Arizona   Arkansas California   Colorado  #>         15         15         15         15         15         15   ids_10 <- kfold_split_grouped(K = 10, x = grp) (tab_10 <- table(grp, ids_10)) #>                 ids_10 #> grp               1  2  3  4  5  6  7  8  9 10 #>   Alabama         0  0 15  0  0  0  0  0  0  0 #>   Alaska          0  0  0  0  0  0 15  0  0  0 #>   Arizona         0  0  0  0  0  0 15  0  0  0 #>   Arkansas        0 15  0  0  0  0  0  0  0  0 #>   California      0  0  0  0  0  0  0  0  0 15 #>   Colorado        0  0  0  0  0  0 15  0  0  0 #>   Connecticut     0  0  0  0 15  0  0  0  0  0 #>   Delaware        0  0  0  0  0  0  0 15  0  0 #>   Florida         0  0  0  0 15  0  0  0  0  0 #>   Georgia        15  0  0  0  0  0  0  0  0  0 #>   Hawaii          0  0  0 15  0  0  0  0  0  0 #>   Idaho           0  0  0  0  0  0  0  0  0 15 #>   Illinois        0  0 15  0  0  0  0  0  0  0 #>   Indiana        15  0  0  0  0  0  0  0  0  0 #>   Iowa            0 15  0  0  0  0  0  0  0  0 #>   Kansas          0 15  0  0  0  0  0  0  0  0 #>   Kentucky        0  0  0  0  0  0  0  0  0 15 #>   Louisiana       0  0  0 15  0  0  0  0  0  0 #>   Maine           0  0  0  0  0  0  0  0  0 15 #>   Maryland       15  0  0  0  0  0  0  0  0  0 #>   Massachusetts   0  0  0  0  0  0 15  0  0  0 #>   Michigan       15  0  0  0  0  0  0  0  0  0 #>   Minnesota       0  0  0 15  0  0  0  0  0  0 #>   Mississippi     0  0 15  0  0  0  0  0  0  0 #>   Missouri        0  0  0  0  0  0  0 15  0  0 #>   Montana         0  0  0  0  0 15  0  0  0  0 #>   Nebraska        0  0  0  0 15  0  0  0  0  0 #>   Nevada          0  0  0  0  0 15  0  0  0  0 #>   New Hampshire   0  0  0  0  0  0  0 15  0  0 #>   New Jersey      0  0  0  0  0  0 15  0  0  0 #>   New Mexico      0  0  0  0  0 15  0  0  0  0 #>   New York        0  0  0 15  0  0  0  0  0  0 #>   North Carolina  0  0  0  0  0 15  0  0  0  0 #>   North Dakota    0  0  0  0  0  0  0  0 15  0 #>   Ohio            0 15  0  0  0  0  0  0  0  0 #>   Oklahoma        0  0  0  0  0 15  0  0  0  0 #>   Oregon          0  0  0  0  0  0  0  0 15  0 #>   Pennsylvania    0  0  0 15  0  0  0  0  0  0 #>   Rhode Island    0  0 15  0  0  0  0  0  0  0 #>   South Carolina  0  0  0  0  0  0  0 15  0  0 #>   South Dakota    0  0 15  0  0  0  0  0  0  0 #>   Tennessee       0  0  0  0  0  0  0 15  0  0 #>   Texas           0  0  0  0 15  0  0  0  0  0 #>   Utah            0  0  0  0  0  0  0  0 15  0 #>   Vermont         0  0  0  0 15  0  0  0  0  0 #>   Virginia        0  0  0  0  0  0  0  0  0 15 #>   Washington     15  0  0  0  0  0  0  0  0  0 #>   West Virginia   0  0  0  0  0  0  0  0 15  0 #>   Wisconsin       0  0  0  0  0  0  0  0 15  0 #>   Wyoming         0 15  0  0  0  0  0  0  0  0 colSums(tab_10) #>  1  2  3  4  5  6  7  8  9 10  #> 75 75 75 75 75 75 75 75 75 75   ids_9 <- kfold_split_grouped(K = 9, x = grp) (tab_9 <- table(grp, ids_9)) #>                 ids_9 #> grp               1  2  3  4  5  6  7  8  9 #>   Alabama         0 15  0  0  0  0  0  0  0 #>   Alaska          0  0  0 15  0  0  0  0  0 #>   Arizona         0  0  0  0  0  0  0  0 15 #>   Arkansas        0  0  0  0  0  0  0 15  0 #>   California      0  0  0  0  0  0  0  0 15 #>   Colorado       15  0  0  0  0  0  0  0  0 #>   Connecticut     0  0 15  0  0  0  0  0  0 #>   Delaware        0  0  0  0  0  0  0 15  0 #>   Florida         0  0  0  0 15  0  0  0  0 #>   Georgia         0  0  0 15  0  0  0  0  0 #>   Hawaii         15  0  0  0  0  0  0  0  0 #>   Idaho           0  0  0  0  0 15  0  0  0 #>   Illinois        0  0  0  0 15  0  0  0  0 #>   Indiana         0  0  0 15  0  0  0  0  0 #>   Iowa            0  0 15  0  0  0  0  0  0 #>   Kansas          0  0 15  0  0  0  0  0  0 #>   Kentucky        0  0 15  0  0  0  0  0  0 #>   Louisiana       0  0  0  0 15  0  0  0  0 #>   Maine           0  0  0  0  0  0 15  0  0 #>   Maryland        0  0  0  0  0  0  0  0 15 #>   Massachusetts   0 15  0  0  0  0  0  0  0 #>   Michigan        0  0  0  0  0  0 15  0  0 #>   Minnesota       0 15  0  0  0  0  0  0  0 #>   Mississippi    15  0  0  0  0  0  0  0  0 #>   Missouri        0  0  0  0 15  0  0  0  0 #>   Montana         0  0  0  0  0  0 15  0  0 #>   Nebraska        0  0 15  0  0  0  0  0  0 #>   Nevada          0 15  0  0  0  0  0  0  0 #>   New Hampshire   0  0 15  0  0  0  0  0  0 #>   New Jersey      0  0  0  0  0  0  0  0 15 #>   New Mexico      0  0  0  0  0  0 15  0  0 #>   New York        0  0  0  0  0 15  0  0  0 #>   North Carolina  0  0  0  0 15  0  0  0  0 #>   North Dakota    0  0  0  0  0  0  0 15  0 #>   Ohio            0  0  0  0  0 15  0  0  0 #>   Oklahoma        0  0  0  0  0 15  0  0  0 #>   Oregon          0  0  0 15  0  0  0  0  0 #>   Pennsylvania   15  0  0  0  0  0  0  0  0 #>   Rhode Island   15  0  0  0  0  0  0  0  0 #>   South Carolina  0 15  0  0  0  0  0  0  0 #>   South Dakota    0  0  0  0  0  0  0  0 15 #>   Tennessee       0  0  0  0  0 15  0  0  0 #>   Texas           0  0  0 15  0  0  0  0  0 #>   Utah            0  0  0  0  0  0 15  0  0 #>   Vermont         0  0  0  0 15  0  0  0  0 #>   Virginia       15  0  0  0  0  0  0  0  0 #>   Washington      0  0  0  0  0  0  0 15  0 #>   West Virginia   0 15  0  0  0  0  0  0  0 #>   Wisconsin       0  0  0  0  0  0  0 15  0 #>   Wyoming         0  0  0 15  0  0  0  0  0 colSums(tab_9) #>  1  2  3  4  5  6  7  8  9  #> 90 90 90 90 90 75 75 75 75"},{"path":"https://mc-stan.org/loo/dev/reference/loo-datasets.html","id":null,"dir":"Reference","previous_headings":"","what":"Datasets for loo examples and vignettes — loo-datasets","title":"Datasets for loo examples and vignettes — loo-datasets","text":"Small datasets use loo examples vignettes. Kline milk datasets also included rethinking package (McElreath, 2016a), include rethinking CRAN.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo-datasets.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Datasets for loo examples and vignettes — loo-datasets","text":"Currently data sets included : Kline: Small dataset Kline Boyd (2010) tool complexity demography Oceanic islands societies. data discussed detail McElreath (2016a,2016b). (Link variable descriptions) milk: Small dataset Hinde Milligan (2011) primate milk composition.data discussed detail McElreath (2016a,2016b). (Link variable descriptions) voice: Voice rehabilitation data Tsanas et al. (2014).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo-datasets.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Datasets for loo examples and vignettes — loo-datasets","text":"Hinde Milligan. 2011. Evolutionary Anthropology 20:9-23. Kline, M.. R. Boyd. 2010. Proc R Soc B 277:2559-2564. McElreath, R. (2016a). rethinking: Statistical Rethinking book package. R package version 1.59. McElreath, R. (2016b). Statistical rethinking: Bayesian course examples R Stan. Chapman & Hall/CRC. . Tsanas, M.. Little, C. Fox, L.O. Ramig: Objective automatic assessment rehabilitative speech treatment Parkinson's disease, IEEE Transactions Neural Systems Rehabilitation Engineering, Vol. 22, pp. 181-190, January 2014","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo-datasets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Datasets for loo examples and vignettes — loo-datasets","text":"","code":"str(Kline) #> 'data.frame':\t10 obs. of  5 variables: #>  $ culture    : Factor w/ 10 levels \"Chuuk\",\"Hawaii\",..: 4 7 6 10 3 9 1 5 8 2 #>  $ population : int  1100 1500 3600 4791 7400 8000 9200 13000 17500 275000 #>  $ contact    : Factor w/ 2 levels \"high\",\"low\": 2 2 2 1 1 1 1 2 1 2 #>  $ total_tools: int  13 22 24 43 33 19 40 28 55 71 #>  $ mean_TU    : num  3.2 4.7 4 5 5 4 3.8 6.6 5.4 6.6 str(milk) #> 'data.frame':\t29 obs. of  8 variables: #>  $ clade         : Factor w/ 4 levels \"Ape\",\"New World Monkey\",..: 4 4 4 4 4 2 2 2 2 2 ... #>  $ species       : Factor w/ 29 levels \"A palliata\",\"Alouatta seniculus\",..: 11 8 9 10 16 2 1 6 28 27 ... #>  $ kcal.per.g    : num  0.49 0.51 0.46 0.48 0.6 0.47 0.56 0.89 0.91 0.92 ... #>  $ perc.fat      : num  16.6 19.3 14.1 14.9 27.3 ... #>  $ perc.protein  : num  15.4 16.9 16.9 13.2 19.5 ... #>  $ perc.lactose  : num  68 63.8 69 71.9 53.2 ... #>  $ mass          : num  1.95 2.09 2.51 1.62 2.19 5.25 5.37 2.51 0.71 0.68 ... #>  $ neocortex.perc: num  55.2 NA NA NA NA ..."},{"path":"https://mc-stan.org/loo/dev/reference/loo-glossary.html","id":null,"dir":"Reference","previous_headings":"","what":"LOO package glossary — loo-glossary","title":"LOO package glossary — loo-glossary","text":"pages provides definitions key terms. Also see FAQ page loo website answers frequently asked questions. Note: VGG2017 refers Vehtari, Gelman, Gabry (2017). See References, .","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo-glossary.html","id":"elpd-and-elpd-loo","dir":"Reference","previous_headings":"","what":"ELPD and elpd_loo","title":"LOO package glossary — loo-glossary","text":"ELPD theoretical expected log pointwise predictive density new dataset (Eq 1 VGG2017), can estimated, e.g., using cross-validation. elpd_loo Bayesian LOO estimate expected log pointwise predictive density (Eq 4 VGG2017) sum N individual pointwise log predictive densities. Probability densities can smaller larger 1, thus log predictive densities can negative positive. simplicity ELPD acronym used also expected log pointwise predictive probabilities discrete models. Probabilities always equal less 1, thus log predictive probabilities 0 negative.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo-glossary.html","id":"standard-error-of-elpd-loo","dir":"Reference","previous_headings":"","what":"Standard error of elpd_loo","title":"LOO package glossary — loo-glossary","text":"elpd_loo defined sum N independent components (Eq 4 VGG2017), can compute standard error using standard deviation N components multiplying sqrt(N) (Eq 23 VGG2017). standard error coarse description uncertainty predictive performance unknown future data. N small severe model misspecification, current SE estimate overoptimistic actual SE can even twice large. Even moderate N, SE estimate accurate estimate scale, ignores skewness. making model comparisons, SE component-wise (pairwise) differences used instead (see se_diff section Eq 24 VGG2017). Sivula et al. (2022) discuss conditions normal approximation used SE se_diff good.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo-glossary.html","id":"monte-carlo-se-of-elpd-loo","dir":"Reference","previous_headings":"","what":"Monte Carlo SE of elpd_loo","title":"LOO package glossary — loo-glossary","text":"Monte Carlo standard error estimate computational accuracy MCMC importance sampling used compute elpd_loo. Usually negligible compared standard describing uncertainty due finite number observations (Eq 23 VGG2017).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo-glossary.html","id":"p-loo-effective-number-of-parameters-","dir":"Reference","previous_headings":"","what":"p_loo (effective number of parameters)","title":"LOO package glossary — loo-glossary","text":"p_loo difference elpd_loo non-cross-validated log posterior predictive density. describes much difficult predict future data observed data. Asymptotically certain regularity conditions, p_loo can interpreted effective number parameters. well behaving cases p_loo < N p_loo < p, p total number parameters model. p_loo > N  p_loo > p indicates model weak predictive capability may indicate severe model misspecification. See interpreting p_loo warnings high Pareto k diagnostic values.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo-glossary.html","id":"pareto-k-estimates","dir":"Reference","previous_headings":"","what":"Pareto k estimates","title":"LOO package glossary — loo-glossary","text":"Pareto \\(k\\) estimate diagnostic Pareto smoothed importance sampling (PSIS), used compute components elpd_loo. importance-sampling LOO full posterior distribution used proposal distribution. Pareto k diagnostic estimates far individual leave-one-distribution full distribution. leaving observation changes posterior much importance sampling able give reliable estimate. Pareto smoothing stabilizes importance sampling guarantees finite variance estimate cost bias. diagnostic threshold Pareto \\(k\\) depends sample size \\(S\\) (sample size dependent threshold introduced Vehtari et al., 2024, fixed thresholds 0.5 0.7 recommended). simplicity, loo package uses nominal sample size \\(S\\)  computing sample size specific threshold. provides optimistic threshold effective sample size less 2200, even ESS/S > 1/2 difference usually negligible. Thinning MCMC draws can used improve ratio ESS/S. \\(k < \\min(1 - 1 / \\log_{10}(S), 0.7)\\), \\(S\\) sample size, PSIS estimate corresponding Monte Carlo standard error estimate reliable. \\(1 - 1 / \\log_{10}(S) <= k < 0.7\\), PSIS estimate corresponding Monte Carlo standard error estimate reliable, increasing (effective) sample size \\(S\\) 2200 may help (increase sample size specific threshold \\((1 - 1 / \\log_{10}(2200) > 0.7\\) bias specific threshold 0.7 dominates). \\(0.7 <= k < 1\\), PSIS estimate corresponding Monte Carlo standard error large bias reliable. Increasing sample size may reduce variability \\(k\\) estimate, may also result lower \\(k\\) estimate. \\(k \\geq 1\\), target distribution estimated non-finite mean. PSIS estimate corresponding Monte Carlo standard error well defined. Increasing sample size may reduce variability \\(k\\) estimate, may also result lower \\(k\\) estimate. Pareto \\(k\\) also useful measure influence observation.  Highly influential observations high \\(k\\) values. high \\(k\\) values often indicate model misspecification, outliers mistakes data processing. See Section 6 Gabry et al. (2019) example.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo-glossary.html","id":"interpreting-p-loo-when-pareto-k-is-large","dir":"Reference","previous_headings":"","what":"Interpreting p_loo when Pareto k is large","title":"LOO package glossary — loo-glossary","text":"\\(k > 0.7\\) can also look p_loo estimate additional information problem: p_loo << p (total number parameters model), model likely misspecified. Posterior predictive checks (PPCs) likely also detect problem. Try using overdispersed model, add structural information (nonlinearity, mixture model, etc.). p_loo < p number parameters p relatively large compared number observations (e.g., p>N/5), likely model flexible population prior weak ’s difficult predict left observation (even true model). happens, example, simulated 8 schools (VGG2017), random effect models observations per random effect, Gaussian processes spatial models short correlation lengths. p_loo > p, model likely badly misspecified. number parameters p<<N, PPCs also likely detect problem. See case study https://avehtari.github.io/modelselection/roaches.html example. p relatively large compared number observations, say p>N/5 (accurately count number observations influencing parameter hierarchical models groups may observations groups many), possible PPCs detect problem.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo-glossary.html","id":"elpd-diff","dir":"Reference","previous_headings":"","what":"elpd_diff","title":"LOO package glossary — loo-glossary","text":"elpd_diff difference elpd_loo two models. two models compared, difference computed relative model highest elpd_loo.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo-glossary.html","id":"se-diff","dir":"Reference","previous_headings":"","what":"se_diff","title":"LOO package glossary — loo-glossary","text":"standard error component-wise differences elpd_loo (Eq 24 VGG2017) two models. SE smaller SE individual models due correlation (.e., observations easier difficult predict models).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo-glossary.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"LOO package glossary — loo-glossary","text":"Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. doi:10.1007/s11222-016-9696-4 (journal version, preprint arXiv:1507.04544). Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF Sivula, T, Magnusson, M., Matamoros . ., Vehtari, . (2022).  Uncertainty Bayesian leave-one-cross-validation based model comparison. preprint arXiv:2008.10296v3.. Gabry, J. , Simpson, D. , Vehtari, . , Betancourt, M. Gelman, . (2019), Visualization Bayesian workflow. J. R. Stat. Soc. , 182: 389-402. doi:10.1111/rssa.12378 (journal version, preprint arXiv:1709.01449, code GitHub)","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo-package.html","id":null,"dir":"Reference","previous_headings":"","what":"Efficient LOO-CV and WAIC for Bayesian models — loo-package","title":"Efficient LOO-CV and WAIC for Bayesian models — loo-package","text":"Stan Development Team package implements methods described Vehtari, Gelman, Gabry (2017), Vehtari, Simpson, Gelman, Yao, Gabry (2024), Yao et al. (2018). get started see loo package vignettes, loo() function efficient approximate leave-one-cross-validation (LOO-CV), psis() function Pareto smoothed importance sampling (PSIS) algorithm, loo_model_weights() implementation Bayesian stacking predictive distributions multiple models.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Efficient LOO-CV and WAIC for Bayesian models — loo-package","text":"Leave-one-cross-validation (LOO-CV) widely applicable information criterion (WAIC) methods estimating pointwise --sample prediction accuracy fitted Bayesian model using log-likelihood evaluated posterior simulations parameter values. LOO-CV WAIC various advantages simpler estimates predictive error AIC DIC less used practice involve additional computational steps. package implements fast stable computations approximate LOO-CV laid Vehtari, Gelman, Gabry (2017). existing posterior simulation draws, compute LOO-CV using Pareto smoothed importance sampling (PSIS; Vehtari, Simpson, Gelman, Yao, Gabry, 2024), new procedure stabilizing diagnosing importance weights. byproduct calculations, also obtain approximate standard errors estimated predictive errors comparing predictive errors two models. recommend PSIS-LOO-CV instead WAIC, PSIS provides useful diagnostics effective sample size Monte Carlo standard error estimates.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Efficient LOO-CV and WAIC for Bayesian models — loo-package","text":"Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. doi:10.1007/s11222-016-9696-4 (journal version, preprint arXiv:1507.04544). Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF Yao, Y., Vehtari, ., Simpson, D., Gelman, . (2018) Using stacking average Bayesian predictive distributions. Bayesian Analysis, advance publication,  doi:10.1214/17-BA1091. (online). Magnusson, M., Riis Andersen, M., Jonasson, J. Vehtari, . (2019). Leave-One-Cross-Validation Large Data. Thirty-sixth International Conference Machine Learning, PMLR 97:4244-4253. Magnusson, M., Riis Andersen, M., Jonasson, J. Vehtari, . (2020). Leave-One-Cross-Validation Model Comparison Large Data. Proceedings 23rd International Conference Artificial Intelligence Statistics (AISTATS), PMLR 108:341-351. Epifani, ., MacEachern, S. N., Peruggia, M. (2008). Case-deletion importance sampling estimators: Central limit theorems related results. Electronic Journal Statistics 2, 774-806. Gelfand, . E. (1996). Model determination using sampling-based methods. Markov Chain Monte Carlo Practice, ed. W. R. Gilks, S. Richardson, D. J. Spiegelhalter, 145-162. London: Chapman Hall. Gelfand, . E., Dey, D. K., Chang, H. (1992). Model determination using predictive distributions implementation via sampling-based methods. Bayesian Statistics 4, ed. J. M. Bernardo, J. O. Berger, . P. Dawid, . F. M. Smith, 147-167. Oxford University Press. Gelman, ., Hwang, J., Vehtari, . (2014). Understanding predictive information criteria Bayesian models. Statistics Computing 24, 997-1016. Ionides, E. L. (2008). Truncated importance sampling. Journal Computational Graphical Statistics 17, 295-311. Koopman, S. J., Shephard, N., Creal, D. (2009). Testing assumptions behind importance sampling. Journal Econometrics 149, 2-11. Peruggia, M. (1997). variability case-deletion importance sampling weights Bayesian linear model. Journal American Statistical Association 92, 199-207. Stan Development Team (2017). Stan C++ Library, Version 2.17.0. https://mc-stan.org. Stan Development Team (2018). RStan: R interface Stan, Version 2.17.3. https://mc-stan.org. Watanabe, S. (2010). Asymptotic equivalence Bayes cross validation widely application information criterion singular learning theory. Journal Machine Learning Research 11, 3571-3594. Zhang, J., Stephens, M. . (2009). new efficient estimation method generalized Pareto distribution. Technometrics 51, 316-325.","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/loo-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Efficient LOO-CV and WAIC for Bayesian models — loo-package","text":"Maintainer: Jonah Gabry jsg2201@columbia.edu Authors: Aki Vehtari Aki.Vehtari@aalto.fi Måns Magnusson Yuling Yao Paul-Christian Bürkner Topi Paananen Andrew Gelman contributors: Ben Goodrich [contributor] Juho Piironen [contributor] Bruno Nicenboim [contributor] Leevi Lindgren [contributor]","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo.html","id":null,"dir":"Reference","previous_headings":"","what":"Efficient approximate leave-one-out cross-validation (LOO) — loo","title":"Efficient approximate leave-one-out cross-validation (LOO) — loo","text":"loo() methods arrays, matrices, functions compute PSIS-LOO CV, efficient approximate leave-one-(LOO) cross-validation Bayesian models using Pareto smoothed importance sampling (PSIS). implementation methods described Vehtari, Gelman, Gabry (2017) Vehtari, Simpson, Gelman, Yao, Gabry (2024). loo_i() function enables testing log-likelihood functions use loo.function() method.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Efficient approximate leave-one-out cross-validation (LOO) — loo","text":"","code":"loo(x, ...)  # S3 method for class 'array' loo(   x,   ...,   r_eff = 1,   save_psis = FALSE,   cores = getOption(\"mc.cores\", 1),   is_method = c(\"psis\", \"tis\", \"sis\") )  # S3 method for class 'matrix' loo(   x,   ...,   r_eff = 1,   save_psis = FALSE,   cores = getOption(\"mc.cores\", 1),   is_method = c(\"psis\", \"tis\", \"sis\") )  # S3 method for class '`function`' loo(   x,   ...,   data = NULL,   draws = NULL,   r_eff = 1,   save_psis = FALSE,   cores = getOption(\"mc.cores\", 1),   is_method = c(\"psis\", \"tis\", \"sis\") )  loo_i(i, llfun, ..., data = NULL, draws = NULL, r_eff = 1, is_method = \"psis\")  is.loo(x)  is.psis_loo(x)"},{"path":"https://mc-stan.org/loo/dev/reference/loo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Efficient approximate leave-one-out cross-validation (LOO) — loo","text":"x log-likelihood array, matrix, function. Methods (class) section, , detailed descriptions specify inputs method. r_eff Vector relative effective sample size estimates likelihood (exp(log_lik)) observation. related relative efficiency estimating normalizing term self-normalized importance sampling using posterior draws obtained MCMC. MCMC draws used r_eff provided reported PSIS effective sample sizes Monte Carlo error estimates can -optimistic. posterior draws (near) independent r_eff=1 can used. r_eff scalar (value used observations) vector length equal number observations. default value 1. See relative_eff() helper functions help computing r_eff. save_psis psis object created internally loo() saved returned object? loo() function calls psis() internally default discards (potentially large) psis object using compute LOO-CV summaries. Setting save_psis=TRUE add psis_object component list returned loo. useful plan use E_loo() function compute weighted expectations running loo. Several functions bayesplot package also accept psis objects. cores number cores use parallelization. defaults option mc.cores can set entire R session options(mc.cores = NUMBER). old option loo.cores now deprecated given precedence mc.cores loo.cores removed future release. version 2.0.0 default now 1 core mc.cores set, recommend using many (close many) cores possible. Note Windows 10 users: strongly recommended avoid using .Rprofile file set mc.cores (using cores argument setting mc.cores interactively script fine). is_method importance sampling method use. following methods implemented: \"psis\": Pareto-Smoothed Importance Sampling (PSIS). Default method. \"tis\": Truncated Importance Sampling (TIS) truncation sqrt(S), S number posterior draws. \"sis\": Standard Importance Sampling (SIS). data, draws, ... loo.function() method loo_i() function, data, posterior draws, arguments pass log-likelihood function. See Methods (class) section details specify arguments. loo_i(), integer 1:N. llfun loo_i(), x loo.function() method. log-likelihood function described Methods (class) section.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Efficient approximate leave-one-out cross-validation (LOO) — loo","text":"loo() methods return named list class c(\"psis_loo\", \"loo\") components: estimates matrix two columns (Estimate, SE) three rows (elpd_loo, p_loo, looic). contains point estimates standard errors expected log pointwise predictive density (elpd_loo), effective number parameters (p_loo) LOO information criterion looic (just -2 * elpd_loo, .e., converted deviance scale). pointwise matrix five columns (number rows equal number observations) containing pointwise contributions measures (elpd_loo, mcse_elpd_loo, p_loo, looic, influence_pareto_k). addition three measures estimates, also report pointwise values Monte Carlo standard error elpd_loo (mcse_elpd_loo), statistics describing influence observation posterior distribution (influence_pareto_k). estimates shape parameter \\(k\\) generalized Pareto fit importance ratios leave-one-distribution (see pareto-k-diagnostic page details). diagnostics named list containing two vectors: pareto_k: Importance sampling reliability diagnostics. default, equal influence_pareto_k pointwise. algorithms can improve importance sampling reliability modify diagnostics. See pareto-k-diagnostic page details. n_eff: PSIS effective sample size estimates. psis_object component NULL unless save_psis argument set TRUE calling loo(). case psis_object object class \"psis\" created loo() function calls psis() internally PSIS procedure. loo_i() function returns named list components pointwise diagnostics. components structure pointwise diagnostics components object returned loo() except contain results single observation.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Efficient approximate leave-one-out cross-validation (LOO) — loo","text":"loo() function S3 generic methods provided 3-D pointwise log-likelihood arrays, pointwise log-likelihood matrices, log-likelihood functions. array matrix methods convenient, models fit large datasets loo.function() method memory efficient may preferable.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Efficient approximate leave-one-out cross-validation (LOO) — loo","text":"loo(array): \\(\\) \\(C\\) \\(N\\) array, \\(\\) number MCMC iterations per chain, \\(C\\) number chains, \\(N\\) number data points. loo(matrix): \\(S\\) \\(N\\) matrix, \\(S\\) size posterior sample (chains merged) \\(N\\) number data points. loo(`function`): function f() takes arguments data_i draws returns vector containing log-likelihood single observation evaluated posterior draw. function written , observation 1:N, evaluating   results vector length S (size posterior sample). log-likelihood function can also additional arguments data_i draws required. using function method arguments data draws must also specified call loo(): data: data frame matrix containing data (e.g. observed outcome predictors) needed compute pointwise log-likelihood. observation , ith row data passed data_i argument log-likelihood function. draws: object containing posterior draws parameters needed compute pointwise log-likelihood. Unlike data, indexed observation, observation entire object draws passed draws argument log-likelihood function. ... can used log-likelihood function takes additional arguments. arguments used like draws argument recycled observation.","code":"f(data_i = data[i,, drop=FALSE], draws = draws)"},{"path":"https://mc-stan.org/loo/dev/reference/loo.html","id":"defining-loo-methods-in-a-package","dir":"Reference","previous_headings":"","what":"Defining loo() methods in a package","title":"Efficient approximate leave-one-out cross-validation (LOO) — loo","text":"Package developers can define loo() methods fitted models objects. See example loo.stanfit() method Examples section example defining method calls loo.array(). loo.stanreg() method rstanarm package example defining method calls loo.function().","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Efficient approximate leave-one-out cross-validation (LOO) — loo","text":"Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. doi:10.1007/s11222-016-9696-4 (journal version, preprint arXiv:1507.04544). Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/loo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Efficient approximate leave-one-out cross-validation (LOO) — loo","text":"","code":"### Array and matrix methods (using example objects included with loo package) # Array method LLarr <- example_loglik_array() rel_n_eff <- relative_eff(exp(LLarr)) loo(LLarr, r_eff = rel_n_eff, cores = 2) #>  #> Computed from 1000 by 32 log-likelihood matrix. #>  #>          Estimate  SE #> elpd_loo    -83.6 4.3 #> p_loo         3.3 1.2 #> looic       167.2 8.6 #> ------ #> MCSE of elpd_loo is 0.1. #> MCSE and ESS estimates assume MCMC draws (r_eff in [0.6, 1.0]). #>  #> All Pareto k estimates are good (k < 0.67). #> See help('pareto-k-diagnostic') for details.  # Matrix method LLmat <- example_loglik_matrix() rel_n_eff <- relative_eff(exp(LLmat), chain_id = rep(1:2, each = 500)) loo(LLmat, r_eff = rel_n_eff, cores = 2) #>  #> Computed from 1000 by 32 log-likelihood matrix. #>  #>          Estimate  SE #> elpd_loo    -83.6 4.3 #> p_loo         3.3 1.2 #> looic       167.2 8.6 #> ------ #> MCSE of elpd_loo is 0.1. #> MCSE and ESS estimates assume MCMC draws (r_eff in [0.6, 1.0]). #>  #> All Pareto k estimates are good (k < 0.67). #> See help('pareto-k-diagnostic') for details.   ### Using log-likelihood function instead of array or matrix set.seed(124)  # Simulate data and draw from posterior N <- 50; K <- 10; S <- 100; a0 <- 3; b0 <- 2 p <- rbeta(1, a0, b0) y <- rbinom(N, size = K, prob = p) a <- a0 + sum(y); b <- b0 + N * K - sum(y) fake_posterior <- as.matrix(rbeta(S, a, b)) dim(fake_posterior) # S x 1 #> [1] 100   1 fake_data <- data.frame(y,K) dim(fake_data) # N x 2 #> [1] 50  2  llfun <- function(data_i, draws) {   # each time called internally within loo the arguments will be equal to:   # data_i: ith row of fake_data (fake_data[i,, drop=FALSE])   # draws: entire fake_posterior matrix   dbinom(data_i$y, size = data_i$K, prob = draws, log = TRUE) }  # Use the loo_i function to check that llfun works on a single observation # before running on all obs. For example, using the 3rd obs in the data: loo_3 <- loo_i(i = 3, llfun = llfun, data = fake_data, draws = fake_posterior) print(loo_3$pointwise[, \"elpd_loo\"]) #>  elpd_loo  #> -1.267103   # Use loo.function method (default r_eff=1 is used as this posterior not obtained via MCMC) loo_with_fn <- loo(llfun, draws = fake_posterior, data = fake_data)  # If we look at the elpd_loo contribution from the 3rd obs it should be the # same as what we got above with the loo_i function and i=3: print(loo_with_fn$pointwise[3, \"elpd_loo\"]) #>  elpd_loo  #> -1.267103  print(loo_3$pointwise[, \"elpd_loo\"]) #>  elpd_loo  #> -1.267103   # Check that the loo.matrix method gives same answer as loo.function method log_lik_matrix <- sapply(1:N, function(i) {   llfun(data_i = fake_data[i,, drop=FALSE], draws = fake_posterior) }) loo_with_mat <- loo(log_lik_matrix) all.equal(loo_with_mat$estimates, loo_with_fn$estimates) # should be TRUE! #> [1] TRUE   # \\dontrun{ ### For package developers: defining loo methods  # An example of a possible loo method for 'stanfit' objects (rstan package). # A similar method is included in the rstan package. # In order for users to be able to call loo(stanfit) instead of # loo.stanfit(stanfit) the NAMESPACE needs to be handled appropriately # (roxygen2 and devtools packages are good for that). # loo.stanfit <-  function(x,          pars = \"log_lik\",          ...,          save_psis = FALSE,          cores = getOption(\"mc.cores\", 1)) {   stopifnot(length(pars) == 1L)   LLarray <- loo::extract_log_lik(stanfit = x,                                   parameter_name = pars,                                   merge_chains = FALSE)   r_eff <- loo::relative_eff(x = exp(LLarray), cores = cores)   loo::loo.array(LLarray,                  r_eff = r_eff,                  cores = cores,                  save_psis = save_psis) } # }"},{"path":"https://mc-stan.org/loo/dev/reference/loo_approximate_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Efficient approximate leave-one-out cross-validation (LOO) for posterior approximations — loo_approximate_posterior","title":"Efficient approximate leave-one-out cross-validation (LOO) for posterior approximations — loo_approximate_posterior","text":"Efficient approximate leave-one-cross-validation (LOO) posterior approximations","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_approximate_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Efficient approximate leave-one-out cross-validation (LOO) for posterior approximations — loo_approximate_posterior","text":"","code":"loo_approximate_posterior(x, log_p, log_g, ...)  # S3 method for class 'array' loo_approximate_posterior(   x,   log_p,   log_g,   ...,   save_psis = FALSE,   cores = getOption(\"mc.cores\", 1) )  # S3 method for class 'matrix' loo_approximate_posterior(   x,   log_p,   log_g,   ...,   save_psis = FALSE,   cores = getOption(\"mc.cores\", 1) )  # S3 method for class '`function`' loo_approximate_posterior(   x,   ...,   data = NULL,   draws = NULL,   log_p = NULL,   log_g = NULL,   save_psis = FALSE,   cores = getOption(\"mc.cores\", 1) )"},{"path":"https://mc-stan.org/loo/dev/reference/loo_approximate_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Efficient approximate leave-one-out cross-validation (LOO) for posterior approximations — loo_approximate_posterior","text":"x log-likelihood array, matrix, function. Methods (class) section, , detailed descriptions specify inputs method. log_p log-posterior (target) evaluated S samples proposal distribution (g). vector length S. log_g log-density (proposal) evaluated S samples proposal distribution (g). vector length S. save_psis \"psis\" object created internally loo_approximate_posterior() saved returned object? See loo() details. cores number cores use parallelization. defaults option mc.cores can set entire R session options(mc.cores = NUMBER). old option loo.cores now deprecated given precedence mc.cores loo.cores removed future release. version 2.0.0 default now 1 core mc.cores set, recommend using many (close many) cores possible. Note Windows 10 users: strongly recommended avoid using .Rprofile file set mc.cores (using cores argument setting mc.cores interactively script fine). data, draws, ... loo_approximate_posterior.function() method, data, posterior draws, arguments pass log-likelihood function. See Methods (class) section details specify arguments.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_approximate_posterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Efficient approximate leave-one-out cross-validation (LOO) for posterior approximations — loo_approximate_posterior","text":"loo_approximate_posterior() methods return named list class c(\"psis_loo_ap\", \"psis_loo\", \"loo\"). structure objects returned loo() additional slot: posterior_approximation list two vectors, log_p log_g length containing posterior density approximation density individual draws.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_approximate_posterior.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Efficient approximate leave-one-out cross-validation (LOO) for posterior approximations — loo_approximate_posterior","text":"loo_approximate_posterior() function S3 generic methods provided 3-D pointwise log-likelihood arrays, pointwise log-likelihood matrices, log-likelihood functions. implementation works posterior approximations possible compute log density posterior approximation.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_approximate_posterior.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Efficient approximate leave-one-out cross-validation (LOO) for posterior approximations — loo_approximate_posterior","text":"loo_approximate_posterior(array): \\(\\) \\(C\\) \\(N\\) array, \\(\\) number MCMC iterations per chain, \\(C\\) number chains, \\(N\\) number data points. loo_approximate_posterior(matrix): \\(S\\) \\(N\\) matrix, \\(S\\) size posterior sample (chains merged) \\(N\\) number data points. loo_approximate_posterior(`function`): function f() takes arguments data_i draws returns vector containing log-likelihood single observation evaluated posterior draw. function written , observation 1:N, evaluating   results vector length S (size posterior sample). log-likelihood function can also additional arguments data_i draws required. using function method arguments data draws must also specified call loo(): data: data frame matrix containing data (e.g. observed outcome predictors) needed compute pointwise log-likelihood. observation , ith row data passed data_i argument log-likelihood function. draws: object containing posterior draws parameters needed compute pointwise log-likelihood. Unlike data, indexed observation, observation entire object draws passed draws argument log-likelihood function. ... can used log-likelihood function takes additional arguments. arguments used like draws argument recycled observation.","code":"f(data_i = data[i,, drop=FALSE], draws = draws)"},{"path":"https://mc-stan.org/loo/dev/reference/loo_approximate_posterior.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Efficient approximate leave-one-out cross-validation (LOO) for posterior approximations — loo_approximate_posterior","text":"Magnusson, M., Riis Andersen, M., Jonasson, J. Vehtari, . (2019). Leave-One-Cross-Validation Large Data. Thirty-sixth International Conference Machine Learning, PMLR 97:4244-4253. Magnusson, M., Riis Andersen, M., Jonasson, J. Vehtari, . (2020). Leave-One-Cross-Validation Model Comparison Large Data. Proceedings 23rd International Conference Artificial Intelligence Statistics (AISTATS), PMLR 108:341-351.","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/loo_compare.html","id":null,"dir":"Reference","previous_headings":"","what":"Model comparison — loo_compare","title":"Model comparison — loo_compare","text":"Compare fitted models based ELPD. default print method shows important information. Use print(..., simplify=FALSE) print detailed summary.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model comparison — loo_compare","text":"","code":"loo_compare(x, ...)  # Default S3 method loo_compare(x, ...)  # S3 method for class 'compare.loo' print(x, ..., digits = 1, simplify = TRUE)  # S3 method for class 'compare.loo_ss' print(x, ..., digits = 1, simplify = TRUE)"},{"path":"https://mc-stan.org/loo/dev/reference/loo_compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model comparison — loo_compare","text":"x object class \"loo\" list objects. list used list names used model names output. See Examples. ... Additional objects class \"loo\", passed single list. digits print method , number digits use printing. simplify print method , essential columns summary matrix printed? entire matrix always returned, default important columns printed.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_compare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model comparison — loo_compare","text":"matrix class \"compare.loo\" print method. See Details section.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_compare.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model comparison — loo_compare","text":"comparing two fitted models, can estimate difference expected predictive accuracy difference elpd_loo elpd_waic (multiplied \\(-2\\), desired, deviance scale). using loo_compare(), returned matrix one row per model several columns estimates. values elpd_diff se_diff columns returned matrix computed making pairwise comparisons model model largest ELPD (model first row). reason elpd_diff column always value 0 first row (.e., difference preferred model ) negative values subsequent rows remaining models. compute standard error difference ELPD — expected equal difference standard errors — use paired estimate take advantage fact set \\(N\\) data points used fit models. calculations useful \\(N\\) large, non-normality distribution issue estimating uncertainty sums. standard errors, flaws, give better sense uncertainty obtained using current standard approach comparing differences deviances Chi-squared distribution, practice derived Gaussian linear models asymptotically, applies nested models case. Sivula et al. (2022) discuss conditions normal approximation used SE se_diff good. \\(11\\) models compared, internally recompute model differences using median model ELPD baseline model. estimate whether differences predictive performance potentially due chance described McLatchie Vehtari (2023). flag warning deemed risk -fitting due selection process. case users recommended avoid model selection based LOO-CV, instead favor model averaging/stacking projection predictive inference.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_compare.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Model comparison — loo_compare","text":"Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. doi:10.1007/s11222-016-9696-4 (journal version, preprint arXiv:1507.04544). Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF Sivula, T, Magnusson, M., Matamoros . ., Vehtari, . (2022). Uncertainty Bayesian leave-one-cross-validation based model comparison. preprint arXiv:2008.10296v3.. McLatchie, Y., Vehtari, . (2023).  Efficient estimation correction selection-induced bias order statistics. preprint arXiv:2309.03742","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/loo_compare.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model comparison — loo_compare","text":"","code":"# very artificial example, just for demonstration! LL <- example_loglik_array() loo1 <- loo(LL)     # should be worst model when compared loo2 <- loo(LL + 1) # should be second best model when compared loo3 <- loo(LL + 2) # should be best model when compared  comp <- loo_compare(loo1, loo2, loo3) print(comp, digits = 2) #>        elpd_diff se_diff #> model3   0.00      0.00  #> model2 -32.00      0.00  #> model1 -64.00      0.00   # show more details with simplify=FALSE # (will be the same for all models in this artificial example) print(comp, simplify = FALSE, digits = 3) #>        elpd_diff se_diff elpd_loo se_elpd_loo p_loo   se_p_loo looic   se_looic #> model3   0.000     0.000 -19.589    4.284       3.329   1.152   39.178   8.568  #> model2 -32.000     0.000 -51.589    4.284       3.329   1.152  103.178   8.568  #> model1 -64.000     0.000 -83.589    4.284       3.329   1.152  167.178   8.568   # can use a list of objects with custom names # will use apple, banana, and cherry, as the names in the output loo_compare(list(\"apple\" = loo1, \"banana\" = loo2, \"cherry\" = loo3)) #>        elpd_diff se_diff #> cherry   0.0       0.0   #> banana -32.0       0.0   #> apple  -64.0       0.0    # \\dontrun{ # works for waic (and kfold) too loo_compare(waic(LL), waic(LL - 10)) #> Warning:  #> 3 (9.4%) p_waic estimates greater than 0.4. We recommend trying loo instead. #> Warning:  #> 3 (9.4%) p_waic estimates greater than 0.4. We recommend trying loo instead. #>        elpd_diff se_diff #> model1    0.0       0.0  #> model2 -320.0       0.0  # }"},{"path":"https://mc-stan.org/loo/dev/reference/loo_model_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Model averaging/weighting via stacking or pseudo-BMA weighting — loo_model_weights","title":"Model averaging/weighting via stacking or pseudo-BMA weighting — loo_model_weights","text":"Model averaging via stacking predictive distributions, pseudo-BMA weighting pseudo-BMA+ weighting Bayesian bootstrap. See Yao et al. (2018), Vehtari, Gelman, Gabry (2017), Vehtari, Simpson, Gelman, Yao, Gabry (2024) background.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_model_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Model averaging/weighting via stacking or pseudo-BMA weighting — loo_model_weights","text":"","code":"loo_model_weights(x, ...)  # Default S3 method loo_model_weights(   x,   ...,   method = c(\"stacking\", \"pseudobma\"),   optim_method = \"BFGS\",   optim_control = list(),   BB = TRUE,   BB_n = 1000,   alpha = 1,   r_eff_list = NULL,   cores = getOption(\"mc.cores\", 1) )  stacking_weights(lpd_point, optim_method = \"BFGS\", optim_control = list())  pseudobma_weights(lpd_point, BB = TRUE, BB_n = 1000, alpha = 1)"},{"path":"https://mc-stan.org/loo/dev/reference/loo_model_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Model averaging/weighting via stacking or pseudo-BMA weighting — loo_model_weights","text":"x list \"psis_loo\" objects (objects returned loo()) pointwise log-likelihood matrices , one model. list elements named names used label models results. matrix/object dimensions \\(S\\) \\(N\\), \\(S\\) size posterior sample (chains merged) \\(N\\) number data points. x list log-likelihood matrices loo() called internally matrix. Currently loo_model_weights() function implemented used results K-fold CV, can still obtain weights using K-fold CV results calling stacking_weights() pseudobma_weights() function directly. ... Unused, except generic pass arguments individual methods. method Either \"stacking\" (default) \"pseudobma\", indicating method use obtaining weights. \"stacking\" refers stacking predictive distributions  \"pseudobma\" refers pseudo-BMA+ weighting (plain pseudo-BMA weighting argument BB FALSE). optim_method method=\"stacking\", string passed method argument stats::constrOptim() specify optimization algorithm. default optim_method=\"BFGS\", options available (see stats::optim()). optim_control method=\"stacking\", list control parameters optimization passed control argument stats::constrOptim(). BB Logical used \"method\"=\"pseudobma\". TRUE (default), Bayesian bootstrap used adjust pseudo-BMA weighting, called pseudo-BMA+ weighting. helps regularize weight away 0 1, reduce variance. BB_n pseudo-BMA+ weighting , number samples use Bayesian bootstrap. default BB_n=1000. alpha Positive scalar shape parameter Dirichlet distribution used Bayesian bootstrap. default alpha=1, corresponds uniform distribution simplex space. r_eff_list Optionally, list relative effective sample size estimates likelihood (exp(log_lik)) observation model. See psis()  relative_eff() helper function computing r_eff. x list \"psis_loo\" objects r_eff_list ignored. cores number cores use parallelization. defaults option mc.cores can set entire R session options(mc.cores = NUMBER). old option loo.cores now deprecated given precedence mc.cores loo.cores removed future release. version 2.0.0 default now 1 core mc.cores set, recommend using many (close many) cores possible. Note Windows 10 users: strongly recommended avoid using .Rprofile file set mc.cores (using cores argument setting mc.cores interactively script fine). lpd_point calling stacking_weights() pseudobma_weights() directly, matrix pointwise leave-one-(K-fold) log likelihoods evaluated different models. \\(N\\) \\(K\\)  matrix \\(N\\) sample size \\(K\\) number models. column corresponds one model. values can calculated approximately using loo() running exact leave-one-K-fold cross-validation.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_model_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Model averaging/weighting via stacking or pseudo-BMA weighting — loo_model_weights","text":"numeric vector containing one weight model.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_model_weights.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Model averaging/weighting via stacking or pseudo-BMA weighting — loo_model_weights","text":"loo_model_weights() wrapper around stacking_weights() pseudobma_weights() functions implements stacking, pseudo-BMA, pseudo-BMA+ weighting combining multiple predictive distributions. can use approximate exact leave-one-cross-validation (LOO-CV) K-fold CV estimate expected log predictive density (ELPD). stacking method (method=\"stacking\"), default loo_model_weights(), combines models maximizing leave-one-predictive density combination distribution. , finds optimal linear combining weights maximizing leave-one-log score. pseudo-BMA method (method=\"pseudobma\") finds relative weights proportional ELPD model. However, method=\"pseudobma\", default also use Bayesian bootstrap (BB=TRUE), corresponds pseudo-BMA+ method. Bayesian bootstrap  takes account uncertainty finite data points regularizes weights away extremes 0 1. general, recommend stacking averaging predictive distributions, pseudo-BMA+ can serve computationally easier alternative.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_model_weights.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Model averaging/weighting via stacking or pseudo-BMA weighting — loo_model_weights","text":"Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. doi:10.1007/s11222-016-9696-4 (journal version, preprint arXiv:1507.04544). Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF Yao, Y., Vehtari, ., Simpson, D., Gelman, . (2018) Using stacking average Bayesian predictive distributions. Bayesian Analysis, advance publication,  doi:10.1214/17-BA1091. (online).","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/loo_model_weights.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Model averaging/weighting via stacking or pseudo-BMA weighting — loo_model_weights","text":"","code":"# \\dontrun{ ### Demonstrating usage after fitting models with RStan library(rstan) #> Loading required package: StanHeaders #>  #> rstan version 2.32.7 (Stan version 2.32.2) #> For execution on a local, multicore CPU with excess RAM we recommend calling #> options(mc.cores = parallel::detectCores()). #> To avoid recompilation of unchanged Stan programs, we recommend calling #> rstan_options(auto_write = TRUE) #> For within-chain threading using `reduce_sum()` or `map_rect()` Stan functions, #> change `threads_per_chain` option: #> rstan_options(threads_per_chain = 1) #> Do not specify '-march=native' in 'LOCAL_CPPFLAGS' or a Makevars file  # generate fake data from N(0,1). N <- 100 y <- rnorm(N, 0, 1)  # Suppose we have three models: N(-1, sigma), N(0.5, sigma) and N(0.6,sigma). stan_code <- \"   data {     int N;     vector[N] y;     real mu_fixed;   }   parameters {     real<lower=0> sigma;   }   model {     sigma ~ exponential(1);     y ~ normal(mu_fixed, sigma);   }   generated quantities {     vector[N] log_lik;     for (n in 1:N) log_lik[n] = normal_lpdf(y[n]| mu_fixed, sigma);   }\"  mod <- stan_model(model_code = stan_code) fit1 <- sampling(mod, data=list(N=N, y=y, mu_fixed=-1)) #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 5.3e-05 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.53 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.038 seconds (Warm-up) #> Chain 1:                0.03 seconds (Sampling) #> Chain 1:                0.068 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 5e-06 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.035 seconds (Warm-up) #> Chain 2:                0.024 seconds (Sampling) #> Chain 2:                0.059 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 6e-06 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.029 seconds (Warm-up) #> Chain 3:                0.023 seconds (Sampling) #> Chain 3:                0.052 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 4e-06 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.024 seconds (Warm-up) #> Chain 4:                0.022 seconds (Sampling) #> Chain 4:                0.046 seconds (Total) #> Chain 4:  fit2 <- sampling(mod, data=list(N=N, y=y, mu_fixed=0.5)) #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 7e-06 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.04 seconds (Warm-up) #> Chain 1:                0.025 seconds (Sampling) #> Chain 1:                0.065 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 7e-06 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.026 seconds (Warm-up) #> Chain 2:                0.033 seconds (Sampling) #> Chain 2:                0.059 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 5e-06 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.035 seconds (Warm-up) #> Chain 3:                0.026 seconds (Sampling) #> Chain 3:                0.061 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 1e-05 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.034 seconds (Warm-up) #> Chain 4:                0.026 seconds (Sampling) #> Chain 4:                0.06 seconds (Total) #> Chain 4:  fit3 <- sampling(mod, data=list(N=N, y=y, mu_fixed=0.6)) #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1). #> Chain 1:  #> Chain 1: Gradient evaluation took 4e-06 seconds #> Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds. #> Chain 1: Adjust your expectations accordingly! #> Chain 1:  #> Chain 1:  #> Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 1:  #> Chain 1:  Elapsed Time: 0.008 seconds (Warm-up) #> Chain 1:                0.007 seconds (Sampling) #> Chain 1:                0.015 seconds (Total) #> Chain 1:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2). #> Chain 2:  #> Chain 2: Gradient evaluation took 3e-06 seconds #> Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds. #> Chain 2: Adjust your expectations accordingly! #> Chain 2:  #> Chain 2:  #> Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 2:  #> Chain 2:  Elapsed Time: 0.008 seconds (Warm-up) #> Chain 2:                0.007 seconds (Sampling) #> Chain 2:                0.015 seconds (Total) #> Chain 2:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3). #> Chain 3:  #> Chain 3: Gradient evaluation took 2e-06 seconds #> Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds. #> Chain 3: Adjust your expectations accordingly! #> Chain 3:  #> Chain 3:  #> Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 3:  #> Chain 3:  Elapsed Time: 0.007 seconds (Warm-up) #> Chain 3:                0.007 seconds (Sampling) #> Chain 3:                0.014 seconds (Total) #> Chain 3:  #>  #> SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4). #> Chain 4:  #> Chain 4: Gradient evaluation took 2e-06 seconds #> Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds. #> Chain 4: Adjust your expectations accordingly! #> Chain 4:  #> Chain 4:  #> Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup) #> Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup) #> Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup) #> Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup) #> Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup) #> Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup) #> Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling) #> Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling) #> Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling) #> Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling) #> Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling) #> Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling) #> Chain 4:  #> Chain 4:  Elapsed Time: 0.007 seconds (Warm-up) #> Chain 4:                0.007 seconds (Sampling) #> Chain 4:                0.014 seconds (Total) #> Chain 4:  model_list <- list(fit1, fit2, fit3) log_lik_list <- lapply(model_list, extract_log_lik)  # optional but recommended r_eff_list <- lapply(model_list, function(x) {   ll_array <- extract_log_lik(x, merge_chains = FALSE)   relative_eff(exp(ll_array)) })  # stacking method: wts1 <- loo_model_weights(   log_lik_list,   method = \"stacking\",   r_eff_list = r_eff_list,   optim_control = list(reltol=1e-10) ) print(wts1) #> Method: stacking #> ------ #>        weight #> model1 0.270  #> model2 0.730  #> model3 0.000   # can also pass a list of psis_loo objects to avoid recomputing loo loo_list <- lapply(1:length(log_lik_list), function(j) {   loo(log_lik_list[[j]], r_eff = r_eff_list[[j]]) })  wts2 <- loo_model_weights(   loo_list,   method = \"stacking\",   optim_control = list(reltol=1e-10) ) all.equal(wts1, wts2) #> [1] TRUE  # can provide names to be used in the results loo_model_weights(setNames(loo_list, c(\"A\", \"B\", \"C\"))) #> Method: stacking #> ------ #>   weight #> A 0.270  #> B 0.730  #> C 0.000    # pseudo-BMA+ method: set.seed(1414) loo_model_weights(loo_list, method = \"pseudobma\") #> Method: pseudo-BMA+ with Bayesian bootstrap #> ------ #>        weight #> model1 0.045  #> model2 0.942  #> model3 0.013   # pseudo-BMA method (set BB = FALSE): loo_model_weights(loo_list, method = \"pseudobma\", BB = FALSE) #> Method: pseudo-BMA #> ------ #>        weight #> model1 0.000  #> model2 0.990  #> model3 0.010   # calling stacking_weights or pseudobma_weights directly lpd1 <- loo(log_lik_list[[1]], r_eff = r_eff_list[[1]])$pointwise[,1] lpd2 <- loo(log_lik_list[[2]], r_eff = r_eff_list[[2]])$pointwise[,1] lpd3 <- loo(log_lik_list[[3]], r_eff = r_eff_list[[3]])$pointwise[,1] stacking_weights(cbind(lpd1, lpd2, lpd3)) #> Method: stacking #> ------ #>        weight #> model1 0.270  #> model2 0.730  #> model3 0.000  pseudobma_weights(cbind(lpd1, lpd2, lpd3)) #> Method: pseudo-BMA+ with Bayesian bootstrap #> ------ #>        weight #> model1 0.061  #> model2 0.927  #> model3 0.012  pseudobma_weights(cbind(lpd1, lpd2, lpd3), BB = FALSE) #> Method: pseudo-BMA #> ------ #>        weight #> model1 0.000  #> model2 0.990  #> model3 0.010  # }"},{"path":"https://mc-stan.org/loo/dev/reference/loo_moment_match.html","id":null,"dir":"Reference","previous_headings":"","what":"Moment matching for efficient approximate leave-one-out cross-validation (LOO) — loo_moment_match","title":"Moment matching for efficient approximate leave-one-out cross-validation (LOO) — loo_moment_match","text":"Moment matching algorithm updating loo object Pareto k estimates large.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_moment_match.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Moment matching for efficient approximate leave-one-out cross-validation (LOO) — loo_moment_match","text":"","code":"loo_moment_match(x, ...)  # Default S3 method loo_moment_match(   x,   loo,   post_draws,   log_lik_i,   unconstrain_pars,   log_prob_upars,   log_lik_i_upars,   max_iters = 30L,   k_threshold = NULL,   split = TRUE,   cov = TRUE,   cores = getOption(\"mc.cores\", 1),   ... )"},{"path":"https://mc-stan.org/loo/dev/reference/loo_moment_match.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Moment matching for efficient approximate leave-one-out cross-validation (LOO) — loo_moment_match","text":"x fitted model object. ... arguments passed custom functions documented . loo loo object modified. post_draws function takes x first argument returns matrix posterior draws model parameters. log_lik_i function takes x returns matrix (one column per chain) vector (chains stacked) log-likelihood draws ith observation based model x. draws obtained using MCMC, matrix MCMC chains separated preferred. unconstrain_pars function takes arguments x, pars returns posterior draws unconstrained space based posterior draws constrained space passed via pars. log_prob_upars function takes arguments x upars returns matrix log-posterior density values unconstrained posterior draws passed via upars. log_lik_i_upars function takes arguments x, upars, returns vector log-likelihood draws ith observation based unconstrained posterior draws passed via upars. max_iters Maximum number moment matching iterations. Usually need modified. maximum number iterations reached, warning, increasing max_iters may improve accuracy. k_threshold Threshold value Pareto k values moment matching algorithm used. default value min(1 - 1/log10(S), 0.7), S sample size. split Logical; Indicate whether split transformation end moment matching LOO fold. cov Logical; Indicate whether match covariance matrix samples . FALSE, mean marginal variances matched. cores number cores use parallelization. defaults option mc.cores can set entire R session options(mc.cores = NUMBER). old option loo.cores now deprecated given precedence mc.cores loo.cores removed future release. version 2.0.0 default now 1 core mc.cores set, recommend using many (close many) cores possible. Note Windows 10 users: strongly recommended avoid using .Rprofile file set mc.cores (using cores argument setting mc.cores interactively script fine).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_moment_match.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Moment matching for efficient approximate leave-one-out cross-validation (LOO) — loo_moment_match","text":"loo_moment_match() methods return updated loo object. structure updated loo object similar, method also stores original Pareto k diagnostic values diagnostics field.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_moment_match.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Moment matching for efficient approximate leave-one-out cross-validation (LOO) — loo_moment_match","text":"loo_moment_match() function S3 generic provide default method takes arguments user-specified functions post_draws, log_lik_i, unconstrain_pars, log_prob_upars, log_lik_i_upars. functions take .... argument addition specified function.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_moment_match.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Moment matching for efficient approximate leave-one-out cross-validation (LOO) — loo_moment_match","text":"loo_moment_match(default): default method takes arguments user-specified model object x, loo object user-specified functions post_draws, log_lik_i, unconstrain_pars, log_prob_upars, log_lik_i_upars.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_moment_match.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Moment matching for efficient approximate leave-one-out cross-validation (LOO) — loo_moment_match","text":"Paananen, T., Piironen, J., Buerkner, P.-C., Vehtari, . (2021). Implicitly adaptive importance sampling. Statistics Computing, 31, 16. doi:10.1007/s11222-020-09982-2. arXiv preprint arXiv:1906.08850.","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/loo_moment_match.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Moment matching for efficient approximate leave-one-out cross-validation (LOO) — loo_moment_match","text":"","code":"# See the vignette for loo_moment_match()"},{"path":"https://mc-stan.org/loo/dev/reference/loo_moment_match_split.html","id":null,"dir":"Reference","previous_headings":"","what":"Split moment matching for efficient approximate leave-one-out cross-validation (LOO) — loo_moment_match_split","title":"Split moment matching for efficient approximate leave-one-out cross-validation (LOO) — loo_moment_match_split","text":"function computes split moment matching importance sampling loo. Takes moment matching total transformation, transforms half draws, computes single elpd using multiple importance sampling.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_moment_match_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split moment matching for efficient approximate leave-one-out cross-validation (LOO) — loo_moment_match_split","text":"","code":"loo_moment_match_split(   x,   upars,   cov,   total_shift,   total_scaling,   total_mapping,   i,   log_prob_upars,   log_lik_i_upars,   r_eff_i,   cores,   is_method,   ... )"},{"path":"https://mc-stan.org/loo/dev/reference/loo_moment_match_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split moment matching for efficient approximate leave-one-out cross-validation (LOO) — loo_moment_match_split","text":"x fitted model object. upars matrix containing model parameters unconstrained space can real value. cov Logical; Indicate whether match covariance matrix samples . FALSE, mean marginal variances matched. total_shift vector representing total shift made moment matching algorithm. total_scaling vector representing total scaling marginal variance made moment matching algorithm. total_mapping vector representing total covariance transformation made moment matching algorithm. Observation index. log_prob_upars function takes arguments x upars returns matrix log-posterior density values unconstrained posterior draws passed via upars. log_lik_i_upars function takes arguments x, upars, returns vector log-likeliood draws ith observation based unconstrained posterior draws passed via upars. r_eff_i MCMC relative effective sample size 'th log likelihood draws. cores number cores use parallelization. defaults option mc.cores can set entire R session options(mc.cores = NUMBER). old option loo.cores now deprecated given precedence mc.cores loo.cores removed future release. version 2.0.0 default now 1 core mc.cores set, recommend using many (close many) cores possible. Note Windows 10 users: strongly recommended avoid using .Rprofile file set mc.cores (using cores argument setting mc.cores interactively script fine). is_method importance sampling method use. following methods implemented: \"psis\": Pareto-Smoothed Importance Sampling (PSIS). Default method. \"tis\": Truncated Importance Sampling (TIS) truncation sqrt(S), S number posterior draws. \"sis\": Standard Importance Sampling (SIS). ... arguments passed custom functions documented .","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_moment_match_split.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split moment matching for efficient approximate leave-one-out cross-validation (LOO) — loo_moment_match_split","text":"list containing updated log-importance weights log-likelihood values. Also returns updated MCMC effective sample size integrand-specific log-importance weights.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_moment_match_split.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Split moment matching for efficient approximate leave-one-out cross-validation (LOO) — loo_moment_match_split","text":"Paananen, T., Piironen, J., Buerkner, P.-C., Vehtari, . (2021). Implicitly adaptive importance sampling. Statistics Computing, 31, 16. doi:10.1007/s11222-020-09982-2. arXiv preprint arXiv:1906.08850.","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/loo_predictive_metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate leave-one-out predictive performance.. — loo_predictive_metric","title":"Estimate leave-one-out predictive performance.. — loo_predictive_metric","text":"loo_predictive_metric() function computes estimates leave-one-predictive metrics given set predictions observations. Currently supported metrics mean absolute error, mean squared error root mean squared error continuous predictions accuracy balanced accuracy binary classification. Predictions passed E_loo() function, function assumes PSIS approximation working well.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_predictive_metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate leave-one-out predictive performance.. — loo_predictive_metric","text":"","code":"loo_predictive_metric(x, ...)  # S3 method for class 'matrix' loo_predictive_metric(   x,   y,   log_lik,   ...,   metric = c(\"mae\", \"rmse\", \"mse\", \"acc\", \"balanced_acc\"),   r_eff = 1,   cores = getOption(\"mc.cores\", 1) )"},{"path":"https://mc-stan.org/loo/dev/reference/loo_predictive_metric.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate leave-one-out predictive performance.. — loo_predictive_metric","text":"x numeric matrix predictions. ... Additional arguments passed E_loo() y numeric vector observations. Length equal number rows x. log_lik matrix pointwise log-likelihoods. dimension x. metric type predictive metric used. Currently supported options \"mae\", \"rmse\" \"mse\" regression binary classification \"acc\" \"balanced_acc\". \"mae\" Mean absolute error. \"mse\" Mean squared error. \"rmse\" Root mean squared error, given square root MSE. \"acc\" proportion predictions indicating correct outcome. \"balanced_acc\" Balanced accuracy given average true positive true negative rates. r_eff Vector relative effective sample size estimates containing one element per observation. See psis() details. cores number cores use parallelization [psis()]. See psis() details.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_predictive_metric.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate leave-one-out predictive performance.. — loo_predictive_metric","text":"list following components: estimate Estimate given metric. se Standard error estimate.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_predictive_metric.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate leave-one-out predictive performance.. — loo_predictive_metric","text":"","code":"# \\donttest{ if (requireNamespace(\"rstanarm\", quietly = TRUE)) { # Use rstanarm package to quickly fit a model and get both a log-likelihood # matrix and draws from the posterior predictive distribution library(\"rstanarm\")  # data from help(\"lm\") ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14) trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69) d <- data.frame(   weight = c(ctl, trt),   group = gl(2, 10, 20, labels = c(\"Ctl\",\"Trt\")) ) fit <- stan_glm(weight ~ group, data = d, refresh = 0) ll <- log_lik(fit) r_eff <- relative_eff(exp(-ll), chain_id = rep(1:4, each = 1000))  mu_pred <- posterior_epred(fit) # Leave-one-out mean absolute error of predictions mae <- loo_predictive_metric(x = mu_pred, y = d$weight, log_lik = ll,                             pred_error = 'mae', r_eff = r_eff) # Leave-one-out 90%-quantile of mean absolute error mae_90q <- loo_predictive_metric(x = mu_pred, y = d$weight, log_lik = ll,                                 pred_error = 'mae', r_eff = r_eff,                                 type = 'quantile', probs = 0.9) } # }"},{"path":"https://mc-stan.org/loo/dev/reference/loo_subsample.html","id":null,"dir":"Reference","previous_headings":"","what":"Efficient approximate leave-one-out cross-validation (LOO) using subsampling, so that less costly and more approximate computation is made for all LOO-fold, and more costly and accurate computations are made only for m<N LOO-folds. — loo_subsample","title":"Efficient approximate leave-one-out cross-validation (LOO) using subsampling, so that less costly and more approximate computation is made for all LOO-fold, and more costly and accurate computations are made only for m<N LOO-folds. — loo_subsample","text":"Efficient approximate leave-one-cross-validation (LOO) using subsampling, less costly approximate computation made LOO-fold, costly accurate computations made m<N LOO-folds.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_subsample.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Efficient approximate leave-one-out cross-validation (LOO) using subsampling, so that less costly and more approximate computation is made for all LOO-fold, and more costly and accurate computations are made only for m<N LOO-folds. — loo_subsample","text":"","code":"loo_subsample(x, ...)  # S3 method for class '`function`' loo_subsample(   x,   ...,   data = NULL,   draws = NULL,   observations = 400,   log_p = NULL,   log_g = NULL,   r_eff = 1,   save_psis = FALSE,   cores = getOption(\"mc.cores\", 1),   loo_approximation = \"plpd\",   loo_approximation_draws = NULL,   estimator = \"diff_srs\",   llgrad = NULL,   llhess = NULL )"},{"path":"https://mc-stan.org/loo/dev/reference/loo_subsample.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Efficient approximate leave-one-out cross-validation (LOO) using subsampling, so that less costly and more approximate computation is made for all LOO-fold, and more costly and accurate computations are made only for m<N LOO-folds. — loo_subsample","text":"x function. Methods (class) section, , detailed descriptions specify inputs. data, draws, ... loo_subsample.function(), data, posterior draws, arguments pass log-likelihood function. Note loo_approximations, draws replaced posteriors summary statistics compute loo approximations. See argument loo_approximation details. observations subsample observations use. argument can take four (4) types arguments: NULL use observations. algorithm just uses standard loo() loo_approximate_posterior(). single integer specify number observations subsampled. vector integers provide indices used subset data. observations need subsampled scheme given estimator argument. psis_loo_ss object use observations used previous call loo_subsample(). log_p, log_g supplied approximate posterior draws used. default (NULL) indicates draws \"true\" posterior (.e. using MCMC). NULL specified described loo_approximate_posterior(). r_eff Vector relative effective sample size estimates likelihood (exp(log_lik)) observation. related relative efficiency estimating normalizing term self-normalized importance sampling using posterior draws obtained MCMC. MCMC draws used r_eff provided reported PSIS effective sample sizes Monte Carlo error estimates can -optimistic. posterior draws (near) independent r_eff=1 can used. r_eff scalar (value used observations) vector length equal number observations. default value 1. See relative_eff() helper functions help computing r_eff. save_psis \"psis\" object created internally loo_subsample() saved returned object? See loo() details. cores number cores use parallelization. defaults option mc.cores can set entire R session options(mc.cores = NUMBER). old option loo.cores now deprecated given precedence mc.cores loo.cores removed future release. version 2.0.0 default now 1 core mc.cores set, recommend using many (close many) cores possible. Note Windows 10 users: strongly recommended avoid using .Rprofile file set mc.cores (using cores argument setting mc.cores interactively script fine). loo_approximation type approximation loo_i's used? default \"plpd\" (log predictive density using posterior expectation). six different methods implemented approximate loo_i's (see references details): \"plpd\": uses lpd based point estimates (.e., \\(p(y_i|\\hat{\\theta})\\)). \"lpd\": uses lpds (,e., \\(p(y_i|y)\\)). \"tis\": uses truncated importance sampling approximate PSIS-LOO. \"waic\": uses waic (.e., \\(p(y_i|y) - p_{waic}\\)). \"waic_grad_marginal\": uses waic approximation using first order delta method posterior marginal variances approximate \\(p_{waic}\\) (ie. \\(p(y_i|\\hat{\\theta})\\)-p_waic_grad_marginal). Requires gradient likelihood function. \"waic_grad\": uses waic approximation using first order delta method posterior covariance approximate \\(p_{waic}\\) (ie. \\(p(y_i|\\hat{\\theta})\\)-p_waic_grad). Requires gradient likelihood function. \"waic_hess\": uses waic approximation using second order delta method posterior covariance approximate \\(p_{waic}\\) (ie. \\(p(y_i|\\hat{\\theta})\\)-p_waic_grad). Requires gradient Hessian likelihood function. point estimates \\(\\hat{\\theta}\\), posterior expectations parameters used. loo_approximation_draws number posterior draws used integrating posterior. used loo_approximation set \"lpd\", \"waic\", \"tis\". estimator elpd_loo, p_loo looic estimated? default \"diff_srs\". \"diff_srs\": uses difference estimator simple random sampling without replacement (srs). p_loo estimated using standard srs. (Magnusson et al., 2020) \"hh\": uses Hansen-Hurwitz estimator sampling replacement proportional size, abs loo_approximation used size. (Magnusson et al., 2019) \"srs\": uses simple random sampling ordinary estimation. llgrad gradient log-likelihood. used loo_approximation \"waic_grad\", \"waic_grad_marginal\", \"waic_hess\". default NULL. llhess Hessian log-likelihood. used loo_approximation = \"waic_hess\". default NULL.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_subsample.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Efficient approximate leave-one-out cross-validation (LOO) using subsampling, so that less costly and more approximate computation is made for all LOO-fold, and more costly and accurate computations are made only for m<N LOO-folds. — loo_subsample","text":"loo_subsample() returns named list class c(\"psis_loo_ss\", \"psis_loo\", \"loo\"). structure objects returned loo() additional slot: loo_subsampling: list two vectors, log_p log_g, length containing posterior density approximation density individual draws.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_subsample.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Efficient approximate leave-one-out cross-validation (LOO) using subsampling, so that less costly and more approximate computation is made for all LOO-fold, and more costly and accurate computations are made only for m<N LOO-folds. — loo_subsample","text":"loo_subsample() function S3 generic methods currently provided log-likelihood functions. implementation works MCMC posterior approximations possible compute log density approximation.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/loo_subsample.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Efficient approximate leave-one-out cross-validation (LOO) using subsampling, so that less costly and more approximate computation is made for all LOO-fold, and more costly and accurate computations are made only for m<N LOO-folds. — loo_subsample","text":"loo_subsample(`function`): function f() takes arguments data_i draws returns vector containing log-likelihood single observation evaluated posterior draw. function written , observation 1:N, evaluating   results vector length S (size posterior sample). log-likelihood function can also additional arguments data_i draws required. using function method arguments data draws must also specified call loo(): data: data frame matrix containing data (e.g. observed outcome predictors) needed compute pointwise log-likelihood. observation , ith row data passed data_i argument log-likelihood function. draws: object containing posterior draws parameters needed compute pointwise log-likelihood. Unlike data, indexed observation, observation entire object draws passed draws argument log-likelihood function. ... can used log-likelihood function takes additional arguments. arguments used like draws argument recycled observation.","code":"f(data_i = data[i,, drop=FALSE], draws = draws)"},{"path":"https://mc-stan.org/loo/dev/reference/loo_subsample.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Efficient approximate leave-one-out cross-validation (LOO) using subsampling, so that less costly and more approximate computation is made for all LOO-fold, and more costly and accurate computations are made only for m<N LOO-folds. — loo_subsample","text":"Magnusson, M., Riis Andersen, M., Jonasson, J. Vehtari, . (2019). Leave-One-Cross-Validation Large Data. Thirty-sixth International Conference Machine Learning, PMLR 97:4244-4253. Magnusson, M., Riis Andersen, M., Jonasson, J. Vehtari, . (2020). Leave-One-Cross-Validation Model Comparison Large Data. Proceedings 23rd International Conference Artificial Intelligence Statistics (AISTATS), PMLR 108:341-351.","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/nlist.html","id":null,"dir":"Reference","previous_headings":"","what":"Named lists — nlist","title":"Named lists — nlist","text":"Create named list using specified names , names omitted, using names objects list. code list(= , b = b) becomes nlist(,b) list(= , b = 2) becomes nlist(, b = 2), etc.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/nlist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Named lists — nlist","text":"","code":"nlist(...)"},{"path":"https://mc-stan.org/loo/dev/reference/nlist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Named lists — nlist","text":"... Objects include list.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/nlist.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Named lists — nlist","text":"named list.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/nlist.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Named lists — nlist","text":"","code":"# All variables already defined a <- rnorm(100) b <- mat.or.vec(10, 3) nlist(a,b) #> $a #>   [1]  0.46402132  0.18328496  0.37014325 -0.46539846 -1.35699064 -0.94756588 #>   [7] -1.32675628  1.71944404 -0.87898014 -0.02435987 -0.35046913 -1.49272159 #>  [13] -1.34795616 -0.87239734  0.36550662 -0.95172768 -0.20884901 -0.58875870 #>  [19] -0.71210362  2.55268532 -0.15015995  0.49893157  0.48499617 -0.46047212 #>  [25]  0.47671215  1.44219503 -0.53252713 -1.00355596 -0.79759812 -0.35212601 #>  [31] -0.12575206 -1.12890042  1.81283778  0.54590031  0.27614100 -1.78703622 #>  [37] -0.69897022  0.66958072  1.16590622 -0.10045622 -0.19541553  1.01477218 #>  [43] -0.29486217  1.95328836  0.22345390 -0.89055374 -0.21735722  0.64246743 #>  [49] -0.19687145 -0.92607721  1.18453783  0.68133067 -0.22411617 -0.42614768 #>  [55]  1.33986614 -0.72595917  0.54091251  0.71569348  0.08556613 -0.98998589 #>  [61]  0.27201072 -2.00633480 -2.45095243  0.04180641  1.27960696  0.32538273 #>  [67] -0.45765369  0.78471577 -0.03627547  1.09984716 -0.93415634  1.16878532 #>  [73]  0.71871116  0.68790149  0.28979210  0.69836408  1.10855493  0.27345095 #>  [79]  0.98693726 -0.58554379 -0.01686564  0.88033592 -0.50875613  0.33882608 #>  [85] -0.81332136  1.04149262  0.24335859 -0.64718064  0.61923141  0.89574032 #>  [91] -1.48522355 -1.14509293 -0.52444523 -0.37295246  1.25390995 -0.11286019 #>  [97] -0.22566170 -0.13817146  1.37191158 -1.54525644 #>  #> $b #>       [,1] [,2] [,3] #>  [1,]    0    0    0 #>  [2,]    0    0    0 #>  [3,]    0    0    0 #>  [4,]    0    0    0 #>  [5,]    0    0    0 #>  [6,]    0    0    0 #>  [7,]    0    0    0 #>  [8,]    0    0    0 #>  [9,]    0    0    0 #> [10,]    0    0    0 #>   # Define some variables in the call and take the rest from the environment nlist(a, b, veggies = c(\"lettuce\", \"spinach\"), fruits = c(\"banana\", \"papaya\")) #> $a #>   [1]  0.46402132  0.18328496  0.37014325 -0.46539846 -1.35699064 -0.94756588 #>   [7] -1.32675628  1.71944404 -0.87898014 -0.02435987 -0.35046913 -1.49272159 #>  [13] -1.34795616 -0.87239734  0.36550662 -0.95172768 -0.20884901 -0.58875870 #>  [19] -0.71210362  2.55268532 -0.15015995  0.49893157  0.48499617 -0.46047212 #>  [25]  0.47671215  1.44219503 -0.53252713 -1.00355596 -0.79759812 -0.35212601 #>  [31] -0.12575206 -1.12890042  1.81283778  0.54590031  0.27614100 -1.78703622 #>  [37] -0.69897022  0.66958072  1.16590622 -0.10045622 -0.19541553  1.01477218 #>  [43] -0.29486217  1.95328836  0.22345390 -0.89055374 -0.21735722  0.64246743 #>  [49] -0.19687145 -0.92607721  1.18453783  0.68133067 -0.22411617 -0.42614768 #>  [55]  1.33986614 -0.72595917  0.54091251  0.71569348  0.08556613 -0.98998589 #>  [61]  0.27201072 -2.00633480 -2.45095243  0.04180641  1.27960696  0.32538273 #>  [67] -0.45765369  0.78471577 -0.03627547  1.09984716 -0.93415634  1.16878532 #>  [73]  0.71871116  0.68790149  0.28979210  0.69836408  1.10855493  0.27345095 #>  [79]  0.98693726 -0.58554379 -0.01686564  0.88033592 -0.50875613  0.33882608 #>  [85] -0.81332136  1.04149262  0.24335859 -0.64718064  0.61923141  0.89574032 #>  [91] -1.48522355 -1.14509293 -0.52444523 -0.37295246  1.25390995 -0.11286019 #>  [97] -0.22566170 -0.13817146  1.37191158 -1.54525644 #>  #> $b #>       [,1] [,2] [,3] #>  [1,]    0    0    0 #>  [2,]    0    0    0 #>  [3,]    0    0    0 #>  [4,]    0    0    0 #>  [5,]    0    0    0 #>  [6,]    0    0    0 #>  [7,]    0    0    0 #>  [8,]    0    0    0 #>  [9,]    0    0    0 #> [10,]    0    0    0 #>  #> $veggies #> [1] \"lettuce\" \"spinach\" #>  #> $fruits #> [1] \"banana\" \"papaya\" #>"},{"path":"https://mc-stan.org/loo/dev/reference/nobs.psis_loo_ss.html","id":null,"dir":"Reference","previous_headings":"","what":"The number of observations in a psis_loo_ss object. — nobs.psis_loo_ss","title":"The number of observations in a psis_loo_ss object. — nobs.psis_loo_ss","text":"number observations psis_loo_ss object.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/nobs.psis_loo_ss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The number of observations in a psis_loo_ss object. — nobs.psis_loo_ss","text":"","code":"# S3 method for class 'psis_loo_ss' nobs(object, ...)"},{"path":"https://mc-stan.org/loo/dev/reference/nobs.psis_loo_ss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The number of observations in a psis_loo_ss object. — nobs.psis_loo_ss","text":"object psis_loo_ss object. ... Currently unused.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/obs_idx.html","id":null,"dir":"Reference","previous_headings":"","what":"Get observation indices used in subsampling — obs_idx","title":"Get observation indices used in subsampling — obs_idx","text":"Get observation indices used subsampling","code":""},{"path":"https://mc-stan.org/loo/dev/reference/obs_idx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get observation indices used in subsampling — obs_idx","text":"","code":"obs_idx(x, rep = TRUE)"},{"path":"https://mc-stan.org/loo/dev/reference/obs_idx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get observation indices used in subsampling — obs_idx","text":"x psis_loo_ss object. rep sampling replacement used, observation can multiple samples repeated returned object rep=TRUE (e.g., vector c(1,1,2) indicates observation 1 subampled two times). rep=FALSE unique indices returned.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/obs_idx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get observation indices used in subsampling — obs_idx","text":"integer vector.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/old-extractors.html","id":null,"dir":"Reference","previous_headings":"","what":"Extractor methods — old-extractors","title":"Extractor methods — old-extractors","text":"defined order deprecate warning (rather remove break backwards compatibility) old way accessing point estimates \"psis_loo\" \"psis\" object. new way v2.0.0 get \"estimates\" component object.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/old-extractors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extractor methods — old-extractors","text":"","code":"# S3 method for class 'loo' x[i]  # S3 method for class 'loo' x[[i, exact = TRUE]]  # S3 method for class 'loo' x$name"},{"path":"https://mc-stan.org/loo/dev/reference/old-extractors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extractor methods — old-extractors","text":"x, , exact, name See Extract.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/parallel_psis_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Parallel psis list computations — parallel_psis_list","title":"Parallel psis list computations — parallel_psis_list","text":"Parallel psis list computations","code":""},{"path":"https://mc-stan.org/loo/dev/reference/parallel_psis_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parallel psis list computations — parallel_psis_list","text":"","code":"parallel_psis_list(   N,   .loo_i,   .llfun,   data,   draws,   r_eff,   save_psis,   cores,   ... )  parallel_importance_sampling_list(   N,   .loo_i,   .llfun,   data,   draws,   r_eff,   save_psis,   cores,   method,   ... )"},{"path":"https://mc-stan.org/loo/dev/reference/parallel_psis_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parallel psis list computations — parallel_psis_list","text":"N total number observations (.e. nrow(data)). .loo_i function used compute individual loo contributions. .llfun See llfun loo.function(). data, draws, ... loo.function() method loo_i() function, data, posterior draws, arguments pass log-likelihood function. See Methods (class) section details specify arguments. r_eff Vector relative effective sample size estimates likelihood (exp(log_lik)) observation. related relative efficiency estimating normalizing term self-normalized importance sampling using posterior draws obtained MCMC. MCMC draws used r_eff provided reported PSIS effective sample sizes Monte Carlo error estimates can -optimistic. posterior draws (near) independent r_eff=1 can used. r_eff scalar (value used observations) vector length equal number observations. default value 1. See relative_eff() helper functions help computing r_eff. save_psis psis object created internally loo() saved returned object? loo() function calls psis() internally default discards (potentially large) psis object using compute LOO-CV summaries. Setting save_psis=TRUE add psis_object component list returned loo. useful plan use E_loo() function compute weighted expectations running loo. Several functions bayesplot package also accept psis objects. cores number cores use parallelization. defaults option mc.cores can set entire R session options(mc.cores = NUMBER). old option loo.cores now deprecated given precedence mc.cores loo.cores removed future release. version 2.0.0 default now 1 core mc.cores set, recommend using many (close many) cores possible. Note Windows 10 users: strongly recommended avoid using .Rprofile file set mc.cores (using cores argument setting mc.cores interactively script fine). method See is_method loo()","code":""},{"path":"https://mc-stan.org/loo/dev/reference/parallel_psis_list.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parallel psis list computations — parallel_psis_list","text":"Refactored function handle parallel computations psis_list","code":""},{"path":"https://mc-stan.org/loo/dev/reference/pareto-k-diagnostic.html","id":null,"dir":"Reference","previous_headings":"","what":"Diagnostics for Pareto smoothed importance sampling (PSIS) — pareto-k-diagnostic","title":"Diagnostics for Pareto smoothed importance sampling (PSIS) — pareto-k-diagnostic","text":"Print diagnostic table summarizing estimated Pareto shape parameters PSIS effective sample sizes, find indexes observations estimated Pareto shape parameter \\(k\\) larger threshold value, plot observation indexes vs. diagnostic estimates. Details section provides brief overview diagnostics, recommend consulting Vehtari, Gelman, Gabry (2017) Vehtari, Simpson, Gelman, Yao, Gabry (2024) full details.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/pareto-k-diagnostic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diagnostics for Pareto smoothed importance sampling (PSIS) — pareto-k-diagnostic","text":"","code":"pareto_k_table(x)  pareto_k_ids(x, threshold = NULL)  pareto_k_values(x)  pareto_k_influence_values(x)  psis_n_eff_values(x)  mcse_loo(x, threshold = NULL)  # S3 method for class 'psis_loo' plot(   x,   diagnostic = c(\"k\", \"ESS\", \"n_eff\"),   ...,   label_points = FALSE,   main = \"PSIS diagnostic plot\" )  # S3 method for class 'psis' plot(   x,   diagnostic = c(\"k\", \"ESS\", \"n_eff\"),   ...,   label_points = FALSE,   main = \"PSIS diagnostic plot\" )"},{"path":"https://mc-stan.org/loo/dev/reference/pareto-k-diagnostic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Diagnostics for Pareto smoothed importance sampling (PSIS) — pareto-k-diagnostic","text":"x object created loo() psis(). threshold pareto_k_ids(), threshold minimum \\(k\\) value flag (default sample size S dependend threshold 1 - 1 / log10(S)). mcse_loo(), \\(k\\) estimates greater threshold MCSE estimate returned NA See Details motivation behind defaults. diagnostic plot method, diagnostic plotted? options \"k\" Pareto \\(k\\) estimates (default), \"ESS\" \"n_eff\" PSIS effective sample size estimates. label_points, ... plot() method, label_points TRUE observation numbers corresponding values \\(k\\) greater diagnostic threshold displayed plot. arguments specified ... passed graphics::text() can used control appearance labels. main plot() method, title plot.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/pareto-k-diagnostic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Diagnostics for Pareto smoothed importance sampling (PSIS) — pareto-k-diagnostic","text":"pareto_k_table() returns object class \"pareto_k_table\", matrix columns \"Count\", \"Proportion\", \"Min. n_eff\", print method. pareto_k_ids() returns integer vector indicating observations Pareto \\(k\\) estimates threshold. pareto_k_values() returns vector estimated Pareto \\(k\\) parameters. represent reliability sampling. pareto_k_influence_values() returns vector estimated Pareto \\(k\\) parameters. represent influence observations model posterior distribution. psis_n_eff_values() returns vector estimated PSIS effective sample sizes. mcse_loo() returns Monte Carlo standard error (MCSE) estimate PSIS-LOO. MCSE NA Pareto \\(k\\) values threshold. plot() method called side effect return anything. x result call loo() psis() plot(x, diagnostic) produces plot estimates Pareto shape parameters (diagnostic = \"k\") estimates PSIS effective sample sizes (diagnostic = \"ESS\").","code":""},{"path":"https://mc-stan.org/loo/dev/reference/pareto-k-diagnostic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Diagnostics for Pareto smoothed importance sampling (PSIS) — pareto-k-diagnostic","text":"reliability approximate convergence rate PSIS-based estimates can assessed using estimates shape parameter \\(k\\) generalized Pareto distribution. diagnostic threshold Pareto \\(k\\) depends sample size \\(S\\) (sample size dependent threshold introduced Vehtari et al. (2024), fixed thresholds 0.5 0.7 recommended). simplicity, loo package uses nominal sample size \\(S\\) computing sample size specific threshold. provides optimistic threshold effective sample size less 2200, MCMC-ESS > S/2 difference usually negligible. Thinning MCMC draws can used improve ratio ESS/S. \\(k < min(1 - 1 / log10(S), 0.7)\\), \\(S\\) sample size, PSIS estimate corresponding Monte Carlo standard error estimate reliable. \\(1 - 1 / log10(S) <= k < 0.7\\), PSIS estimate corresponding Monte Carlo standard error estimate reliable, increasing (effective) sample size \\(S\\) 2200 may help (increase sample size specific threshold \\((1-1/log10(2200)>0.7\\) bias specific threshold 0.7 dominates). \\(0.7 <= k < 1\\), PSIS estimate corresponding Monte Carlo standard error large bias reliable. Increasing sample size may reduce variability \\(k\\) estimate, may result lower \\(k\\) estimate, . \\(k \\geq 1\\), target distribution estimated non-finite mean. PSIS estimate corresponding Monte Carlo standard error well defined. Increasing sample size may reduce variability \\(k\\) estimate, may also result lower \\(k\\) estimate.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/pareto-k-diagnostic.html","id":"what-if-the-estimated-tail-shape-parameter-k-exceeds-the-diagnostic-threshold-","dir":"Reference","previous_headings":"","what":"What if the estimated tail shape parameter \\(k\\) exceeds the diagnostic threshold?","title":"Diagnostics for Pareto smoothed importance sampling (PSIS) — pareto-k-diagnostic","text":"Importance sampling likely work less well marginal posterior \\(p(\\theta^s | y)\\) LOO posterior \\(p(\\theta^s | y_{-})\\) different, likely happen non-robust model highly influential observations.  estimated tail shape parameter \\(k\\) exceeds diagnostic threshold, user warned. (Note: \\(k\\) greater diagnostic threshold WAIC also likely fail, WAIC lacks accurate diagnostic.)  using PSIS context approximate LOO-CV, recommend one following actions: additional computations, possible transform MCMC draws posterior distribution obtain reliable importance sampling estimates. results smaller shape parameter \\(k\\).  See loo_moment_match() vignette Avoiding model refits leave-one-cross-validation moment matching example . Sampling leave-one-mixture distribution (see vignette Mixture leave-one-cross-validation high-dimensional Bayesian models), directly \\(p(\\theta^s   | y_{-})\\) problematic observations \\(\\), using \\(K\\)-fold cross-validation (see vignette Holdout validation K-fold cross-validation Stan programs loo package) generally stable. Using model robust anomalous observations generally make approximate LOO-CV stable.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/pareto-k-diagnostic.html","id":"observation-influence-statistics","dir":"Reference","previous_headings":"","what":"Observation influence statistics","title":"Diagnostics for Pareto smoothed importance sampling (PSIS) — pareto-k-diagnostic","text":"estimated shape parameter \\(k\\) observation can used measure observation's influence posterior distribution model. can obtained pareto_k_influence_values().","code":""},{"path":"https://mc-stan.org/loo/dev/reference/pareto-k-diagnostic.html","id":"effective-sample-size-and-error-estimates","dir":"Reference","previous_headings":"","what":"Effective sample size and error estimates","title":"Diagnostics for Pareto smoothed importance sampling (PSIS) — pareto-k-diagnostic","text":"case obtain samples proposal distribution via MCMC loo package also computes estimates Monte Carlo error effective sample size importance sampling, accurate PSIS TIS (see Vehtari et al (2024) details). However, PSIS effective sample size estimate -optimistic estimate \\(k\\) greater \\(min(1-1/log10(S), 0.7)\\), \\(S\\) sample size.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/pareto-k-diagnostic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Diagnostics for Pareto smoothed importance sampling (PSIS) — pareto-k-diagnostic","text":"Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. doi:10.1007/s11222-016-9696-4 (journal version, preprint arXiv:1507.04544). Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/pointwise.html","id":null,"dir":"Reference","previous_headings":"","what":"Convenience function for extracting pointwise estimates — pointwise","title":"Convenience function for extracting pointwise estimates — pointwise","text":"Convenience function extracting pointwise estimates","code":""},{"path":"https://mc-stan.org/loo/dev/reference/pointwise.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convenience function for extracting pointwise estimates — pointwise","text":"","code":"pointwise(x, estimate, ...)  # S3 method for class 'loo' pointwise(x, estimate, ...)"},{"path":"https://mc-stan.org/loo/dev/reference/pointwise.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convenience function for extracting pointwise estimates — pointwise","text":"x loo object, example one returned loo(), loo_subsample(), loo_approximate_posterior(), loo_moment_match(), etc. estimate pointwise estimate return. default returned. objects returned different functions (loo(), loo_subsample(), etc.) slightly different estimates available. Typically minimum estimates elpd_loo, looic, mcse_elpd_loo, p_loo, influence_pareto_k available, may others. ... Currently ignored.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/pointwise.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convenience function for extracting pointwise estimates — pointwise","text":"vector length equal number observations.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/pointwise.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convenience function for extracting pointwise estimates — pointwise","text":"","code":"x <- loo(example_loglik_array()) pointwise(x, \"elpd_loo\") #>  [1] -2.372054 -2.132756 -2.337100 -2.177556 -2.088849 -2.112027 -2.920085 #>  [8] -3.038168 -2.385516 -2.091878 -2.150381 -2.138015 -2.090231 -2.281848 #> [15] -2.241406 -2.448014 -4.517458 -4.989572 -2.330323 -4.711113 -2.466241 #> [22] -2.562420 -2.840067 -2.749268 -2.420624 -2.129352 -2.112648 -2.240625 #> [29] -3.220368 -2.505142 -2.642838 -2.145284"},{"path":"https://mc-stan.org/loo/dev/reference/print.loo.html","id":null,"dir":"Reference","previous_headings":"","what":"Print methods — print.loo","title":"Print methods — print.loo","text":"Print methods","code":""},{"path":"https://mc-stan.org/loo/dev/reference/print.loo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print methods — print.loo","text":"","code":"# S3 method for class 'loo' print(x, digits = 1, ...)  # S3 method for class 'waic' print(x, digits = 1, ...)  # S3 method for class 'psis_loo' print(x, digits = 1, plot_k = FALSE, ...)  # S3 method for class 'importance_sampling_loo' print(x, digits = 1, plot_k = FALSE, ...)  # S3 method for class 'psis_loo_ap' print(x, digits = 1, plot_k = FALSE, ...)  # S3 method for class 'psis' print(x, digits = 1, plot_k = FALSE, ...)  # S3 method for class 'importance_sampling' print(x, digits = 1, plot_k = FALSE, ...)"},{"path":"https://mc-stan.org/loo/dev/reference/print.loo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print methods — print.loo","text":"x object returned loo(), psis(), waic(). digits integer passed base::round(). ... Arguments passed plot.psis_loo() plot_k TRUE. plot_k Logical. TRUE estimates Pareto shape parameter \\(k\\) plotted. Ignored x generated waic(). just plot \\(k\\) without printing use plot() method 'loo' objects.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/print.loo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print methods — print.loo","text":"x, invisibly.","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/print_dims.html","id":null,"dir":"Reference","previous_headings":"","what":"Print dimensions of log-likelihood or log-weights matrix — print_dims","title":"Print dimensions of log-likelihood or log-weights matrix — print_dims","text":"Print dimensions log-likelihood log-weights matrix","code":""},{"path":"https://mc-stan.org/loo/dev/reference/print_dims.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print dimensions of log-likelihood or log-weights matrix — print_dims","text":"","code":"print_dims(x, ...)  # S3 method for class 'importance_sampling' print_dims(x, ...)  # S3 method for class 'psis_loo' print_dims(x, ...)  # S3 method for class 'importance_sampling_loo' print_dims(x, ...)  # S3 method for class 'waic' print_dims(x, ...)  # S3 method for class 'kfold' print_dims(x, ...)  # S3 method for class 'psis_loo_ss' print_dims(x, ...)"},{"path":"https://mc-stan.org/loo/dev/reference/print_dims.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print dimensions of log-likelihood or log-weights matrix — print_dims","text":"x object returned psis(), loo(), waic(). ... Ignored.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/psis.html","id":null,"dir":"Reference","previous_headings":"","what":"Pareto smoothed importance sampling (PSIS) — psis","title":"Pareto smoothed importance sampling (PSIS) — psis","text":"Implementation Pareto smoothed importance sampling (PSIS), method stabilizing importance ratios. version PSIS implemented corresponds algorithm presented Vehtari, Simpson, Gelman, Yao, Gabry (2024). PSIS diagnostics see pareto-k-diagnostic page.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/psis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pareto smoothed importance sampling (PSIS) — psis","text":"","code":"psis(log_ratios, ...)  # S3 method for class 'array' psis(log_ratios, ..., r_eff = 1, cores = getOption(\"mc.cores\", 1))  # S3 method for class 'matrix' psis(log_ratios, ..., r_eff = 1, cores = getOption(\"mc.cores\", 1))  # Default S3 method psis(log_ratios, ..., r_eff = 1)  is.psis(x)  is.sis(x)  is.tis(x)"},{"path":"https://mc-stan.org/loo/dev/reference/psis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pareto smoothed importance sampling (PSIS) — psis","text":"log_ratios array, matrix, vector importance ratios log scale (PSIS-LOO negative log-likelihood values). See Methods (class) section detailed description specify inputs method. ... Arguments passed various methods. r_eff Vector relative effective sample size estimates containing one element per observation. values provided relative effective sample sizes 1/exp(log_ratios) (.e., 1/ratios). related relative efficiency estimating normalizing term self-normalizing importance sampling. r_eff provided reported PSIS effective sample sizes Monte Carlo error estimates can -optimistic. posterior draws (near) independent r_eff=1 can used. r_eff scalar (value used observations) vector length equal number observations. default value 1. See relative_eff() helper function computing r_eff. cores number cores use parallelization. defaults option mc.cores can set entire R session options(mc.cores = NUMBER). old option loo.cores now deprecated given precedence mc.cores loo.cores removed future release. version 2.0.0 default now 1 core mc.cores set, recommend using many (close many) cores possible. Note Windows 10 users: strongly recommended avoid using .Rprofile file set mc.cores (using cores argument setting mc.cores interactively script fine). x .psis(), object check.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/psis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pareto smoothed importance sampling (PSIS) — psis","text":"psis() methods return object class \"psis\", named list following components: log_weights Vector matrix smoothed (truncated) unnormalized log weights. get normalized weights use weights() method provided objects class \"psis\". diagnostics named list containing two vectors: pareto_k: Estimates shape parameter \\(k\\) generalized Pareto distribution. See pareto-k-diagnostic page details. n_eff: PSIS effective sample size estimates. Objects class \"psis\" also following attributes: norm_const_log Vector precomputed values colLogSumExps(log_weights) used internally weights method normalize log weights. tail_len Vector tail lengths used fitting generalized Pareto distribution. r_eff specified, user's r_eff argument. dims Integer vector length 2 containing S (posterior sample size) N (number observations). method Method used importance sampling, psis.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/psis.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Pareto smoothed importance sampling (PSIS) — psis","text":"psis(array): \\(\\) \\(C\\) \\(N\\) array, \\(\\) number MCMC iterations per chain, \\(C\\) number chains, \\(N\\) number data points. psis(matrix): \\(S\\) \\(N\\) matrix, \\(S\\) size posterior sample (chains merged) \\(N\\) number data points. psis(default): vector length \\(S\\) (posterior sample size).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/psis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pareto smoothed importance sampling (PSIS) — psis","text":"Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. doi:10.1007/s11222-016-9696-4 (journal version, preprint arXiv:1507.04544). Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/psis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pareto smoothed importance sampling (PSIS) — psis","text":"","code":"log_ratios <- -1 * example_loglik_array() r_eff <- relative_eff(exp(-log_ratios)) psis_result <- psis(log_ratios, r_eff = r_eff) str(psis_result) #> List of 2 #>  $ log_weights: num [1:1000, 1:32] 2.37 2.12 2.24 2.41 2.25 ... #>  $ diagnostics:List of 3 #>   ..$ pareto_k: num [1:32] 0.0489 -0.0593 0.0686 -0.0513 -0.1161 ... #>   ..$ n_eff   : num [1:32] 909 937 938 901 907 ... #>   ..$ r_eff   : num [1:32] 0.942 0.954 0.977 0.919 0.923 ... #>  - attr(*, \"norm_const_log\")= num [1:32] 9.28 9.04 9.25 9.09 9 ... #>  - attr(*, \"tail_len\")= num [1:32] 98 98 96 99 99 101 99 100 102 98 ... #>  - attr(*, \"r_eff\")= num [1:32] 0.942 0.954 0.977 0.919 0.923 ... #>  - attr(*, \"dims\")= int [1:2] 1000 32 #>  - attr(*, \"method\")= chr \"psis\" #>  - attr(*, \"class\")= chr [1:3] \"psis\" \"importance_sampling\" \"list\" plot(psis_result)   # extract smoothed weights lw <- weights(psis_result) # default args are log=TRUE, normalize=TRUE ulw <- weights(psis_result, normalize=FALSE) # unnormalized log-weights  w <- weights(psis_result, log=FALSE) # normalized weights (not log-weights) uw <- weights(psis_result, log=FALSE, normalize = FALSE) # unnormalized weights"},{"path":"https://mc-stan.org/loo/dev/reference/psislw.html","id":null,"dir":"Reference","previous_headings":"","what":"Pareto smoothed importance sampling (deprecated, old version) — psislw","title":"Pareto smoothed importance sampling (deprecated, old version) — psislw","text":"version 2.0.0 function deprecated. Please use psis() function new PSIS algorithm.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/psislw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pareto smoothed importance sampling (deprecated, old version) — psislw","text":"","code":"psislw(   lw,   wcp = 0.2,   wtrunc = 3/4,   cores = getOption(\"mc.cores\", 1),   llfun = NULL,   llargs = NULL,   ... )"},{"path":"https://mc-stan.org/loo/dev/reference/psislw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pareto smoothed importance sampling (deprecated, old version) — psislw","text":"lw matrix vector log weights. computing LOO, lw = -log_lik, negative \\(S\\) (simulations) \\(N\\) (data points) pointwise log-likelihood matrix. wcp proportion importance weights use generalized Pareto fit. 100*wcp\\ estimate parameters generalized Pareto distribution. wtrunc truncating large weights \\(S\\)^wtrunc. Set zero truncation. cores number cores use parallelization. defaults option mc.cores can set entire R session options(mc.cores = NUMBER), old option loo.cores now deprecated given precedence mc.cores removed. version 2.0.0, default now 1 core mc.cores set, recommend using many (close many) cores possible. llfun, llargs See loo.function(). ... Ignored psislw() called directly. ... used internally psislw() called loo() function.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/psislw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pareto smoothed importance sampling (deprecated, old version) — psislw","text":"named list components lw_smooth (modified log weights) pareto_k (estimated generalized Pareto shape parameter(s) k).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/psislw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Pareto smoothed importance sampling (deprecated, old version) — psislw","text":"Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. doi:10.1007/s11222-016-9696-4 (journal version, preprint arXiv:1507.04544). Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/psis_approximate_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Diagnostics for Laplace and ADVI approximations and Laplace-loo and ADVI-loo — psis_approximate_posterior","title":"Diagnostics for Laplace and ADVI approximations and Laplace-loo and ADVI-loo — psis_approximate_posterior","text":"Diagnostics Laplace ADVI approximations Laplace-loo ADVI-loo","code":""},{"path":"https://mc-stan.org/loo/dev/reference/psis_approximate_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Diagnostics for Laplace and ADVI approximations and Laplace-loo and ADVI-loo — psis_approximate_posterior","text":"","code":"psis_approximate_posterior(   log_p = NULL,   log_g = NULL,   log_liks = NULL,   cores,   save_psis,   ...,   log_q = NULL )"},{"path":"https://mc-stan.org/loo/dev/reference/psis_approximate_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Diagnostics for Laplace and ADVI approximations and Laplace-loo and ADVI-loo — psis_approximate_posterior","text":"log_p log-posterior (target) evaluated S samples proposal distribution (g). vector length S. log_g log-density (proposal) evaluated S samples proposal distribution (g). vector length S. log_liks log-likelihood matrix size S * N, N number observations S number samples q. See loo.matrix() details. Default NULL. posterior evaluated using k_hat diagnostic. cores number cores use parallelization. defaults option mc.cores can set entire R session options(mc.cores = NUMBER). old option loo.cores now deprecated given precedence mc.cores loo.cores removed future release. version 2.0.0 default now 1 core mc.cores set, recommend using many (close many) cores possible. Note Windows 10 users: strongly recommended avoid using .Rprofile file set mc.cores (using cores argument setting mc.cores interactively script fine). save_psis psis object created internally loo() saved returned object? loo() function calls psis() internally default discards (potentially large) psis object using compute LOO-CV summaries. Setting save_psis=TRUE add psis_object component list returned loo. useful plan use E_loo() function compute weighted expectations running loo. Several functions bayesplot package also accept psis objects. log_q Deprecated argument name (log_g).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/psis_approximate_posterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Diagnostics for Laplace and ADVI approximations and Laplace-loo and ADVI-loo — psis_approximate_posterior","text":"log likelihoods supplied, function returns \"loo\" object, otherwise function returns \"psis\" object.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/psis_approximate_posterior.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Diagnostics for Laplace and ADVI approximations and Laplace-loo and ADVI-loo — psis_approximate_posterior","text":"Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. doi:10.1007/s11222-016-9696-4 (journal version, preprint arXiv:1507.04544). Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/relative_eff.html","id":null,"dir":"Reference","previous_headings":"","what":"Convenience function for computing relative efficiencies — relative_eff","title":"Convenience function for computing relative efficiencies — relative_eff","text":"relative_eff() computes MCMC effective sample size divided total sample size.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/relative_eff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convenience function for computing relative efficiencies — relative_eff","text":"","code":"relative_eff(x, ...)  # Default S3 method relative_eff(x, chain_id, ...)  # S3 method for class 'matrix' relative_eff(x, chain_id, ..., cores = getOption(\"mc.cores\", 1))  # S3 method for class 'array' relative_eff(x, ..., cores = getOption(\"mc.cores\", 1))  # S3 method for class '`function`' relative_eff(   x,   chain_id,   ...,   cores = getOption(\"mc.cores\", 1),   data = NULL,   draws = NULL )  # S3 method for class 'importance_sampling' relative_eff(x, ...)"},{"path":"https://mc-stan.org/loo/dev/reference/relative_eff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convenience function for computing relative efficiencies — relative_eff","text":"x vector, matrix, 3-D array, function. See Methods (class) section details specifying x, \"log-likelihood\" mentioned replace one following depending use case: use loo() function, values x (generated x, function) likelihood values (.e., exp(log_lik)), log scale. generic use psis(), values x reciprocal importance ratios (.e., exp(-log_ratios)). chain_id vector length NROW(x) containing MCMC chain indexes row x (matrix) value x (vector). chain_id needed x 3-D array. C chains valid chain indexes values 1:C. cores number cores use parallelization. data, draws, ... loo() function method.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/relative_eff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convenience function for computing relative efficiencies — relative_eff","text":"vector relative effective sample sizes.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/relative_eff.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Convenience function for computing relative efficiencies — relative_eff","text":"relative_eff(default): vector length \\(S\\) (posterior sample size). relative_eff(matrix): \\(S\\) \\(N\\) matrix, \\(S\\) size posterior sample (chains merged) \\(N\\) number data points. relative_eff(array): \\(\\) \\(C\\) \\(N\\) array, \\(\\) number MCMC iterations per chain, \\(C\\) number chains, \\(N\\) number data points. relative_eff(`function`): function f() takes arguments data_i draws returns vector containing log-likelihood single observation evaluated posterior draw. function written , observation 1:N, evaluating   results vector length S (size posterior sample). log-likelihood function can also additional arguments data_i draws required. using function method arguments data draws must also specified call loo(): data: data frame matrix containing data (e.g. observed outcome predictors) needed compute pointwise log-likelihood. observation , ith row data passed data_i argument log-likelihood function. draws: object containing posterior draws parameters needed compute pointwise log-likelihood. Unlike data, indexed observation, observation entire object draws passed draws argument log-likelihood function. ... can used log-likelihood function takes additional arguments. arguments used like draws argument recycled observation. relative_eff(importance_sampling): x object class \"psis\", relative_eff() simply returns r_eff attribute x.","code":"f(data_i = data[i,, drop=FALSE], draws = draws)"},{"path":"https://mc-stan.org/loo/dev/reference/relative_eff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convenience function for computing relative efficiencies — relative_eff","text":"","code":"LLarr <- example_loglik_array() LLmat <- example_loglik_matrix() dim(LLarr) #> [1] 500   2  32 dim(LLmat) #> [1] 1000   32  rel_n_eff_1 <- relative_eff(exp(LLarr)) rel_n_eff_2 <- relative_eff(exp(LLmat), chain_id = rep(1:2, each = 500)) all.equal(rel_n_eff_1, rel_n_eff_2) #> [1] TRUE"},{"path":"https://mc-stan.org/loo/dev/reference/sis.html","id":null,"dir":"Reference","previous_headings":"","what":"Standard importance sampling (SIS) — sis","title":"Standard importance sampling (SIS) — sis","text":"Implementation standard importance sampling (SIS).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/sis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standard importance sampling (SIS) — sis","text":"","code":"sis(log_ratios, ...)  # S3 method for class 'array' sis(log_ratios, ..., r_eff = NULL, cores = getOption(\"mc.cores\", 1))  # S3 method for class 'matrix' sis(log_ratios, ..., r_eff = NULL, cores = getOption(\"mc.cores\", 1))  # Default S3 method sis(log_ratios, ..., r_eff = NULL)"},{"path":"https://mc-stan.org/loo/dev/reference/sis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standard importance sampling (SIS) — sis","text":"log_ratios array, matrix, vector importance ratios log scale (Importance sampling LOO, negative log-likelihood values). See Methods (class) section detailed description specify inputs method. ... Arguments passed various methods. r_eff Vector relative effective sample size estimates containing one element per observation. values provided relative effective sample sizes 1/exp(log_ratios) (.e., 1/ratios). related relative efficiency estimating normalizing term self-normalizing importance sampling. See relative_eff() helper function computing r_eff. using psis draws log_ratios obtained MCMC warning message thrown specifying r_eff can disabled setting r_eff NA. cores number cores use parallelization. defaults option mc.cores can set entire R session options(mc.cores = NUMBER). old option loo.cores now deprecated given precedence mc.cores loo.cores removed future release. version 2.0.0 default now 1 core mc.cores set, recommend using many (close many) cores possible. Note Windows 10 users: strongly recommended avoid using .Rprofile file set mc.cores (using cores argument setting mc.cores interactively script fine).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/sis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standard importance sampling (SIS) — sis","text":"sis() methods return object class \"sis\", named list following components: log_weights Vector matrix smoothed unnormalized log weights. get normalized weights use weights() method provided objects class sis. diagnostics named list containing one vector: pareto_k: used sis, set 0. n_eff: effective sample size estimates. Objects class \"sis\" also following attributes: norm_const_log Vector precomputed values colLogSumExps(log_weights) used internally weights method normalize log weights. r_eff specified, user's r_eff argument. tail_len used sis. dims Integer vector length 2 containing S (posterior sample size) N (number observations). method Method used importance sampling, sis.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/sis.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Standard importance sampling (SIS) — sis","text":"sis(array): \\(\\) \\(C\\) \\(N\\) array, \\(\\) number MCMC iterations per chain, \\(C\\) number chains, \\(N\\) number data points. sis(matrix): \\(S\\) \\(N\\) matrix, \\(S\\) size posterior sample (chains merged) \\(N\\) number data points. sis(default): vector length \\(S\\) (posterior sample size).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/sis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Standard importance sampling (SIS) — sis","text":"Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. doi:10.1007/s11222-016-9696-4 (journal version, preprint arXiv:1507.04544). Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/sis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standard importance sampling (SIS) — sis","text":"","code":"log_ratios <- -1 * example_loglik_array() r_eff <- relative_eff(exp(-log_ratios)) sis_result <- sis(log_ratios, r_eff = r_eff) str(sis_result) #> List of 2 #>  $ log_weights: num [1:1000, 1:32] 2.37 2.12 2.24 2.41 2.25 ... #>  $ diagnostics:List of 3 #>   ..$ pareto_k: num [1:32] 0 0 0 0 0 0 0 0 0 0 ... #>   ..$ n_eff   : num [1:32] 910 937 938 901 907 ... #>   ..$ r_eff   : num [1:32] 0.942 0.954 0.977 0.919 0.923 ... #>  - attr(*, \"norm_const_log\")= num [1:32] 9.28 9.04 9.24 9.09 9 ... #>  - attr(*, \"tail_len\")= num [1:32] 98 98 96 99 99 101 99 100 102 98 ... #>  - attr(*, \"r_eff\")= num [1:32] 0.942 0.954 0.977 0.919 0.923 ... #>  - attr(*, \"dims\")= int [1:2] 1000 32 #>  - attr(*, \"method\")= chr \"sis\" #>  - attr(*, \"class\")= chr [1:3] \"sis\" \"importance_sampling\" \"list\"  # extract smoothed weights lw <- weights(sis_result) # default args are log=TRUE, normalize=TRUE ulw <- weights(sis_result, normalize=FALSE) # unnormalized log-weights  w <- weights(sis_result, log=FALSE) # normalized weights (not log-weights) uw <- weights(sis_result, log=FALSE, normalize = FALSE) # unnormalized weights"},{"path":"https://mc-stan.org/loo/dev/reference/tis.html","id":null,"dir":"Reference","previous_headings":"","what":"Truncated importance sampling (TIS) — tis","title":"Truncated importance sampling (TIS) — tis","text":"Implementation truncated (self-normalized) importance sampling (TIS), truncated S^(1/2) recommended Ionides (2008).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/tis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Truncated importance sampling (TIS) — tis","text":"","code":"tis(log_ratios, ...)  # S3 method for class 'array' tis(log_ratios, ..., r_eff = 1, cores = getOption(\"mc.cores\", 1))  # S3 method for class 'matrix' tis(log_ratios, ..., r_eff = 1, cores = getOption(\"mc.cores\", 1))  # Default S3 method tis(log_ratios, ..., r_eff = 1)"},{"path":"https://mc-stan.org/loo/dev/reference/tis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Truncated importance sampling (TIS) — tis","text":"log_ratios array, matrix, vector importance ratios log scale (Importance sampling LOO, negative log-likelihood values). See Methods (class) section detailed description specify inputs method. ... Arguments passed various methods. r_eff Vector relative effective sample size estimates containing one element per observation. values provided relative effective sample sizes 1/exp(log_ratios) (.e., 1/ratios). related relative efficiency estimating normalizing term self-normalizing importance sampling. r_eff provided reported (T)effective sample sizes Monte Carlo error estimates can -optimistic. posterior draws (near) independent r_eff=1 can used. r_eff scalar (value used observations) vector length equal number observations. default value 1. See relative_eff() helper function computing r_eff. cores number cores use parallelization. defaults option mc.cores can set entire R session options(mc.cores = NUMBER). old option loo.cores now deprecated given precedence mc.cores loo.cores removed future release. version 2.0.0 default now 1 core mc.cores set, recommend using many (close many) cores possible. Note Windows 10 users: strongly recommended avoid using .Rprofile file set mc.cores (using cores argument setting mc.cores interactively script fine).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/tis.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Truncated importance sampling (TIS) — tis","text":"tis() methods return object class \"tis\", named list following components: log_weights Vector matrix smoothed (truncated) unnormalized log weights. get normalized weights use weights() method provided objects class tis. diagnostics named list containing one vector: pareto_k: used tis, set 0. n_eff: Effective sample size estimates. Objects class \"tis\" also following attributes: norm_const_log Vector precomputed values colLogSumExps(log_weights) used internally weights()method normalize log weights. r_eff specified, user's r_eff argument. tail_len used tis. dims Integer vector length 2 containing S (posterior sample size) N (number observations). method Method used importance sampling, tis.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/tis.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Truncated importance sampling (TIS) — tis","text":"tis(array): \\(\\) \\(C\\) \\(N\\) array, \\(\\) number MCMC iterations per chain, \\(C\\) number chains, \\(N\\) number data points. tis(matrix): \\(S\\) \\(N\\) matrix, \\(S\\) size posterior sample (chains merged) \\(N\\) number data points. tis(default): vector length \\(S\\) (posterior sample size).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/tis.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Truncated importance sampling (TIS) — tis","text":"Ionides, Edward L. (2008). Truncated importance sampling. Journal Computational Graphical Statistics 17(2): 295–311.","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/tis.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Truncated importance sampling (TIS) — tis","text":"","code":"log_ratios <- -1 * example_loglik_array() r_eff <- relative_eff(exp(-log_ratios)) tis_result <- tis(log_ratios, r_eff = r_eff) str(tis_result) #> List of 2 #>  $ log_weights: num [1:1000, 1:32] 2.37 2.12 2.24 2.41 2.25 ... #>  $ diagnostics:List of 3 #>   ..$ pareto_k: num [1:32] 0 0 0 0 0 0 0 0 0 0 ... #>   ..$ n_eff   : num [1:32] 910 937 938 901 907 ... #>   ..$ r_eff   : num [1:32] 0.942 0.954 0.977 0.919 0.923 ... #>  - attr(*, \"norm_const_log\")= num [1:32] 9.28 9.04 9.24 9.09 9 ... #>  - attr(*, \"tail_len\")= num [1:32] 98 98 96 99 99 101 99 100 102 98 ... #>  - attr(*, \"r_eff\")= num [1:32] 0.942 0.954 0.977 0.919 0.923 ... #>  - attr(*, \"dims\")= int [1:2] 1000 32 #>  - attr(*, \"method\")= chr \"tis\" #>  - attr(*, \"class\")= chr [1:3] \"tis\" \"importance_sampling\" \"list\"  # extract smoothed weights lw <- weights(tis_result) # default args are log=TRUE, normalize=TRUE ulw <- weights(tis_result, normalize=FALSE) # unnormalized log-weights  w <- weights(tis_result, log=FALSE) # normalized weights (not log-weights) uw <- weights(tis_result, log=FALSE, normalize = FALSE) # unnormalized weights"},{"path":"https://mc-stan.org/loo/dev/reference/update.psis_loo_ss.html","id":null,"dir":"Reference","previous_headings":"","what":"Update psis_loo_ss objects — update.psis_loo_ss","title":"Update psis_loo_ss objects — update.psis_loo_ss","text":"Update psis_loo_ss objects","code":""},{"path":"https://mc-stan.org/loo/dev/reference/update.psis_loo_ss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update psis_loo_ss objects — update.psis_loo_ss","text":"","code":"# S3 method for class 'psis_loo_ss' update(   object,   ...,   data = NULL,   draws = NULL,   observations = NULL,   r_eff = 1,   cores = getOption(\"mc.cores\", 1),   loo_approximation = NULL,   loo_approximation_draws = NULL,   llgrad = NULL,   llhess = NULL )"},{"path":"https://mc-stan.org/loo/dev/reference/update.psis_loo_ss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update psis_loo_ss objects — update.psis_loo_ss","text":"object psis_loo_ss object update. ... Currently used. data, draws See loo_subsample.function(). observations subsample observations use. argument can take four (4) types arguments: NULL use observations. algorithm just uses standard loo() loo_approximate_posterior(). single integer specify number observations subsampled. vector integers provide indices used subset data. observations need subsampled scheme given estimator argument. psis_loo_ss object use observations used previous call loo_subsample(). r_eff Vector relative effective sample size estimates likelihood (exp(log_lik)) observation. related relative efficiency estimating normalizing term self-normalized importance sampling using posterior draws obtained MCMC. MCMC draws used r_eff provided reported PSIS effective sample sizes Monte Carlo error estimates can -optimistic. posterior draws (near) independent r_eff=1 can used. r_eff scalar (value used observations) vector length equal number observations. default value 1. See relative_eff() helper functions help computing r_eff. cores number cores use parallelization. defaults option mc.cores can set entire R session options(mc.cores = NUMBER). old option loo.cores now deprecated given precedence mc.cores loo.cores removed future release. version 2.0.0 default now 1 core mc.cores set, recommend using many (close many) cores possible. Note Windows 10 users: strongly recommended avoid using .Rprofile file set mc.cores (using cores argument setting mc.cores interactively script fine). loo_approximation type approximation loo_i's used? default \"plpd\" (log predictive density using posterior expectation). six different methods implemented approximate loo_i's (see references details): \"plpd\": uses lpd based point estimates (.e., \\(p(y_i|\\hat{\\theta})\\)). \"lpd\": uses lpds (,e., \\(p(y_i|y)\\)). \"tis\": uses truncated importance sampling approximate PSIS-LOO. \"waic\": uses waic (.e., \\(p(y_i|y) - p_{waic}\\)). \"waic_grad_marginal\": uses waic approximation using first order delta method posterior marginal variances approximate \\(p_{waic}\\) (ie. \\(p(y_i|\\hat{\\theta})\\)-p_waic_grad_marginal). Requires gradient likelihood function. \"waic_grad\": uses waic approximation using first order delta method posterior covariance approximate \\(p_{waic}\\) (ie. \\(p(y_i|\\hat{\\theta})\\)-p_waic_grad). Requires gradient likelihood function. \"waic_hess\": uses waic approximation using second order delta method posterior covariance approximate \\(p_{waic}\\) (ie. \\(p(y_i|\\hat{\\theta})\\)-p_waic_grad). Requires gradient Hessian likelihood function. point estimates \\(\\hat{\\theta}\\), posterior expectations parameters used. loo_approximation_draws number posterior draws used integrating posterior. used loo_approximation set \"lpd\", \"waic\", \"tis\". llgrad gradient log-likelihood. used loo_approximation \"waic_grad\", \"waic_grad_marginal\", \"waic_hess\". default NULL. llhess Hessian log-likelihood. used loo_approximation = \"waic_hess\". default NULL.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/update.psis_loo_ss.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update psis_loo_ss objects — update.psis_loo_ss","text":"psis_loo_ss object.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/update.psis_loo_ss.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Update psis_loo_ss objects — update.psis_loo_ss","text":"observations updated vector indices psis_loo_ss object supplied updated object exactly observations indicated vector psis_loo_ss object. single integer supplied, new observations sampled reach supplied sample size.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/waic.html","id":null,"dir":"Reference","previous_headings":"","what":"Widely applicable information criterion (WAIC) — waic","title":"Widely applicable information criterion (WAIC) — waic","text":"waic() methods can used compute WAIC pointwise log-likelihood. However, recommend LOO-CV using PSIS (implemented loo() function) PSIS provides useful diagnostics well effective sample size Monte Carlo estimates.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/waic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Widely applicable information criterion (WAIC) — waic","text":"","code":"waic(x, ...)  # S3 method for class 'array' waic(x, ...)  # S3 method for class 'matrix' waic(x, ...)  # S3 method for class '`function`' waic(x, ..., data = NULL, draws = NULL)  is.waic(x)"},{"path":"https://mc-stan.org/loo/dev/reference/waic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Widely applicable information criterion (WAIC) — waic","text":"x log-likelihood array, matrix, function. Methods (class) section, , detailed descriptions specify inputs method. draws, data, ... function method . See Methods (class) section details arguments.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/waic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Widely applicable information criterion (WAIC) — waic","text":"named list (class c(\"waic\", \"loo\")) components: estimates matrix two columns (\"Estimate\", \"SE\") three rows (\"elpd_waic\", \"p_waic\", \"waic\"). contains point estimates standard errors expected log pointwise predictive density (elpd_waic), effective number parameters (p_waic) information criterion waic (just -2 * elpd_waic, .e., converted deviance scale). pointwise matrix three columns (number rows equal number observations) containing pointwise contributions measures (elpd_waic, p_waic, waic).","code":""},{"path":"https://mc-stan.org/loo/dev/reference/waic.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Widely applicable information criterion (WAIC) — waic","text":"waic(array): \\(\\) \\(C\\) \\(N\\) array, \\(\\) number MCMC iterations per chain, \\(C\\) number chains, \\(N\\) number data points. waic(matrix): \\(S\\) \\(N\\) matrix, \\(S\\) size posterior sample (chains merged) \\(N\\) number data points. waic(`function`): function f() takes arguments data_i draws returns vector containing log-likelihood single observation evaluated posterior draw. function written , observation 1:N, evaluating   results vector length S (size posterior sample). log-likelihood function can also additional arguments data_i draws required. using function method arguments data draws must also specified call loo(): data: data frame matrix containing data (e.g. observed outcome predictors) needed compute pointwise log-likelihood. observation , ith row data passed data_i argument log-likelihood function. draws: object containing posterior draws parameters needed compute pointwise log-likelihood. Unlike data, indexed observation, observation entire object draws passed draws argument log-likelihood function. ... can used log-likelihood function takes additional arguments. arguments used like draws argument recycled observation.","code":"f(data_i = data[i,, drop=FALSE], draws = draws)"},{"path":"https://mc-stan.org/loo/dev/reference/waic.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Widely applicable information criterion (WAIC) — waic","text":"Watanabe, S. (2010). Asymptotic equivalence Bayes cross validation widely application information criterion singular learning theory. Journal Machine Learning Research 11, 3571-3594. Vehtari, ., Gelman, ., Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-cross-validation WAIC. Statistics Computing. 27(5), 1413–1432. doi:10.1007/s11222-016-9696-4 (journal version, preprint arXiv:1507.04544). Vehtari, ., Simpson, D., Gelman, ., Yao, Y., Gabry, J. (2024). Pareto smoothed importance sampling. Journal Machine Learning Research, 25(72):1-58. PDF","code":""},{"path":[]},{"path":"https://mc-stan.org/loo/dev/reference/waic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Widely applicable information criterion (WAIC) — waic","text":"","code":"### Array and matrix methods LLarr <- example_loglik_array() dim(LLarr) #> [1] 500   2  32  LLmat <- example_loglik_matrix() dim(LLmat) #> [1] 1000   32  waic_arr <- waic(LLarr) #> Warning:  #> 3 (9.4%) p_waic estimates greater than 0.4. We recommend trying loo instead. waic_mat <- waic(LLmat) #> Warning:  #> 3 (9.4%) p_waic estimates greater than 0.4. We recommend trying loo instead. identical(waic_arr, waic_mat) #> [1] TRUE   # \\dontrun{ log_lik1 <- extract_log_lik(stanfit1) #> Error: object 'stanfit1' not found log_lik2 <- extract_log_lik(stanfit2) #> Error: object 'stanfit2' not found (waic1 <- waic(log_lik1)) #> Error: object 'log_lik1' not found (waic2 <- waic(log_lik2)) #> Error: object 'log_lik2' not found print(compare(waic1, waic2), digits = 2) #> Warning: 'compare' is deprecated. #> Use 'loo_compare' instead. #> See help(\"Deprecated\") #> Error: object 'waic1' not found # }"},{"path":"https://mc-stan.org/loo/dev/reference/weights.importance_sampling.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract importance sampling weights — weights.importance_sampling","title":"Extract importance sampling weights — weights.importance_sampling","text":"Extract importance sampling weights","code":""},{"path":"https://mc-stan.org/loo/dev/reference/weights.importance_sampling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract importance sampling weights — weights.importance_sampling","text":"","code":"# S3 method for class 'importance_sampling' weights(object, ..., log = TRUE, normalize = TRUE)"},{"path":"https://mc-stan.org/loo/dev/reference/weights.importance_sampling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract importance sampling weights — weights.importance_sampling","text":"object object returned psis(), tis(), sis(). ... Ignored. log weights returned log scale? Defaults TRUE. normalize weights normalized? Defaults TRUE.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/weights.importance_sampling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract importance sampling weights — weights.importance_sampling","text":"weights() method returns object dimensions log_weights component object. normalize log arguments control whether returned weights normalized whether return log scale.","code":""},{"path":"https://mc-stan.org/loo/dev/reference/weights.importance_sampling.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract importance sampling weights — weights.importance_sampling","text":"","code":"# See the examples at help(\"psis\")"},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-2809000","dir":"Changelog","previous_headings":"","what":"loo 2.8.0.9000","title":"loo 2.8.0.9000","text":"Items next release go ","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-280","dir":"Changelog","previous_headings":"","what":"loo 2.8.0","title":"loo 2.8.0","text":"CRAN release: 2024-07-03 make E_loo Pareto-k diagnostic robust @avehtari #251 update psis paper reference @avehtari #252 update PSIS references vignettes @jgabry #254 fix loo_moment_match p_loo computation @avehtari #257 fix loo_moment_matching NaN issue @avehtari #259 catch Stan log_prob exceptions inside moment matching @avehtari #262 Fix E_loo_khat error posterior::pareto_khat returns NA @jgabry #264 update psis ref + minor typo fixes @avehtari #266 update PSIS ref + link Nabiximols study Jacobian correction @avehtari #267 Fix issue pareto_khat output longer list @n-kall #269 fix equations loo-glossary @avehtari #268","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-270","dir":"Changelog","previous_headings":"","what":"loo 2.7.0","title":"loo 2.7.0","text":"CRAN release: 2024-02-24","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"major-changes-2-7-0","dir":"Changelog","previous_headings":"","what":"Major changes","title":"loo 2.7.0","text":"New sample size specific diagnostic threshold Pareto k. pre-2022 version PSIS paper recommended diagnostic thresholds k < 0.5 \"good\", 0.5 <= k < 0.7 \"ok\", 0.7 <= k < 1 \"bad\", k>=1 \"bad\". 2022 revision PSIS paper now recommends k < min(1 - 1/log10(S), 0.7) \"good\", min(1 - 1/log10(S), 0.7) <= k < 1 \"bad\", k > 1 \"bad\", S sample size. now one fewer diagnostic threshold (\"ok\" removed), important threshold now depends sample size S. sample sizes 100, 320, 1000, 2200, 10000 sample size specific part 1 - 1/log10(S) corresponds thresholds 0.5, 0.6, 0.67, 0.7, 0.75. Even sample size grows, bias PSIS estimate dominates 0.7 <= k < 1, thus diagnostic threshold good capped 0.7 (k > 1, mean exist bias valid measure). new recommended thresholds based careful bias-variance analysis PSIS based truncated Pareto sums theory. use Stan default 4000 posterior draws, 0.7 threshold roughly , fewer warnings diagnostic message 0.5 <= k < 0.7. use smaller sample sizes may see diagnostic messages threshold less 0.7, can simply increase sample size 2200 get threshold 0.7. warnings r_eff argument provided, default now r_eff = 1. summary print output showing MCSE ESS now shows diagnostic information range r_eff. change made reduce unnecessary warnings. use r_eff change expected value elpd_loo, p_loo, Pareto k, needed estimate MCSE ESS. Thus better show diagnostic information r_eff MCSE ESS values shown.","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"other-changes-2-7-0","dir":"Changelog","previous_headings":"","what":"Other changes","title":"loo 2.7.0","text":"Make Pareto k Inf NA @topipa #224 Fix bug E_loo() type variance @jgabry #226 E_loo() now allows type=\"sd\" @jgabry #226 update array syntax vignettes @jgabry #229 Fix unbalanced knitr backticks @jgabry #232 include cc-4.0 license documentation @jgabry #216 Add order statistic warning @yannmclatchie #230 pointwise() convenience function extracting pointwise estimates @jgabry #241 use new k threshold @avehtari #235 simplify mcse_elpd using log-normal approximation @avehtari #246 show NA n_eff/ESS k > k_threshold @avehtari #248 improved E_loo() Pareto-k diagnostics @avehtari #247 Doc improvement loo_subsample.R @avehtari #238 Fix typo deprecations LFO vignette @jgabry #244 Register internal S3 methods @jgabry #239 Avoid R cmd check NOTEs internal functions @jgabry #240 fix R cmd check note due importance_sampling roxygen template @jgabry #233 fix R cmd check notes @jgabry #242","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-260","dir":"Changelog","previous_headings":"","what":"loo 2.6.0","title":"loo 2.6.0","text":"CRAN release: 2023-03-31","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"new-features-2-6-0","dir":"Changelog","previous_headings":"","what":"New features","title":"loo 2.6.0","text":"New loo_predictive_metric() function computing estimates leave-one-predictive metrics: mean absolute error, mean squared error root mean squared error continuous predictions, accuracy balanced accuracy binary classification. (#202, @LeeviLindgren) New functions crps(), scrps(), loo_crps(), loo_scrps() computing (scaled) continuously ranked probability score. (#203, @LeeviLindgren) New vignette “Mixture leave-one-cross-validation high-dimensional Bayesian models.” demonstration mixture estimators proposed Silva Zanella (2022). (#210)","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"bug-fixes-2-6-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"loo 2.6.0","text":"Minor fix model names displayed loo_model_weights() make consistent loo_compare(). (#217)","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-251","dir":"Changelog","previous_headings":"","what":"loo 2.5.1","title":"loo 2.5.1","text":"CRAN release: 2022-03-24 Fix R CMD check error M1 Mac","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-250","dir":"Changelog","previous_headings":"","what":"loo 2.5.0","title":"loo 2.5.0","text":"CRAN release: 2022-03-16","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"improvements-2-5-0","dir":"Changelog","previous_headings":"","what":"Improvements","title":"loo 2.5.0","text":"New Frequently Asked Questions page package website. (#143) Speed improvement simplifying normalization fitting generalized Pareto distribution. (#187, @sethaxen) Added parallel likelihood computation speedup loo_subsample() using posterior approximations. (#171, @kdubovikov) Switch unit tests Travis GitHub Actions. (#164)","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"bug-fixes-2-5-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"loo 2.5.0","text":"Fixed bug causing normalizing constant PSIS (log) weights get updated performing moment matching save_psis = TRUE (#166, @fweber144).","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-241","dir":"Changelog","previous_headings":"","what":"loo 2.4.1","title":"loo 2.4.1","text":"CRAN release: 2020-12-09 Fixed issue reported CRAN one vignettes errored M1 Mac due RStan’s dependency V8.","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-240","dir":"Changelog","previous_headings":"","what":"loo 2.4.0","title":"loo 2.4.0","text":"CRAN release: 2020-12-05","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"bug-fixes-2-4-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"loo 2.4.0","text":"Fixed bug relative_eff.function() caused error Windows using multiple cores. (#152) Fixed potential numerical issue loo_moment_match() split=TRUE. (#153) Fixed potential integer overflow loo_moment_match(). (#155, @ecmerkle) Fixed relative_eff() used posterior::draws_array. (#161, @rok-cesnovar)","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"new-features-2-4-0","dir":"Changelog","previous_headings":"","what":"New features","title":"loo 2.4.0","text":"New generic function elpd() (methods matrices arrays) computing expected log predictive density new data log predictive density observed data. new vignette demonstrates using function K-fold CV rstan. (#159, @bnicenboim)","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-231","dir":"Changelog","previous_headings":"","what":"loo 2.3.1","title":"loo 2.3.1","text":"CRAN release: 2020-07-14 Fixed bug loo_moment_match() prevented ... arguments used correctly. (#149)","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-230","dir":"Changelog","previous_headings":"","what":"loo 2.3.0","title":"loo 2.3.0","text":"CRAN release: 2020-07-07 Added Topi Paananen Paul Bürkner coauthors. New function loo_moment_match() (new vignette), can used update loo object Pareto k estimates large. (#130) log weights provided importance sampling functions psis(), tis(), sis() longer largest log ratio subtracted returned user. less confusing anyone using weights() method make importance sampler. (#112, #146) MCSE calculation now deterministic (#116, #147)","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-220","dir":"Changelog","previous_headings":"","what":"loo 2.2.0","title":"loo 2.2.0","text":"CRAN release: 2019-12-19 Added Mans Magnusson coauthor. New functions loo_subsample() loo_approximate_posterior() (new vignette) PSIS-LOO large data. (#113) Added support standard importance sampling truncated importance sampling (functions sis() tis()). (#125) compare() now throws deprecation warning suggesting loo_compare(). (#93) smaller threshold used checking uniqueness tail values. (#124) WAIC, warnings thrown running waic() printing waic object. (#117, @mcol) Use markdown syntax roxygen documentation wherever possible. (#108)","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-210","dir":"Changelog","previous_headings":"","what":"loo 2.1.0","title":"loo 2.1.0","text":"CRAN release: 2019-03-13 New function loo_compare() model comparison eventually replace existing compare() function. (#93) New vignette LOO non-factorizable joint Gaussian models. (#75) New vignette “leave-future-” cross-validation time series models. (#90) New glossary page (use help(\"loo-glossary\")) definitions key terms. (#81) New se_diff column model comparison results. (#78) Improved stability psis() log_ratios small. (#74) Allow r_eff=NA suppress warning specifying r_eff applicable (.e., draws MCMC). (#72) Update effective sample size calculations match RStan’s version. (#85) Naming k-fold helper functions now matches scikit-learn. (#96)","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-200","dir":"Changelog","previous_headings":"","what":"loo 2.0.0","title":"loo 2.0.0","text":"CRAN release: 2018-04-11 major release many changes. Whenever possible opted deprecate rather remove old functionality, possible old code accesses elements inside loo objects position rather name may error. New package documentation website http://mc-stan.org/loo/ vignettes, function reference, news. Updated existing vignette added two new vignettes demonstrating use package. New function psis() replaces psislw() (now deprecated). version implements improvements PSIS algorithm described latest version https://arxiv.org/abs/1507.02646. Additional diagnostic information now also provided, including PSIS effective sample sizes. New weights() method extracting smoothed weights psis object. Arguments log normalize control whether weights returned log scale whether normalized. Updated interface loo() methods integrate nicely new PSIS algorithm. Methods log-likelihood arrays, matrices, functions provided. Several arguments changed, particularly loo.function method. documentation help(\"loo\") updated describe new behavior. structure objects returned loo() function also changed slightly, described Value section help(\"loo\", package = \"loo\"). New function loo_model_weights() computes weights model averaging described https://arxiv.org/abs/1704.02030. Implemented methods include stacking predictive distributions, pseudo-BMA weighting pseudo-BMA+ weighting Bayesian bootstrap. Setting options(loo.cores=...) now deprecated favor options(mc.cores=...). now, loo.cores mc.cores options set, preference given loo.cores removed future release. (thanks @cfhammill) New functions example_loglik_array() example_loglik_matrix() provide objects use examples tests. comparing two models compare(), first column output now elpd difference model first row. New helper functions splitting observations K-fold CV: kfold_split_random(), kfold_split_balanced(), kfold_split_stratified(). Additional helper functions implementing K-fold CV included future releases.","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-110","dir":"Changelog","previous_headings":"","what":"loo 1.1.0","title":"loo 1.1.0","text":"CRAN release: 2017-03-27 Introduce E_loo() function computing weighted expectations (means, variances, quantiles).","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-100","dir":"Changelog","previous_headings":"","what":"loo 1.0.0","title":"loo 1.0.0","text":"CRAN release: 2016-12-16 pareto_k_table() pareto_k_ids() convenience functions quickly identifying problematic observations pareto k values now grouped (-Inf, 0.5], (0.5, 0.7], (0.7, 1], (1, Inf) (didn’t used include 0.7) warning messages now issued psislw() instead print.loo print.loo() shows table pareto k estimates (k > 0.7) Add argument compare() allow loo objects provided list rather '...' Update references point published paper","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-016","dir":"Changelog","previous_headings":"","what":"loo 0.1.6","title":"loo 0.1.6","text":"CRAN release: 2016-03-23 GitHub repository moved @jgabry @stan-dev Better error messages extract_log_lik() Fix example code vignette (thanks GitHub user @krz)","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-015","dir":"Changelog","previous_headings":"","what":"loo 0.1.5","title":"loo 0.1.5","text":"CRAN release: 2016-02-12 Add warnings p_waic estimates greather 0.4 Improve line coverage tests 100% Update references documentation Remove model weights compare(). previous versions loo model weights also reported compare(). removed weights based point estimate elpd values ignoring uncertainty. currently working something similar weights also accounts uncertainty, included future versions loo.","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-014","dir":"Changelog","previous_headings":"","what":"loo 0.1.4","title":"loo 0.1.4","text":"CRAN release: 2015-12-10 update makes easier package authors using loo write tests involve running loo function. also includes minor bug fixes additional unit tests. Highlights: Don’t call functions parallel package cores=1. Return entire vector/matrix smoothed weights rather summary statistic psislw function called interactive session. Test coverage > 80%","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-013","dir":"Changelog","previous_headings":"","what":"loo 0.1.3","title":"loo 0.1.3","text":"CRAN release: 2015-09-18 update provides several important improvements, notably alternative method specifying pointwise log-likelihood reduces memory usage allows loo used larger datasets. update also makes easier incorporate loo’s functionality packages. Add Ben Goodrich contributor S3 generics matrix function methods loo() waic(). matrix method provide functionality previous versions loo (taking log-likelihood matrix input). function method allows user provide function computing log-likelihood data posterior draws (also provided user). function method less memory intensive make possible use loo models fit larger amounts data . Separate plot print methods. plot also provides label_points argument, , TRUE, label Pareto k points greater 1/2 index number corresponding observation. plot method also now warns Inf/NA/NaN values k shown plot. compare now returns model weights accepts two inputs. Allow setting number cores using options(loo.cores = NUMBER).","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-012","dir":"Changelog","previous_headings":"","what":"loo 0.1.2","title":"loo 0.1.2","text":"CRAN release: 2015-07-17 Updates names package reflect name changes accompanying paper.","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-011","dir":"Changelog","previous_headings":"","what":"loo 0.1.1","title":"loo 0.1.1","text":"Better handling special cases Deprecates loo_and_waic function favor separate functions loo waic Deprecates loo_and_waic_diff. Use compare instead.","code":""},{"path":"https://mc-stan.org/loo/dev/news/index.html","id":"loo-010","dir":"Changelog","previous_headings":"","what":"loo 0.1.0","title":"loo 0.1.0","text":"CRAN release: 2015-06-26 Initial release","code":""}]
