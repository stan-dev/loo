<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!-- upstream: inst/BS5/templates/head.html; pkgdown-version: 2.1.3, fe04924 --><!-- https://github.com/r-lib/pkgdown/tree/fe04924b3df129bea60ac871614b01d87bcae147 --><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Using the loo package (version &gt;= 2.0.0) • loo</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Source_Sans_3-0.4.10/font.css" rel="stylesheet">
<link href="../deps/Source_Code_Pro-0.4.10/font.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- Font Awesome 7.0.1 for Bluesky icon --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.1/css/all.min.css" referrerpolicy="no-referrer">
<!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Using the loo package (version &gt;= 2.0.0)">
<meta name="robots" content="noindex">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <!-- upstream: inst/BS5/templates/navbar.html; pkgdown-version: 2.1.3, fe04924 -->
<!-- https://github.com/r-lib/pkgdown/tree/fe04924b3df129bea60ac871614b01d87bcae147 -->
<nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">


    <a class="navbar-brand me-2" href="../index.html">
      <!-- Add Stan logo -->
      <picture><source type="image/svg+xml" srcset="../logo.svg"><img src="../logo.png" class="stan-logo" alt="Stan blue hex logo"></source></picture>
      loo
    </a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">2.8.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../index.html" aria-label="Go to homepage"><span class="fa fa-home fa-lg"></span></a></li>
<li class="active nav-item"><a class="nav-link" href="../articles/index.html">Vignettes</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Functions</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-other-packages" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Other Packages</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-other-packages">
<li><a class="external-link dropdown-item" href="https://mc-stan.org/rstan">rstan</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/cmdstanr">cmdstanr</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/rstanarm">rstanarm</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/bayesplot">bayesplot</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/shinystan">shinystan</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/projpred">projpred</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/rstantools">rstantools</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/posterior">posterior</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://mc-stan.org/about/">About Stan</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://bsky.app/profile/did:plc:qznndgdnkem2yryu7ipqbpv7" aria-label="Visit our Bluesky profile"><span class="fa fa-brands fa-bluesky"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://twitter.com/mcmc_stan" aria-label="Visit our Twitter profile"><span class="fa fa-twitter"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://discourse.mc-stan.org/" aria-label="Visit our forums"><span class="fa fa-users"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/stan-dev/loo/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch">
<li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul>
</li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.svg" class="logo" alt=""><h1>Using the loo package (version &gt;= 2.0.0)</h1>
                        <h4 data-toc-skip class="author">Aki Vehtari and
Jonah Gabry</h4>
            
            <h4 data-toc-skip class="date">2025-09-23</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/stan-dev/loo/blob/HEAD/vignettes/loo2-example.Rmd" class="external-link"><code>vignettes/loo2-example.Rmd</code></a></small>
      <div class="d-none name"><code>loo2-example.Rmd</code></div>
    </div>

    
    
<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{Using the loo package}
-->
<p><strong>NOTE: We recommend viewing the fully rendered version of this
vignette online at <a href="https://mc-stan.org/loo/articles/" class="uri">https://mc-stan.org/loo/articles/</a></strong></p>
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>This vignette demonstrates how to use the <strong>loo</strong>
package to carry out Pareto smoothed importance-sampling leave-one-out
cross-validation (PSIS-LOO) for purposes of model checking and model
comparison.</p>
<p>In this vignette we can’t provide all necessary background
information on PSIS-LOO and its diagnostics (Pareto
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
and effective sample size), so we encourage readers to refer to the
following papers for more details:</p>
<ul>
<li><p>Vehtari, A., Gelman, A., and Gabry, J. (2017). Practical Bayesian
model evaluation using leave-one-out cross-validation and WAIC.
<em>Statistics and Computing</em>. 27(5), 1413–1432.
:10.1007/s11222-016-9696-4. Links: <a href="https://link.springer.com/article/10.1007/s11222-016-9696-4" class="external-link">published</a>
| <a href="https://arxiv.org/abs/1507.04544" class="external-link">preprint
arXiv</a>.</p></li>
<li><p>Vehtari, A., Simpson, D., Gelman, A., Yao, Y., and Gabry, J.
(2024). Pareto smoothed importance sampling. <em>Journal of Machine
Learning Research</em>, 25(72):1-58. <a href="https://jmlr.org/papers/v25/19-556.html" class="external-link">PDF</a></p></li>
</ul>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<p>In addition to the <strong>loo</strong> package, we’ll also be using
<strong>rstanarm</strong> and <strong>bayesplot</strong>:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://mc-stan.org/rstanarm/" class="external-link">"rstanarm"</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://mc-stan.org/bayesplot/" class="external-link">"bayesplot"</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://mc-stan.org/loo/">"loo"</a></span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="example-poisson-vs-negative-binomial-for-the-roaches-dataset">Example: Poisson vs negative binomial for the roaches dataset<a class="anchor" aria-label="anchor" href="#example-poisson-vs-negative-binomial-for-the-roaches-dataset"></a>
</h2>
<div class="section level3">
<h3 id="background-and-model-fitting">Background and model fitting<a class="anchor" aria-label="anchor" href="#background-and-model-fitting"></a>
</h3>
<p>The Poisson and negative binomial regression models used below in our
example, as well as the <code>stan_glm</code> function used to fit the
models, are covered in more depth in the <strong>rstanarm</strong>
vignette <a href="http://mc-stan.org/rstanarm/articles/count.html" class="external-link"><em>Estimating
Generalized Linear Models for Count Data with rstanarm</em></a>. In the
rest of this vignette we will assume the reader is already familiar with
these kinds of models.</p>
<div class="section level4">
<h4 id="roaches-data">Roaches data<a class="anchor" aria-label="anchor" href="#roaches-data"></a>
</h4>
<p>The example data we’ll use comes from Chapter 8.3 of <a href="https://sites.stat.columbia.edu/gelman/arm/" class="external-link">Gelman and Hill
(2007)</a>. We want to make inferences about the efficacy of a certain
pest management system at reducing the number of roaches in urban
apartments. Here is how Gelman and Hill describe the experiment and data
(pg. 161):</p>
<blockquote>
<p>the treatment and control were applied to 160 and 104 apartments,
respectively, and the outcome measurement
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">y_i</annotation></semantics></math>
in each apartment
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
was the number of roaches caught in a set of traps. Different apartments
had traps for different numbers of days</p>
</blockquote>
<p>In addition to an intercept, the regression predictors for the model
are <code>roach1</code>, the pre-treatment number of roaches (rescaled
above to be in units of hundreds), the treatment indicator
<code>treatment</code>, and a variable indicating whether the apartment
is in a building restricted to elderly residents <code>senior</code>.
Because the number of days for which the roach traps were used is not
the same for all apartments in the sample, we use the
<code>offset</code> argument to specify that <code>log(exposure2)</code>
should be added to the linear predictor.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># the 'roaches' data frame is included with the rstanarm package</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">roaches</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">roaches</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># rescale to units of hundreds of roaches</span></span>
<span><span class="va">roaches</span><span class="op">$</span><span class="va">roach1</span> <span class="op">&lt;-</span> <span class="va">roaches</span><span class="op">$</span><span class="va">roach1</span> <span class="op">/</span> <span class="fl">100</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="fit-poisson-model">Fit Poisson model<a class="anchor" aria-label="anchor" href="#fit-poisson-model"></a>
</h4>
<p>We’ll fit a simple Poisson regression model using the
<code>stan_glm</code> function from the <strong>rstanarm</strong>
package.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit1</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html" class="external-link">stan_glm</a></span><span class="op">(</span></span>
<span>    formula <span class="op">=</span> <span class="va">y</span> <span class="op">~</span> <span class="va">roach1</span> <span class="op">+</span> <span class="va">treatment</span> <span class="op">+</span> <span class="va">senior</span>,</span>
<span>    offset <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">exposure2</span><span class="op">)</span>,</span>
<span>    data <span class="op">=</span> <span class="va">roaches</span>,</span>
<span>    family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">poisson</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"log"</span><span class="op">)</span>,</span>
<span>    prior <span class="op">=</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/priors.html" class="external-link">normal</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2.5</span>, autoscale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>    prior_intercept <span class="op">=</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/priors.html" class="external-link">normal</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">5</span>, autoscale <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>    seed <span class="op">=</span> <span class="fl">12345</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
<p>Usually we would also run posterior predictive checks as shown in the
<strong>rstanarm</strong> vignette <a href="http://mc-stan.org/rstanarm/articles/count.html" class="external-link">Estimating
Generalized Linear Models for Count Data with rstanarm</a>, but here we
focus only on methods provided by the <strong>loo</strong> package.</p>
<p><br></p>
</div>
</div>
<div class="section level3">
<h3 id="using-the-loo-package-for-model-checking-and-comparison">Using the <strong>loo</strong> package for model checking and
comparison<a class="anchor" aria-label="anchor" href="#using-the-loo-package-for-model-checking-and-comparison"></a>
</h3>
<p><em>Although cross-validation is mostly used for model comparison, it
is also useful for model checking.</em></p>
<div class="section level4">
<h4 id="computing-psis-loo-and-checking-diagnostics">Computing PSIS-LOO and checking diagnostics<a class="anchor" aria-label="anchor" href="#computing-psis-loo-and-checking-diagnostics"></a>
</h4>
<p>We start by computing PSIS-LOO with the <code>loo</code> function.
Since we fit our model using <strong>rstanarm</strong> we can use the
<code>loo</code> method for <code>stanreg</code> objects (fitted model
objects from <strong>rstanarm</strong>), which doesn’t require us to
first extract the pointwise log-likelihood values. If we had written our
own Stan program instead of using <strong>rstanarm</strong> we would
pass an array or matrix of log-likelihood values to the <code>loo</code>
function (see, e.g. <code><a href="../reference/loo.html">help("loo.array", package = "loo")</a></code>).
We’ll also use the argument <code>save_psis = TRUE</code> to save some
intermediate results to be re-used later.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">loo1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/loo.html">loo</a></span><span class="op">(</span><span class="va">fit1</span>, save_psis <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p><code>loo</code> gives us warnings about the Pareto diagnostics,
which indicate that for some observations the leave-one-out posteriors
are different enough from the full posterior that importance-sampling is
not able to correct the difference. We can see more details by printing
the <code>loo</code> object.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">loo1</span><span class="op">)</span></span></code></pre></div>
<p>The table shows us a summary of Pareto
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
diagnostic, which is used to assess the reliability of the estimates. In
addition to the proportion of leave-one-out folds with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
values in different intervals, the minimum of the effective sample sizes
in that category is shown to give idea why higher
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
values are bad. Since we have some
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k&gt;1</annotation></semantics></math>,
we are not able to compute an estimate for the Monte Carlo standard
error (SE) of the expected log predictive density
(<code>elpd_loo</code>) and <code>NA</code> is displayed. (Full details
on the interpretation of the Pareto
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
diagnostics are available in the Vehtari, Gelman, and Gabry (2017) and
Vehtari, Simpson, Gelman, Yao, and Gabry (2024) papers referenced at the
top of this vignette.)</p>
<p>In this case the <code>elpd_loo</code> estimate should not be
considered reliable. If we had a well-specified model we would expect
the estimated effective number of parameters (<code>p_loo</code>) to be
smaller than or similar to the total number of parameters in the model.
Here <code>p_loo</code> is almost 300, which is about 70 times the total
number of parameters in the model, indicating severe model
misspecification.</p>
</div>
<div class="section level4">
<h4 id="plotting-pareto-k-diagnostics">Plotting Pareto
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
diagnostics<a class="anchor" aria-label="anchor" href="#plotting-pareto-k-diagnostics"></a>
</h4>
<p>Using the <code>plot</code> method on our <code>loo1</code> object
produces a plot of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
values (in the same order as the observations in the dataset used to fit
the model) with horizontal lines corresponding to the same categories as
in the printed output above.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">loo1</span><span class="op">)</span></span></code></pre></div>
<p>This plot is useful to quickly see the distribution of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
values, but it’s often also possible to see structure with respect to
data ordering. In our case this is mild, but there seems to be a block
of data that is somewhat easier to predict (indices around 90–150).
Unfortunately even for these data points we see some high
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
values.</p>
</div>
<div class="section level4">
<h4 id="marginal-posterior-predictive-checks">Marginal posterior predictive checks<a class="anchor" aria-label="anchor" href="#marginal-posterior-predictive-checks"></a>
</h4>
<p>The <code>loo</code> package can be used in combination with the
<code>bayesplot</code> package for leave-one-out cross-validation
marginal posterior predictive checks <a href="https://arxiv.org/abs/1709.01449" class="external-link">Gabry et al (2018)</a>. LOO-PIT
values are cumulative probabilities for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">y_i</annotation></semantics></math>
computed using the LOO marginal predictive distributions
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>y</mi><mrow><mi>−</mi><mi>i</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(y_i|y_{-i})</annotation></semantics></math>.
For a good model, the distribution of LOO-PIT values should be uniform.
In the following QQ-plot the LOO-PIT values for our model (y-axi) is
compared to standard uniform distribution (x-axis).</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">yrep</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstantools/reference/posterior_predict.html" class="external-link">posterior_predict</a></span><span class="op">(</span><span class="va">fit1</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/PPC-loo.html" class="external-link">ppc_loo_pit_qq</a></span><span class="op">(</span></span>
<span>  y <span class="op">=</span> <span class="va">roaches</span><span class="op">$</span><span class="va">y</span>,</span>
<span>  yrep <span class="op">=</span> <span class="va">yrep</span>,</span>
<span>  lw <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/weights.html" class="external-link">weights</a></span><span class="op">(</span><span class="va">loo1</span><span class="op">$</span><span class="va">psis_object</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The excessive number of LOO-PIT values close to 0 indicates that the
model is under-dispersed compared to the data, and we should consider a
model that allows for greater dispersion.</p>
</div>
</div>
<div class="section level3">
<h3 id="try-alternative-model-with-more-flexibility">Try alternative model with more flexibility<a class="anchor" aria-label="anchor" href="#try-alternative-model-with-more-flexibility"></a>
</h3>
<p>Here we will try <a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution" class="external-link">negative
binomial</a> regression, which is commonly used for overdispersed count
data.<br>
Unlike the Poisson distribution, the negative binomial distribution
allows the conditional mean and variance of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>
to differ.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html" class="external-link">update</a></span><span class="op">(</span><span class="va">fit1</span>, family <span class="op">=</span> <span class="va">neg_binomial_2</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">loo2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/loo.html">loo</a></span><span class="op">(</span><span class="va">fit2</span>, save_psis <span class="op">=</span> <span class="cn">TRUE</span>, cores <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">loo2</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">loo2</span>, label_points <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p>Using the <code>label_points</code> argument will label any
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
values larger than the diagnostic threshold with the index of the
corresponding data point. These high values are often the result of
model misspecification and frequently correspond to data points that
would be considered ``outliers’’ in the data and surprising according to
the model <a href="https://arxiv.org/abs/1709.01449" class="external-link">Gabry et al
(2019)</a>. Unfortunately, while large
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
values are a useful indicator of model misspecification, small
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
values are not a guarantee that a model is well-specified.</p>
<p>If there are a small number of problematic
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
values then we can use a feature in <strong>rstanarm</strong> that lets
us refit the model once for each of these problematic observations. Each
time the model is refit, one of the observations with a high
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
value is omitted and the LOO calculations are performed exactly for that
observation. The results are then recombined with the approximate LOO
calculations already carried out for the observations without
problematic
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
values:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/any.html" class="external-link">any</a></span><span class="op">(</span><span class="fu"><a href="../reference/pareto-k-diagnostic.html">pareto_k_values</a></span><span class="op">(</span><span class="va">loo2</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">0.7</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">loo2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/loo.html">loo</a></span><span class="op">(</span><span class="va">fit2</span>, save_psis <span class="op">=</span> <span class="cn">TRUE</span>, k_threshold <span class="op">=</span> <span class="fl">0.7</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">loo2</span><span class="op">)</span></span></code></pre></div>
<p>In the print output we can see that the Monte Carlo SE is small
compared to the other uncertainties.</p>
<p>On the other hand, <code>p_loo</code> is about 7 and still a bit
higher than the total number of parameters in the model. This indicates
that there is almost certainly still some degree of model
misspecification, but this is much better than the <code>p_loo</code>
estimate for the Poisson model.</p>
<p>For further model checking we again examine the LOO-PIT values.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">yrep</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstantools/reference/posterior_predict.html" class="external-link">posterior_predict</a></span><span class="op">(</span><span class="va">fit2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/PPC-loo.html" class="external-link">ppc_loo_pit_qq</a></span><span class="op">(</span><span class="va">roaches</span><span class="op">$</span><span class="va">y</span>, <span class="va">yrep</span>, lw <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/weights.html" class="external-link">weights</a></span><span class="op">(</span><span class="va">loo2</span><span class="op">$</span><span class="va">psis_object</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>The plot for the negative binomial model looks better than the
Poisson plot, but we still see that this model is not capturing all of
the essential features in the data.</p>
</div>
<div class="section level3">
<h3 id="comparing-the-models-on-expected-log-predictive-density">Comparing the models on expected log predictive density<a class="anchor" aria-label="anchor" href="#comparing-the-models-on-expected-log-predictive-density"></a>
</h3>
<p>We can use the <code>loo_compare</code> function to compare our two
models on expected log predictive density (ELPD) for new data:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/loo_compare.html">loo_compare</a></span><span class="op">(</span><span class="va">loo1</span>, <span class="va">loo2</span><span class="op">)</span></span></code></pre></div>
<p>The difference in ELPD is much larger than several times the
estimated standard error of the difference again indicating that the
negative-binomial model is xpected to have better predictive performance
than the Poisson model. However, according to the LOO-PIT checks there
is still some misspecification, and a reasonable guess is that a hurdle
or zero-inflated model would be an improvement (we leave that for
another case study).</p>
<p><br></p>
</div>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<p>Gabry, J., Simpson, D., Vehtari, A., Betancourt, M. and Gelman, A.
(2019), Visualization in Bayesian workflow. <em>J. R. Stat. Soc. A</em>,
182: 389-402. :10.1111/rssa.12378. (<a href="https://rss.onlinelibrary.wiley.com/doi/full/10.1111/rssa.12378" class="external-link">journal
version</a>, <a href="https://arxiv.org/abs/1709.01449" class="external-link">arXiv
preprint</a>, <a href="https://github.com/jgabry/bayes-vis-paper" class="external-link">code
on GitHub</a>) <a id="gabry2019"></a></p>
<p>Gelman, A. and Hill, J. (2007). <em>Data Analysis Using Regression
and Multilevel/Hierarchical Models.</em> Cambridge University Press,
Cambridge, UK.</p>
<p>Vehtari, A., Gelman, A., and Gabry, J. (2017). Practical Bayesian
model evaluation using leave-one-out cross-validation and WAIC.
<em>Statistics and Computing</em>. 27(5), 1413–1432.
:10.1007/s11222-016-9696-4. <a href="https://link.springer.com/article/10.1007/s11222-016-9696-4" class="external-link">online</a>,
<a href="https://arxiv.org/abs/1507.04544" class="external-link">arXiv preprint
arXiv:1507.04544</a>.</p>
<p>Vehtari, A., Simpson, D., Gelman, A., Yao, Y., and Gabry, J. (2024).
Pareto smoothed importance sampling. <em>Journal of Machine Learning
Research</em>, 25(72):1-58. <a href="https://jmlr.org/papers/v25/19-556.html" class="external-link">PDF</a></p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Aki Vehtari, Jonah Gabry, Måns Magnusson, Yuling Yao, Paul-Christian Bürkner, Topi Paananen, Andrew Gelman.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
