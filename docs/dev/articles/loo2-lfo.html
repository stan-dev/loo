<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!-- upstream: inst/BS5/templates/head.html; pkgdown-version: 2.1.3, fe04924 --><!-- https://github.com/r-lib/pkgdown/tree/fe04924b3df129bea60ac871614b01d87bcae147 --><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Approximate leave-future-out cross-validation for Bayesian time series models • loo</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Source_Sans_3-0.4.10/font.css" rel="stylesheet">
<link href="../deps/Source_Code_Pro-0.4.10/font.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- Font Awesome 7.0.1 for Bluesky icon --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.1/css/all.min.css" referrerpolicy="no-referrer">
<!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Approximate leave-future-out cross-validation for Bayesian time series models">
<meta name="robots" content="noindex">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <!-- upstream: inst/BS5/templates/navbar.html; pkgdown-version: 2.1.3, fe04924 -->
<!-- https://github.com/r-lib/pkgdown/tree/fe04924b3df129bea60ac871614b01d87bcae147 -->
<nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">


    <a class="navbar-brand me-2" href="../index.html">
      <!-- Add Stan logo -->
      <picture><source type="image/svg+xml" srcset="../logo.svg"><img src="../logo.png" class="stan-logo" alt="Stan blue hex logo"></source></picture>
      loo
    </a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">2.8.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../index.html" aria-label="Go to homepage"><span class="fa fa-home fa-lg"></span></a></li>
<li class="active nav-item"><a class="nav-link" href="../articles/index.html">Vignettes</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Functions</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-other-packages" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Other Packages</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-other-packages">
<li><a class="external-link dropdown-item" href="https://mc-stan.org/rstan">rstan</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/cmdstanr">cmdstanr</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/rstanarm">rstanarm</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/bayesplot">bayesplot</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/shinystan">shinystan</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/projpred">projpred</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/rstantools">rstantools</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/posterior">posterior</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://mc-stan.org/about/">About Stan</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://bsky.app/profile/did:plc:qznndgdnkem2yryu7ipqbpv7" aria-label="Visit our Bluesky profile"><span class="fa fa-brands fa-bluesky"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://twitter.com/mcmc_stan" aria-label="Visit our Twitter profile"><span class="fa fa-twitter"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://discourse.mc-stan.org/" aria-label="Visit our forums"><span class="fa fa-users"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/stan-dev/loo/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch">
<li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul>
</li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.svg" class="logo" alt=""><h1>Approximate leave-future-out cross-validation for Bayesian time series models</h1>
                        <h4 data-toc-skip class="author">Paul Bürkner,
Jonah Gabry, Aki Vehtari</h4>
            
            <h4 data-toc-skip class="date">2025-09-23</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/stan-dev/loo/blob/HEAD/vignettes/loo2-lfo.Rmd" class="external-link"><code>vignettes/loo2-lfo.Rmd</code></a></small>
      <div class="d-none name"><code>loo2-lfo.Rmd</code></div>
    </div>

    
    
<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{Approximate leave-future-out cross-validation for Bayesian time series models}
-->
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>One of the most common goals of a time series analysis is to use the
observed series to inform predictions for future observations. We will
refer to this task of predicting a sequence of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>
future observations as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>-step-ahead
prediction
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>-SAP).
Fortunately, once we have fit a model and can sample from the posterior
predictive distribution, it is straightforward to generate predictions
as far into the future as we want. It is also straightforward to
evaluate the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>-SAP
performance of a time series model by comparing the predictions to the
observed sequence of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>
future data points once they become available.</p>
<p>Unfortunately, we are often in the position of having to use a model
to inform decisions <em>before</em> we can collect the future
observations required for assessing the predictive performance. If we
have many competing models we may also need to first decide which of the
models (or which combination of the models) we should rely on for
predictions. In these situations the best we can do is to use methods
for approximating the expected predictive performance of our models
using only the observations of the time series we already have.</p>
<p>If there were no time dependence in the data or if the focus is to
assess the non-time-dependent part of the model, we could use methods
like leave-one-out cross-validation (LOO-CV). For a data set with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
observations, we refit the model
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
times, each time leaving out one of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
observations and assessing how well the model predicts the left-out
observation. LOO-CV is very expensive computationally in most realistic
settings, but the Pareto smoothed importance sampling (PSIS, Vehtari et
al, 2017, 2024) algorithm provided by the <em>loo</em> package allows
for approximating exact LOO-CV with PSIS-LOO-CV. PSIS-LOO-CV requires
only a single fit of the full model and comes with diagnostics for
assessing the validity of the approximation.</p>
<p>With a time series we can do something similar to LOO-CV but, except
in a few cases, it does not make sense to leave out observations one at
a time because then we are allowing information from the future to
influence predictions of the past (i.e., times
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>+</mo><mn>1</mn><mo>,</mo><mi>t</mi><mo>+</mo><mn>2</mn><mo>,</mo><mi>…</mi></mrow><annotation encoding="application/x-tex">t + 1, t+2, \ldots</annotation></semantics></math>
should not be used to predict for time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>t</mi><annotation encoding="application/x-tex">t</annotation></semantics></math>).
To apply the idea of cross-validation to the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>-SAP
case, instead of leave-<em>one</em>-out cross-validation we need some
form of leave-<em>future</em>-out cross-validation (LFO-CV). As we will
demonstrate in this case study, LFO-CV does not refer to one particular
prediction task but rather to various possible cross-validation
approaches that all involve some form of prediction for new time series
data. Like exact LOO-CV, exact LFO-CV requires refitting the model many
times to different subsets of the data, which is computationally very
costly for most nontrivial examples, in particular for Bayesian analyses
where refitting the model means estimating a new posterior distribution
rather than a point estimate.</p>
<p>Although PSIS-LOO-CV provides an efficient approximation to exact
LOO-CV, until now there has not been an analogous approximation to exact
LFO-CV that drastically reduces the computational burden while also
providing informative diagnostics about the quality of the
approximation. In this case study we present PSIS-LFO-CV, an algorithm
that typically only requires refitting the time-series model a small
number times and will make LFO-CV tractable for many more realistic
applications than previously possible.</p>
<p>More details can be found in our paper about approximate LFO-CV
(Bürkner, Gabry, &amp; Vehtari, 2020), which is available as a preprint
on arXiv (<a href="https://arxiv.org/abs/1902.06281" class="external-link uri">https://arxiv.org/abs/1902.06281</a>).</p>
</div>
<div class="section level2">
<h2 id="m-step-ahead-predictions">
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>-step-ahead
predictions<a class="anchor" aria-label="anchor" href="#m-step-ahead-predictions"></a>
</h2>
<p>Assume we have a time series of observations
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><msub><mi>y</mi><mn>2</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>y</mi><mi>N</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">y = (y_1, y_2, \ldots, y_N)</annotation></semantics></math>
and let
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>L</mi><annotation encoding="application/x-tex">L</annotation></semantics></math>
be the <em>minimum</em> number of observations from the series that we
will require before making predictions for future data. Depending on the
application and how informative the data is, it may not be possible to
make reasonable predictions for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><annotation encoding="application/x-tex">y_{i+1}</annotation></semantics></math>
based on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(y_1, \dots, y_{i})</annotation></semantics></math>
until
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
is large enough so that we can learn enough about the time series to
predict future observations. Setting
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">L=10</annotation></semantics></math>,
for example, means that we will only assess predictive performance
starting with observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mn>11</mn></msub><annotation encoding="application/x-tex">y_{11}</annotation></semantics></math>,
so that we always have at least 10 previous observations to condition
on.</p>
<p>In order to assess
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>-SAP
performance we would like to compute the predictive densities</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>M</mi></mrow></msub><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mi>M</mi></mrow></msub><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mn>1</mn></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mi>y</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">
p(y_{i+1:M} \,|\, y_{1:i}) = 
  p(y_{i+1}, \ldots, y_{i + M} \,|\, y_{1},...,y_{i}) 
</annotation></semantics></math></p>
<p>for each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>∈</mo><mo stretchy="false" form="prefix">{</mo><mi>L</mi><mo>,</mo><mi>…</mi><mo>,</mo><mi>N</mi><mo>−</mo><mi>M</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">i \in \{L, \ldots, N - M\}</annotation></semantics></math>.
The quantities
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>M</mi></mrow></msub><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(y_{i+1:M} \,|\, y_{1:i})</annotation></semantics></math>
can be computed with the help of the posterior distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>θ</mi><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(\theta \,|\, y_{1:i})</annotation></semantics></math>
of the parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>θ</mi><annotation encoding="application/x-tex">\theta</annotation></semantics></math>
conditional on only the first
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
observations of the time-series:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>M</mi></mrow></msub><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mo>∫</mo><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>M</mi></mrow></msub><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo>,</mo><mi>θ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>θ</mi><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mspace width="0.167em"></mspace><mi>d</mi><mi>θ</mi><mi>.</mi></mrow><annotation encoding="application/x-tex">
p(y_{i+1:M} \,| \, y_{1:i}) = 
  \int p(y_{i+1:M} \,| \, y_{1:i}, \theta) \, p(\theta\,|\,y_{1:i}) \,d\theta. 
</annotation></semantics></math></p>
<p>Having obtained
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>S</mi><annotation encoding="application/x-tex">S</annotation></semantics></math>
draws
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><msubsup><mi>θ</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>,</mo><mi>…</mi><mo>,</mo><msubsup><mi>θ</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>S</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(\theta_{1:i}^{(1)}, \ldots, \theta_{1:i}^{(S)})</annotation></semantics></math>
from the posterior distribution
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>θ</mi><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(\theta\,|\,y_{1:i})</annotation></semantics></math>,
we can estimate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>M</mi></mrow></msub><mo stretchy="false" form="prefix">|</mo><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(y_{i+1:M} | y_{1:i})</annotation></semantics></math>
as</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>M</mi></mrow></msub><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>≈</mo><mfrac><mn>1</mn><mi>S</mi></mfrac><munderover><mo>∑</mo><mrow><mi>s</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>M</mi></mrow></msub><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo>,</mo><msubsup><mi>θ</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo stretchy="true" form="postfix">)</mo></mrow><mi>.</mi></mrow><annotation encoding="application/x-tex">
p(y_{i+1:M} \,|\, y_{1:i}) \approx \frac{1}{S}\sum_{s=1}^S p(y_{i+1:M} \,|\, y_{1:i}, \theta_{1:i}^{(s)}).
</annotation></semantics></math></p>
</div>
<div class="section level2">
<h2 id="approximate_MSAP">Approximate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>-SAP
using importance-sampling<a class="anchor" aria-label="anchor" href="#approximate_MSAP"></a>
</h2>
<p>Unfortunately, the math above makes use of the posterior
distributions from many different fits of the model to different subsets
of the data. That is, to obtain the predictive density
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>M</mi></mrow></msub><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(y_{i+1:M} \,|\, y_{1:i})</annotation></semantics></math>
requires fitting a model to only the first
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
data points, and we will need to do this for every value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
under consideration (all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>∈</mo><mo stretchy="false" form="prefix">{</mo><mi>L</mi><mo>,</mo><mi>…</mi><mo>,</mo><mi>N</mi><mo>−</mo><mi>M</mi><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">i \in \{L, \ldots, N - M\}</annotation></semantics></math>).</p>
<p>To reduce the number of models that need to be fit for the purpose of
obtaining each of the densities
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>M</mi></mrow></msub><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(y_{i+1:M} \,|\, y_{1:i})</annotation></semantics></math>,
we propose the following algorithm. First, we refit the model using the
first
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>L</mi><annotation encoding="application/x-tex">L</annotation></semantics></math>
observations of the time series and then perform a single exact
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>-step-ahead
prediction step for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mrow><mi>L</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>M</mi></mrow></msub><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>L</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(y_{L+1:M} \,|\, y_{1:L})</annotation></semantics></math>.
Recall that
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>L</mi><annotation encoding="application/x-tex">L</annotation></semantics></math>
is the minimum number of observations we have deemed acceptable for
making predictions (setting
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">L=0</annotation></semantics></math>
means the first data point will be predicted only based on the prior).
We define
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>i</mi><mo>⋆</mo></msup><mo>=</mo><mi>L</mi></mrow><annotation encoding="application/x-tex">i^\star = L</annotation></semantics></math>
as the current point of refit. Next, starting with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>=</mo><msup><mi>i</mi><mo>⋆</mo></msup><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">i = i^\star + 1</annotation></semantics></math>,
we approximate each
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>M</mi></mrow></msub><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(y_{i+1:M} \,|\, y_{1:i})</annotation></semantics></math>
via</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>M</mi></mrow></msub><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>≈</mo><mfrac><mrow><munderover><mo>∑</mo><mrow><mi>s</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><msubsup><mi>w</mi><mi>i</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mspace width="0.167em"></mspace><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>M</mi></mrow></msub><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo>,</mo><msup><mi>θ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><munderover><mo>∑</mo><mrow><mi>s</mi><mo>=</mo><mn>1</mn></mrow><mi>S</mi></munderover><msubsup><mi>w</mi><mi>i</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup></mrow></mfrac><mo>,</mo></mrow><annotation encoding="application/x-tex">
 p(y_{i+1:M} \,|\, y_{1:i}) \approx
   \frac{ \sum_{s=1}^S w_i^{(s)}\, p(y_{i+1:M} \,|\, y_{1:i}, \theta^{(s)})}
        { \sum_{s=1}^S w_i^{(s)}},
</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>θ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>=</mo><msubsup><mi>θ</mi><mrow><mn>1</mn><mo>:</mo><msup><mi>i</mi><mo>⋆</mo></msup></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\theta^{(s)} = \theta^{(s)}_{1:i^\star}</annotation></semantics></math>
are draws from the posterior distribution based on the first
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>i</mi><mo>⋆</mo></msup><annotation encoding="application/x-tex">i^\star</annotation></semantics></math>
observations and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>w</mi><mi>i</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><annotation encoding="application/x-tex">w_i^{(s)}</annotation></semantics></math>
are the PSIS weights obtained in two steps. First, we compute the raw
importance ratios</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>r</mi><mi>i</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><mo>=</mo><mfrac><mrow><msub><mi>f</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>θ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><mrow><msub><mi>f</mi><mrow><mn>1</mn><mo>:</mo><msup><mi>i</mi><mo>⋆</mo></msup></mrow></msub><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>θ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow></mfrac><mo>∝</mo><munder><mo>∏</mo><mrow><mi>j</mi><mo>∈</mo><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>i</mi><mo>⋆</mo></msup><mo>+</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>:</mo><mi>i</mi></mrow></munder><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>j</mi></msub><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>j</mi><mo>−</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow></msub><mo>,</mo><msup><mi>θ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo stretchy="true" form="postfix">)</mo></mrow><mo>,</mo></mrow><annotation encoding="application/x-tex">
r_i^{(s)} =
\frac{f_{1:i}(\theta^{(s)})}{f_{1:i^\star}(\theta^{(s)})} 
\propto \prod_{j \in (i^\star + 1):i} p(y_j \,|\, y_{1:(j-1)}, \theta^{(s)}),
</annotation></semantics></math></p>
<p>and then stabilize them using PSIS. The function
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><annotation encoding="application/x-tex">f_{1:i}</annotation></semantics></math>
denotes the posterior distribution based on the first
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
observations, that is,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo>=</mo><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>θ</mi><mspace width="0.167em"></mspace><mo stretchy="false" form="prefix">|</mo><mspace width="0.167em"></mspace><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">f_{1:i} = p(\theta \,|\, y_{1:i})</annotation></semantics></math>,
with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mrow><mn>1</mn><mo>:</mo><msup><mi>i</mi><mo>⋆</mo></msup></mrow></msub><annotation encoding="application/x-tex">f_{1:i^\star}</annotation></semantics></math>
defined analogously. The index set
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>i</mi><mo>⋆</mo></msup><mo>+</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>:</mo><mi>i</mi></mrow><annotation encoding="application/x-tex">(i^\star + 1):i</annotation></semantics></math>
indicates all observations which are part of the data for the model
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><annotation encoding="application/x-tex">f_{1:i}</annotation></semantics></math>
whose predictive performance we are trying to approximate but not for
the actually fitted model
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>f</mi><mrow><mn>1</mn><mo>:</mo><msup><mi>i</mi><mo>⋆</mo></msup></mrow></msub><annotation encoding="application/x-tex">f_{1:i^\star}</annotation></semantics></math>.
The proportional statement arises from the fact that we ignore the
normalizing constants
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(y_{1:i})</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mrow><mn>1</mn><mo>:</mo><msup><mi>i</mi><mo>⋆</mo></msup></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">p(y_{1:i^\star})</annotation></semantics></math>
of the compared posteriors, which leads to a self-normalized variant of
PSIS (see Vehtari et al, 2017).</p>
<p>Continuing with the next observation, we gradually increase
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1</mn><annotation encoding="application/x-tex">1</annotation></semantics></math>
(we move forward in time) and repeat the process. At some observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>,
the variability of the importance ratios
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>r</mi><mi>i</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup><annotation encoding="application/x-tex">r_i^{(s)}</annotation></semantics></math>
will become too large and importance sampling will fail. We will refer
to this particular value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>i</mi><mn>1</mn><mo>⋆</mo></msubsup><annotation encoding="application/x-tex">i^\star_1</annotation></semantics></math>.
To identify the value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>i</mi><mn>1</mn><mo>⋆</mo></msubsup><annotation encoding="application/x-tex">i^\star_1</annotation></semantics></math>,
we check for which value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
does the estimated shape parameter
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
of the generalized Pareto distribution first cross a certain threshold
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>τ</mi><annotation encoding="application/x-tex">\tau</annotation></semantics></math>
(Vehtari et al, 2024). Only then do we refit the model using the
observations up to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>i</mi><mn>1</mn><mo>⋆</mo></msubsup><annotation encoding="application/x-tex">i^\star_1</annotation></semantics></math>
and restart the process from there by setting
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>θ</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></msup><mo>=</mo><msubsup><mi>θ</mi><mrow><mn>1</mn><mo>:</mo><msubsup><mi>i</mi><mn>1</mn><mo>⋆</mo></msubsup></mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>s</mi><mo stretchy="true" form="postfix">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\theta^{(s)} = \theta^{(s)}_{1:i^\star_1}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>i</mi><mo>⋆</mo></msup><mo>=</mo><msubsup><mi>i</mi><mn>1</mn><mo>⋆</mo></msubsup></mrow><annotation encoding="application/x-tex">i^\star = i^\star_1</annotation></semantics></math>
until the next refit.</p>
<p>In some cases we may only need to refit once and in other cases we
will find a value
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>i</mi><mn>2</mn><mo>⋆</mo></msubsup><annotation encoding="application/x-tex">i^\star_2</annotation></semantics></math>
that requires a second refitting, maybe an
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>i</mi><mn>3</mn><mo>⋆</mo></msubsup><annotation encoding="application/x-tex">i^\star_3</annotation></semantics></math>
that requires a third refitting, and so on. We refit as many times as is
required (only when
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>&gt;</mo><mi>τ</mi></mrow><annotation encoding="application/x-tex">k &gt; \tau</annotation></semantics></math>)
until we arrive at observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>=</mo><mi>N</mi><mo>−</mo><mi>M</mi></mrow><annotation encoding="application/x-tex">i = N - M</annotation></semantics></math>.
For LOO, assuming posterior sample size is 4000 or larger, we recommend
to use a threshold of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi><mo>=</mo><mn>0.7</mn></mrow><annotation encoding="application/x-tex">\tau = 0.7</annotation></semantics></math>
(Vehtari et al, 2017, 2024) and it turns out this is a reasonable
threshold for LFO as well (Bürkner et al. 2020).</p>
</div>
<div class="section level2">
<h2 id="autoregressive-models">Autoregressive models<a class="anchor" aria-label="anchor" href="#autoregressive-models"></a>
</h2>
<p>Autoregressive (AR) models are some of the most commonly used
time-series models. An AR(p) model —an autoregressive model of order
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>p</mi><annotation encoding="application/x-tex">p</annotation></semantics></math>—
can be defined as</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><msub><mi>η</mi><mi>i</mi></msub><mo>+</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover><msub><mi>φ</mi><mi>k</mi></msub><msub><mi>y</mi><mrow><mi>i</mi><mo>−</mo><mi>k</mi></mrow></msub><mo>+</mo><msub><mi>ε</mi><mi>i</mi></msub><mo>,</mo></mrow><annotation encoding="application/x-tex">
y_i = \eta_i + \sum_{k = 1}^p \varphi_k y_{i - k} + \varepsilon_i,
</annotation></semantics></math></p>
<p>where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>η</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\eta_i</annotation></semantics></math>
is the linear predictor for the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>th
observation,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ϕ</mi><mi>k</mi></msub><annotation encoding="application/x-tex">\phi_k</annotation></semantics></math>
are the autoregressive parameters and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ε</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\varepsilon_i</annotation></semantics></math>
are pairwise independent errors, which are usually assumed to be
normally distributed with equal variance
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>σ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\sigma^2</annotation></semantics></math>.
The model implies a recursive formula that allows for computing the
right-hand side of the above equation for observation
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
based on the values of the equations for previous observations.</p>
</div>
<div class="section level2">
<h2 id="case-study-annual-measurements-of-the-level-of-lake-huron">Case Study: Annual measurements of the level of Lake Huron<a class="anchor" aria-label="anchor" href="#case-study-annual-measurements-of-the-level-of-lake-huron"></a>
</h2>
<p>To illustrate the application of PSIS-LFO-CV for estimating expected
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>-SAP
performance, we will fit a model for 98 annual measurements of the water
level (in feet) of <a href="https://en.wikipedia.org/wiki/Lake_Huron" class="external-link">Lake Huron</a> from the
years 1875–1972. This data set is found in the <strong>datasets</strong>
R package, which is installed automatically with <strong>R</strong>.</p>
<p>In addition to the <strong>loo</strong> package, for this analysis we
will use the <strong>brms</strong> interface to Stan to generate a Stan
program and fit the model, and also the <strong>bayesplot</strong> and
<strong>ggplot2</strong> packages for plotting.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/paul-buerkner/brms" class="external-link">"brms"</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://mc-stan.org/loo/">"loo"</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://mc-stan.org/bayesplot/" class="external-link">"bayesplot"</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://ggplot2.tidyverse.org" class="external-link">"ggplot2"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/bayesplot-colors.html" class="external-link">color_scheme_set</a></span><span class="op">(</span><span class="st">"brightblue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/get_theme.html" class="external-link">theme_set</a></span><span class="op">(</span><span class="fu"><a href="https://mc-stan.org/bayesplot/reference/theme_default.html" class="external-link">theme_default</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">CHAINS</span> <span class="op">&lt;-</span> <span class="fl">4</span></span>
<span><span class="va">SEED</span> <span class="op">&lt;-</span> <span class="fl">5838296</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="va">SEED</span><span class="op">)</span></span></code></pre></div>
<p>Before fitting a model, we will first put the data into a data frame
and then look at the time series.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">LakeHuron</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span>
<span>  y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">LakeHuron</span><span class="op">)</span>,</span>
<span>  year <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/time.html" class="external-link">time</a></span><span class="op">(</span><span class="va">LakeHuron</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  time <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="va">N</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">year</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span></span>
<span>    y <span class="op">=</span> <span class="st">"Water Level (ft)"</span>, </span>
<span>    x <span class="op">=</span> <span class="st">"Year"</span>,</span>
<span>    title <span class="op">=</span> <span class="st">"Water Level in Lake Huron (1875-1972)"</span></span>
<span>  <span class="op">)</span> </span></code></pre></div>
<p><img src="loo2-lfo_files/figure-html/hurondata-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>The above plot shows rather strong autocorrelation of the time-series
as well as some trend towards lower levels for later points in time.</p>
<p>We can specify an AR(4) model for these data using the
<strong>brms</strong> package as follows:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://paulbuerkner.com/brms/reference/brm.html" class="external-link">brm</a></span><span class="op">(</span></span>
<span>  <span class="va">y</span> <span class="op">~</span> <span class="fu">ar</span><span class="op">(</span><span class="va">time</span>, p <span class="op">=</span> <span class="fl">4</span><span class="op">)</span>, </span>
<span>  data <span class="op">=</span> <span class="va">df</span>, </span>
<span>  prior <span class="op">=</span> <span class="fu"><a href="https://paulbuerkner.com/brms/reference/set_prior.html" class="external-link">prior</a></span><span class="op">(</span><span class="fu"><a href="https://mc-stan.org/rstanarm/reference/priors.html" class="external-link">normal</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.5</span><span class="op">)</span>, class <span class="op">=</span> <span class="st">"ar"</span><span class="op">)</span>,</span>
<span>  control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>adapt_delta <span class="op">=</span> <span class="fl">0.99</span><span class="op">)</span>, </span>
<span>  seed <span class="op">=</span> <span class="va">SEED</span>, </span>
<span>  chains <span class="op">=</span> <span class="va">CHAINS</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The model implied predictions along with the observed values can be
plotted, which reveals a rather good fit to the data.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">preds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstantools/reference/posterior_predict.html" class="external-link">posterior_predict</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span>
<span><span class="va">preds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span></span>
<span>  Estimate <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">colMeans</a></span><span class="op">(</span><span class="va">preds</span><span class="op">)</span>, </span>
<span>  Q5 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">preds</span>, <span class="fl">2</span>, <span class="va">quantile</span>, probs <span class="op">=</span> <span class="fl">0.05</span><span class="op">)</span>,</span>
<span>  Q95 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">preds</span>, <span class="fl">2</span>, <span class="va">quantile</span>, probs <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="va">df</span>, <span class="va">preds</span><span class="op">)</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">year</span>, y <span class="op">=</span> <span class="va">Estimate</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html" class="external-link">geom_smooth</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>ymin <span class="op">=</span> <span class="va">Q5</span>, ymax <span class="op">=</span> <span class="va">Q95</span><span class="op">)</span>, stat <span class="op">=</span> <span class="st">"identity"</span>, linewidth <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span></span>
<span>    y <span class="op">=</span> <span class="st">"Water Level (ft)"</span>, </span>
<span>    x <span class="op">=</span> <span class="st">"Year"</span>,</span>
<span>    title <span class="op">=</span> <span class="st">"Water Level in Lake Huron (1875-1972)"</span>,</span>
<span>    subtitle <span class="op">=</span> <span class="st">"Mean (blue) and 90% predictive intervals (gray) vs. observed data (black)"</span></span>
<span>  <span class="op">)</span> </span></code></pre></div>
<p><img src="loo2-lfo_files/figure-html/plotpreds-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>To allow for reasonable predictions of future values, we will require
at least
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo>=</mo><mn>20</mn></mrow><annotation encoding="application/x-tex">L = 20</annotation></semantics></math>
historical observations (20 years) to make predictions.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">L</span> <span class="op">&lt;-</span> <span class="fl">20</span></span></code></pre></div>
<p>We first perform approximate leave-one-out cross-validation (LOO-CV)
for the purpose of later comparison with exact and approximate LFO-CV
for the 1-SAP case.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">loo_cv</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/loo.html">loo</a></span><span class="op">(</span><span class="fu"><a href="https://mc-stan.org/rstantools/reference/log_lik.html" class="external-link">log_lik</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span><span class="op">[</span>, <span class="op">(</span><span class="va">L</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">:</span><span class="va">N</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">loo_cv</span><span class="op">)</span></span></code></pre></div>
<pre><code>
Computed from 4000 by 78 log-likelihood matrix.

         Estimate   SE
elpd_loo    -88.5  6.4
p_loo         4.7  1.0
looic       177.1 12.8
------
MCSE of elpd_loo is 0.0.
MCSE and ESS estimates assume independent draws (r_eff=1).

All Pareto k estimates are good (k &lt; 0.7).
See help('pareto-k-diagnostic') for details.</code></pre>
</div>
<div class="section level2">
<h2 id="step-ahead-predictions-leaving-out-all-future-values">1-step-ahead predictions leaving out all future values<a class="anchor" aria-label="anchor" href="#step-ahead-predictions-leaving-out-all-future-values"></a>
</h2>
<p>The most basic version of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>-SAP
is 1-SAP, in which we predict only one step ahead. In this case,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn><mo>:</mo><mi>M</mi></mrow></msub><annotation encoding="application/x-tex">y_{i+1:M}</annotation></semantics></math>
simplifies to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>y</mi><mi>i</mi></msub><annotation encoding="application/x-tex">y_{i}</annotation></semantics></math>
and the LFO-CV algorithm becomes considerably simpler than for larger
values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>.</p>
<div class="section level3">
<h3 id="exact-1-step-ahead-predictions">Exact 1-step-ahead predictions<a class="anchor" aria-label="anchor" href="#exact-1-step-ahead-predictions"></a>
</h3>
<p>Before we compute approximate LFO-CV using PSIS we will first compute
exact LFO-CV for the 1-SAP case so we can use it as a benchmark later.
The initial step for the exact computation is to calculate the
log-predictive densities by refitting the model many times:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">loglik_exact</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span>nrow <span class="op">=</span> <span class="fu"><a href="https://mc-stan.org/posterior/reference/draws-index.html" class="external-link">ndraws</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="va">N</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="va">L</span><span class="op">:</span><span class="op">(</span><span class="va">N</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">past</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="va">i</span></span>
<span>  <span class="va">oos</span> <span class="op">&lt;-</span> <span class="va">i</span> <span class="op">+</span> <span class="fl">1</span></span>
<span>  <span class="va">df_past</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span><span class="va">past</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span></span>
<span>  <span class="va">df_oos</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">past</span>, <span class="va">oos</span><span class="op">)</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span></span>
<span>  <span class="va">fit_i</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html" class="external-link">update</a></span><span class="op">(</span><span class="va">fit</span>, newdata <span class="op">=</span> <span class="va">df_past</span>, recompile <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>  <span class="va">loglik_exact</span><span class="op">[</span>, <span class="va">i</span> <span class="op">+</span> <span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstantools/reference/log_lik.html" class="external-link">log_lik</a></span><span class="op">(</span><span class="va">fit_i</span>, newdata <span class="op">=</span> <span class="va">df_oos</span>, oos <span class="op">=</span> <span class="va">oos</span><span class="op">)</span><span class="op">[</span>, <span class="va">oos</span><span class="op">]</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>Then we compute the exact expected log predictive density (ELPD):</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># some helper functions we'll use throughout</span></span>
<span></span>
<span><span class="co"># more stable than log(sum(exp(x))) </span></span>
<span><span class="va">log_sum_exp</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">max_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>  </span>
<span>  <span class="va">max_x</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="va">x</span> <span class="op">-</span> <span class="va">max_x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># more stable than log(mean(exp(x)))</span></span>
<span><span class="va">log_mean_exp</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu">log_sum_exp</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># compute log of raw importance ratios</span></span>
<span><span class="co"># sums over observations *not* over posterior samples</span></span>
<span><span class="va">sum_log_ratios</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">loglik</span>, <span class="va">ids</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">ids</span><span class="op">)</span><span class="op">)</span> <span class="va">loglik</span> <span class="op">&lt;-</span> <span class="va">loglik</span><span class="op">[</span>, <span class="va">ids</span>, drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">loglik</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># for printing comparisons later</span></span>
<span><span class="va">rbind_print</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">...</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="va">...</span><span class="op">)</span>, digits <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">exact_elpds_1sap</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">loglik_exact</span>, <span class="fl">2</span>, <span class="va">log_mean_exp</span><span class="op">)</span></span>
<span><span class="va">exact_elpd_1sap</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>ELPD <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">exact_elpds_1sap</span><span class="op">[</span><span class="op">-</span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="va">L</span><span class="op">)</span><span class="op">]</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">rbind_print</span><span class="op">(</span></span>
<span>  <span class="st">"LOO"</span> <span class="op">=</span> <span class="va">loo_cv</span><span class="op">$</span><span class="va">estimates</span><span class="op">[</span><span class="st">"elpd_loo"</span>, <span class="st">"Estimate"</span><span class="op">]</span>,</span>
<span>  <span class="st">"LFO"</span> <span class="op">=</span> <span class="va">exact_elpd_1sap</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span>      <span class="va">ELPD</span></span>
<span><span class="va">LOO</span> <span class="op">-</span><span class="fl">88.53</span></span>
<span><span class="va">LFO</span> <span class="op">-</span><span class="fl">92.48</span></span></code></pre>
<p>We see that the ELPD from LFO-CV for 1-step-ahead predictions is
lower than the ELPD estimate from LOO-CV, which should be expected since
LOO-CV is making use of more of the time series. That is, since the
LFO-CV approach only uses observations from before the left-out data
point but LOO-CV uses <em>all</em> data points other than the left-out
observation, we should expect to see the larger ELPD from LOO-CV.</p>
</div>
<div class="section level3">
<h3 id="approximate-1-step-ahead-predictions">Approximate 1-step-ahead predictions<a class="anchor" aria-label="anchor" href="#approximate-1-step-ahead-predictions"></a>
</h3>
<p>We compute approximate 1-SAP with refit at observations where the
Pareto
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
estimate exceeds the threshold of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>0.7</mn><annotation encoding="application/x-tex">0.7</annotation></semantics></math>.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">k_thres</span> <span class="op">&lt;-</span> <span class="fl">0.7</span></span></code></pre></div>
<p>The code becomes a little bit more involved as compared to the exact
LFO-CV. Note that we can compute exact 1-SAP at the refitting points,
which comes with no additional computational costs since we had to refit
the model anyway.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">approx_elpds_1sap</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="va">N</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># initialize the process for i = L</span></span>
<span><span class="va">past</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="va">L</span></span>
<span><span class="va">oos</span> <span class="op">&lt;-</span> <span class="va">L</span> <span class="op">+</span> <span class="fl">1</span></span>
<span><span class="va">df_past</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span><span class="va">past</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span></span>
<span><span class="va">df_oos</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">past</span>, <span class="va">oos</span><span class="op">)</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span></span>
<span><span class="va">fit_past</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html" class="external-link">update</a></span><span class="op">(</span><span class="va">fit</span>, newdata <span class="op">=</span> <span class="va">df_past</span>, recompile <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">loglik</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstantools/reference/log_lik.html" class="external-link">log_lik</a></span><span class="op">(</span><span class="va">fit_past</span>, newdata <span class="op">=</span> <span class="va">df_oos</span>, oos <span class="op">=</span> <span class="va">oos</span><span class="op">)</span></span>
<span><span class="va">approx_elpds_1sap</span><span class="op">[</span><span class="va">L</span> <span class="op">+</span> <span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">log_mean_exp</span><span class="op">(</span><span class="va">loglik</span><span class="op">[</span>, <span class="va">oos</span><span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># iterate over i &gt; L</span></span>
<span><span class="va">i_refit</span> <span class="op">&lt;-</span> <span class="va">L</span></span>
<span><span class="va">refits</span> <span class="op">&lt;-</span> <span class="va">L</span></span>
<span><span class="va">ks</span> <span class="op">&lt;-</span> <span class="cn">NULL</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="op">(</span><span class="va">L</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">:</span><span class="op">(</span><span class="va">N</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">past</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="va">i</span></span>
<span>  <span class="va">oos</span> <span class="op">&lt;-</span> <span class="va">i</span> <span class="op">+</span> <span class="fl">1</span></span>
<span>  <span class="va">df_past</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span><span class="va">past</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span></span>
<span>  <span class="va">df_oos</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">past</span>, <span class="va">oos</span><span class="op">)</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span></span>
<span>  <span class="va">loglik</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstantools/reference/log_lik.html" class="external-link">log_lik</a></span><span class="op">(</span><span class="va">fit_past</span>, newdata <span class="op">=</span> <span class="va">df_oos</span>, oos <span class="op">=</span> <span class="va">oos</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">logratio</span> <span class="op">&lt;-</span> <span class="fu">sum_log_ratios</span><span class="op">(</span><span class="va">loglik</span>, <span class="op">(</span><span class="va">i_refit</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">:</span><span class="va">i</span><span class="op">)</span></span>
<span>  <span class="va">psis_obj</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/warning.html" class="external-link">suppressWarnings</a></span><span class="op">(</span><span class="fu"><a href="../reference/psis.html">psis</a></span><span class="op">(</span><span class="va">logratio</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">k</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/pareto-k-diagnostic.html">pareto_k_values</a></span><span class="op">(</span><span class="va">psis_obj</span><span class="op">)</span></span>
<span>  <span class="va">ks</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">ks</span>, <span class="va">k</span><span class="op">)</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">k</span> <span class="op">&gt;</span> <span class="va">k_thres</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="co"># refit the model based on the first i observations</span></span>
<span>    <span class="va">i_refit</span> <span class="op">&lt;-</span> <span class="va">i</span></span>
<span>    <span class="va">refits</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">refits</span>, <span class="va">i</span><span class="op">)</span></span>
<span>    <span class="va">fit_past</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html" class="external-link">update</a></span><span class="op">(</span><span class="va">fit_past</span>, newdata <span class="op">=</span> <span class="va">df_past</span>, recompile <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>    <span class="va">loglik</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstantools/reference/log_lik.html" class="external-link">log_lik</a></span><span class="op">(</span><span class="va">fit_past</span>, newdata <span class="op">=</span> <span class="va">df_oos</span>, oos <span class="op">=</span> <span class="va">oos</span><span class="op">)</span></span>
<span>    <span class="va">approx_elpds_1sap</span><span class="op">[</span><span class="va">i</span> <span class="op">+</span> <span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">log_mean_exp</span><span class="op">(</span><span class="va">loglik</span><span class="op">[</span>, <span class="va">oos</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>    <span class="va">lw</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/weights.html" class="external-link">weights</a></span><span class="op">(</span><span class="va">psis_obj</span>, normalize <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span></span>
<span>    <span class="va">approx_elpds_1sap</span><span class="op">[</span><span class="va">i</span> <span class="op">+</span> <span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">log_sum_exp</span><span class="op">(</span><span class="va">lw</span> <span class="op">+</span> <span class="va">loglik</span><span class="op">[</span>, <span class="va">oos</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span> </span></code></pre></div>
<p>We see that the final
Pareto-<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>-estimates
are mostly well below the threshold and that we only needed to refit the
model a few times:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">plot_ks</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">ks</span>, <span class="va">ids</span>, <span class="va">thres</span> <span class="op">=</span> <span class="fl">0.6</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">dat_ks</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>ks <span class="op">=</span> <span class="va">ks</span>, ids <span class="op">=</span> <span class="va">ids</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">dat_ks</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">ids</span>, y <span class="op">=</span> <span class="va">ks</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>color <span class="op">=</span> <span class="va">ks</span> <span class="op">&gt;</span> <span class="va">thres</span><span class="op">)</span>, shape <span class="op">=</span> <span class="fl">3</span>, show.legend <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_hline</a></span><span class="op">(</span>yintercept <span class="op">=</span> <span class="va">thres</span>, linetype <span class="op">=</span> <span class="fl">2</span>, color <span class="op">=</span> <span class="st">"red2"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html" class="external-link">scale_color_manual</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"cornflowerblue"</span>, <span class="st">"darkblue"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Data point"</span>, y <span class="op">=</span> <span class="st">"Pareto k"</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html" class="external-link">ylim</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.5</span>, <span class="fl">1.5</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Using threshold "</span>, <span class="va">k_thres</span>, </span>
<span>    <span class="st">", model was refit "</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">refits</span><span class="op">)</span>, </span>
<span>    <span class="st">" times, at observations"</span>, <span class="va">refits</span><span class="op">)</span></span></code></pre></div>
<pre><code>Using threshold  0.7 , model was refit  3  times, at observations 20 45 78</code></pre>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">plot_ks</span><span class="op">(</span><span class="va">ks</span>, <span class="op">(</span><span class="va">L</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">:</span><span class="op">(</span><span class="va">N</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="loo2-lfo_files/figure-html/refitsummary1sap-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>The approximate 1-SAP ELPD is remarkably similar to the exact 1-SAP
ELPD computed above, which indicates our algorithm to compute
approximate 1-SAP worked well for the present data and model.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">approx_elpd_1sap</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">approx_elpds_1sap</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu">rbind_print</span><span class="op">(</span></span>
<span>  <span class="st">"approx LFO"</span> <span class="op">=</span> <span class="va">approx_elpd_1sap</span>,</span>
<span>  <span class="st">"exact LFO"</span> <span class="op">=</span> <span class="va">exact_elpd_1sap</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code>             ELPD
approx LFO -92.48
exact LFO  -92.48</code></pre>
<p>Plotting exact against approximate predictions, we see that no
approximation value deviates far from its exact counterpart, providing
further evidence for the good quality of our approximation.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat_elpd</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span>
<span>  approx_elpd <span class="op">=</span> <span class="va">approx_elpds_1sap</span>,</span>
<span>  exact_elpd <span class="op">=</span> <span class="va">exact_elpds_1sap</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">dat_elpd</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">approx_elpd</span>, y <span class="op">=</span> <span class="va">exact_elpd</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_abline</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"gray30"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Approximate ELPDs"</span>, y <span class="op">=</span> <span class="st">"Exact ELPDs"</span><span class="op">)</span></span></code></pre></div>
<p><img src="loo2-lfo_files/figure-html/plot1sap-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>We can also look at the maximum difference and average difference
between the approximate and exact ELPD calculations, which also indicate
a ver close approximation:</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">max_diff</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">dat_elpd</span>, <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="va">approx_elpd</span> <span class="op">-</span> <span class="va">exact_elpd</span><span class="op">)</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">mean_diff</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">dat_elpd</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="va">approx_elpd</span> <span class="op">-</span> <span class="va">exact_elpd</span><span class="op">)</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">rbind_print</span><span class="op">(</span></span>
<span>  <span class="st">"Max diff"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">max_diff</span>, <span class="fl">2</span><span class="op">)</span>, </span>
<span>  <span class="st">"Mean diff"</span> <span class="op">=</span>  <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">mean_diff</span>, <span class="fl">3</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code>          [,1]
Max diff  0.09
Mean diff 0.01</code></pre>
</div>
</div>
<div class="section level2">
<h2 id="m-step-ahead-predictions-leaving-out-all-future-values">
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>-step-ahead
predictions leaving out all future values<a class="anchor" aria-label="anchor" href="#m-step-ahead-predictions-leaving-out-all-future-values"></a>
</h2>
<p>To illustrate the application of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>-SAP
for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">M &gt; 1</annotation></semantics></math>,
we next compute exact and approximate LFO-CV for the 4-SAP case.</p>
<div class="section level3">
<h3 id="exact-m-step-ahead-predictions">Exact
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>-step-ahead
predictions<a class="anchor" aria-label="anchor" href="#exact-m-step-ahead-predictions"></a>
</h3>
<p>The necessary steps are the same as for 1-SAP with the exception that
the log-density values of interest are now the sums of the log
predictive densities of four consecutive observations. Further, the
stability of the PSIS approximation actually stays the same for all
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>
as it only depends on the number of observations we leave out, not on
the number of observations we predict.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">M</span> <span class="op">&lt;-</span> <span class="fl">4</span></span>
<span><span class="va">loglikm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span>nrow <span class="op">=</span> <span class="fu"><a href="https://mc-stan.org/posterior/reference/draws-index.html" class="external-link">ndraws</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span>, ncol <span class="op">=</span> <span class="va">N</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="va">L</span><span class="op">:</span><span class="op">(</span><span class="va">N</span> <span class="op">-</span> <span class="va">M</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">past</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="va">i</span></span>
<span>  <span class="va">oos</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">i</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">:</span><span class="op">(</span><span class="va">i</span> <span class="op">+</span> <span class="va">M</span><span class="op">)</span></span>
<span>  <span class="va">df_past</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span><span class="va">past</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span></span>
<span>  <span class="va">df_oos</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">past</span>, <span class="va">oos</span><span class="op">)</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span></span>
<span>  <span class="va">fit_past</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html" class="external-link">update</a></span><span class="op">(</span><span class="va">fit</span>, newdata <span class="op">=</span> <span class="va">df_past</span>, recompile <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>  <span class="va">loglik</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstantools/reference/log_lik.html" class="external-link">log_lik</a></span><span class="op">(</span><span class="va">fit_past</span>, newdata <span class="op">=</span> <span class="va">df_oos</span>, oos <span class="op">=</span> <span class="va">oos</span><span class="op">)</span></span>
<span>  <span class="va">loglikm</span><span class="op">[</span>, <span class="va">i</span> <span class="op">+</span> <span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">loglik</span><span class="op">[</span>, <span class="va">oos</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">exact_elpds_4sap</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html" class="external-link">apply</a></span><span class="op">(</span><span class="va">loglikm</span>, <span class="fl">2</span>, <span class="va">log_mean_exp</span><span class="op">)</span></span>
<span><span class="op">(</span><span class="va">exact_elpd_4sap</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>ELPD <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">exact_elpds_4sap</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span>     <span class="va">ELPD</span> </span>
<span><span class="op">-</span><span class="fl">405.0813</span> </span></code></pre>
</div>
<div class="section level3">
<h3 id="approximate-m-step-ahead-predictions">Approximate
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>-step-ahead
predictions<a class="anchor" aria-label="anchor" href="#approximate-m-step-ahead-predictions"></a>
</h3>
<p>Computing the approximate PSIS-LFO-CV for the 4-SAP case is a little
bit more involved than the approximate version for the 1-SAP case,
although the underlying principles remain the same.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">approx_elpds_4sap</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="va">N</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># initialize the process for i = L</span></span>
<span><span class="va">past</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="va">L</span></span>
<span><span class="va">oos</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">L</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">:</span><span class="op">(</span><span class="va">L</span> <span class="op">+</span> <span class="va">M</span><span class="op">)</span></span>
<span><span class="va">df_past</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span><span class="va">past</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span></span>
<span><span class="va">df_oos</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">past</span>, <span class="va">oos</span><span class="op">)</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span></span>
<span><span class="va">fit_past</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html" class="external-link">update</a></span><span class="op">(</span><span class="va">fit</span>, newdata <span class="op">=</span> <span class="va">df_past</span>, recompile <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">loglik</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstantools/reference/log_lik.html" class="external-link">log_lik</a></span><span class="op">(</span><span class="va">fit_past</span>, newdata <span class="op">=</span> <span class="va">df_oos</span>, oos <span class="op">=</span> <span class="va">oos</span><span class="op">)</span></span>
<span><span class="va">loglikm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">loglik</span><span class="op">[</span>, <span class="va">oos</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">approx_elpds_4sap</span><span class="op">[</span><span class="va">L</span> <span class="op">+</span> <span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">log_mean_exp</span><span class="op">(</span><span class="va">loglikm</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># iterate over i &gt; L</span></span>
<span><span class="va">i_refit</span> <span class="op">&lt;-</span> <span class="va">L</span></span>
<span><span class="va">refits</span> <span class="op">&lt;-</span> <span class="va">L</span></span>
<span><span class="va">ks</span> <span class="op">&lt;-</span> <span class="cn">NULL</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="op">(</span><span class="va">L</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">:</span><span class="op">(</span><span class="va">N</span> <span class="op">-</span> <span class="va">M</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">past</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="va">i</span></span>
<span>  <span class="va">oos</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">i</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">:</span><span class="op">(</span><span class="va">i</span> <span class="op">+</span> <span class="va">M</span><span class="op">)</span></span>
<span>  <span class="va">df_past</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span><span class="va">past</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span></span>
<span>  <span class="va">df_oos</span> <span class="op">&lt;-</span> <span class="va">df</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">past</span>, <span class="va">oos</span><span class="op">)</span>, , drop <span class="op">=</span> <span class="cn">FALSE</span><span class="op">]</span></span>
<span>  <span class="va">loglik</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstantools/reference/log_lik.html" class="external-link">log_lik</a></span><span class="op">(</span><span class="va">fit_past</span>, newdata <span class="op">=</span> <span class="va">df_oos</span>, oos <span class="op">=</span> <span class="va">oos</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">logratio</span> <span class="op">&lt;-</span> <span class="fu">sum_log_ratios</span><span class="op">(</span><span class="va">loglik</span>, <span class="op">(</span><span class="va">i_refit</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">:</span><span class="va">i</span><span class="op">)</span></span>
<span>  <span class="va">psis_obj</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/warning.html" class="external-link">suppressWarnings</a></span><span class="op">(</span><span class="fu"><a href="../reference/psis.html">psis</a></span><span class="op">(</span><span class="va">logratio</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">k</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/pareto-k-diagnostic.html">pareto_k_values</a></span><span class="op">(</span><span class="va">psis_obj</span><span class="op">)</span></span>
<span>  <span class="va">ks</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">ks</span>, <span class="va">k</span><span class="op">)</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="va">k</span> <span class="op">&gt;</span> <span class="va">k_thres</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="co"># refit the model based on the first i observations</span></span>
<span>    <span class="va">i_refit</span> <span class="op">&lt;-</span> <span class="va">i</span></span>
<span>    <span class="va">refits</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">refits</span>, <span class="va">i</span><span class="op">)</span></span>
<span>    <span class="va">fit_past</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html" class="external-link">update</a></span><span class="op">(</span><span class="va">fit_past</span>, newdata <span class="op">=</span> <span class="va">df_past</span>, recompile <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span>    <span class="va">loglik</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstantools/reference/log_lik.html" class="external-link">log_lik</a></span><span class="op">(</span><span class="va">fit_past</span>, newdata <span class="op">=</span> <span class="va">df_oos</span>, oos <span class="op">=</span> <span class="va">oos</span><span class="op">)</span></span>
<span>    <span class="va">loglikm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">loglik</span><span class="op">[</span>, <span class="va">oos</span><span class="op">]</span><span class="op">)</span></span>
<span>    <span class="va">approx_elpds_4sap</span><span class="op">[</span><span class="va">i</span> <span class="op">+</span> <span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">log_mean_exp</span><span class="op">(</span><span class="va">loglikm</span><span class="op">)</span></span>
<span>  <span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span>
<span>    <span class="va">lw</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/weights.html" class="external-link">weights</a></span><span class="op">(</span><span class="va">psis_obj</span>, normalize <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span></span>
<span>    <span class="va">loglikm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">rowSums</a></span><span class="op">(</span><span class="va">loglik</span><span class="op">[</span>, <span class="va">oos</span><span class="op">]</span><span class="op">)</span></span>
<span>    <span class="va">approx_elpds_4sap</span><span class="op">[</span><span class="va">i</span> <span class="op">+</span> <span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">log_sum_exp</span><span class="op">(</span><span class="va">lw</span> <span class="op">+</span> <span class="va">loglikm</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">}</span> </span></code></pre></div>
<p>Again, we see that the final
Pareto-<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>-estimates
are mostly well below the threshold and that we only needed to refit the
model a few times:</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Using threshold "</span>, <span class="va">k_thres</span>, </span>
<span>    <span class="st">", model was refit "</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">refits</span><span class="op">)</span>, </span>
<span>    <span class="st">" times, at observations"</span>, <span class="va">refits</span><span class="op">)</span></span></code></pre></div>
<pre><code>Using threshold  0.7 , model was refit  3  times, at observations 20 50 90</code></pre>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">plot_ks</span><span class="op">(</span><span class="va">ks</span>, <span class="op">(</span><span class="va">L</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">:</span><span class="op">(</span><span class="va">N</span> <span class="op">-</span> <span class="va">M</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="loo2-lfo_files/figure-html/refitsummary4sap-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>The approximate ELPD computed for the 4-SAP case is not as close to
its exact counterpart as in the 1-SAP case. In general, the larger
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>,
the larger the variation of the approximate ELPD around the exact ELPD.
It turns out that the ELPD estimates of AR-models with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">M&gt;1</annotation></semantics></math>
show particular variation due to their predictions’ dependency on other
predicted values. In Bürkner et al. (2020) we provide further
explanation and simulations for these cases.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">approx_elpd_4sap</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">approx_elpds_4sap</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="fu">rbind_print</span><span class="op">(</span></span>
<span>  <span class="st">"Approx LFO"</span> <span class="op">=</span> <span class="va">approx_elpd_4sap</span>,</span>
<span>  <span class="st">"Exact LFO"</span> <span class="op">=</span> <span class="va">exact_elpd_4sap</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code>              ELPD
Approx LFO -405.35
Exact LFO  -405.08</code></pre>
<p>Plotting exact against approximate pointwise predictions confirms
that, for a few specific data points, the approximate predictions
underestimate the exact predictions.</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dat_elpd_4sap</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span>
<span>  approx_elpd <span class="op">=</span> <span class="va">approx_elpds_4sap</span>,</span>
<span>  exact_elpd <span class="op">=</span> <span class="va">exact_elpds_4sap</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">dat_elpd_4sap</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">approx_elpd</span>, y <span class="op">=</span> <span class="va">exact_elpd</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html" class="external-link">geom_abline</a></span><span class="op">(</span>color <span class="op">=</span> <span class="st">"gray30"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span>size <span class="op">=</span> <span class="fl">2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Approximate ELPDs"</span>, y <span class="op">=</span> <span class="st">"Exact ELPDs"</span><span class="op">)</span></span></code></pre></div>
<p><img src="loo2-lfo_files/figure-html/plot4sap-1.png" width="60%" style="display: block; margin: auto;"></p>
</div>
</div>
<div class="section level2">
<h2 id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h2>
<p>In this case study we have shown how to do carry out exact and
approximate leave-future-out cross-validation for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>-step-ahead
prediction tasks. For the data and model used in our example, the
PSIS-LFO-CV algorithm provides reasonably stable and accurate results
despite not requiring us to refit the model nearly as many times. For
more details on approximate LFO-CV, we refer to Bürkner et
al. (2020).</p>
<p><br></p>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<p>Bürkner P. C., Gabry J., &amp; Vehtari A. (2020). Approximate
leave-future-out cross-validation for time series models. <em>Journal of
Statistical Computation and Simulation</em>, 90(14):2499-2523.
:/10.1080/00949655.2020.1783262. <a href="https://www.tandfonline.com/doi/full/10.1080/00949655.2020.1783262" class="external-link">Online</a>.
<a href="https://arxiv.org/abs/1902.06281" class="external-link">arXiv preprint</a>.</p>
<p>Vehtari A., Gelman A., &amp; Gabry J. (2017). Practical Bayesian
model evaluation using leave-one-out cross-validation and WAIC.
<em>Statistics and Computing</em>, 27(5), 1413–1432.
:10.1007/s11222-016-9696-4. <a href="https://link.springer.com/article/10.1007/s11222-016-9696-4" class="external-link">Online</a>.
<a href="https://arxiv.org/abs/1507.04544" class="external-link">arXiv preprint
arXiv:1507.04544</a>.</p>
<p>Vehtari, A., Simpson, D., Gelman, A., Yao, Y., and Gabry, J. (2024).
Pareto smoothed importance sampling. <em>Journal of Machine Learning
Research</em>, 25(72):1-58. <a href="https://jmlr.org/papers/v25/19-556.html" class="external-link">PDF</a></p>
<p><br></p>
</div>
<div class="section level2">
<h2 id="appendix">Appendix<a class="anchor" aria-label="anchor" href="#appendix"></a>
</h2>
<div class="section level3">
<h3 id="appendix-session-information">Appendix: Session information<a class="anchor" aria-label="anchor" href="#appendix-session-information"></a>
</h3>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/sessionInfo.html" class="external-link">sessionInfo</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<pre><code>R version 4.5.1 (2025-06-13 ucrt)
Platform: x86_64-w64-mingw32/x64
Running under: Windows 11 x64 (build 26100)

Matrix products: default
  LAPACK version 3.12.1

locale:
[1] LC_COLLATE=English_United States.utf8 
[2] LC_CTYPE=English_United States.utf8   
[3] LC_MONETARY=English_United States.utf8
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.utf8    

time zone: America/Los_Angeles
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] ggplot2_4.0.0.9000 bayesplot_1.13.0   loo_2.8.0.9000     brms_2.22.0       
[5] Rcpp_1.1.0         knitr_1.50        

loaded via a namespace (and not attached):
 [1] gtable_0.3.6         tensorA_0.36.2.1     xfun_0.53           
 [4] bslib_0.9.0          QuickJSR_1.8.0       htmlwidgets_1.6.4   
 [7] processx_3.8.6       inline_0.3.21        lattice_0.22-7      
[10] callr_3.7.6          ps_1.9.1             vctrs_0.6.5         
[13] tools_4.5.1          generics_0.1.4       stats4_4.5.1        
[16] curl_7.0.0           parallel_4.5.1       tibble_3.3.0        
[19] pkgconfig_2.0.3      Matrix_1.7-4         checkmate_2.3.3     
[22] RColorBrewer_1.1-3   S7_0.2.0             desc_1.4.3          
[25] distributional_0.5.0 RcppParallel_5.1.10  lifecycle_1.0.4     
[28] compiler_4.5.1       farver_2.1.2         stringr_1.5.2       
[31] textshaping_1.0.3    Brobdingnag_1.2-9    codetools_0.2-20    
[34] htmltools_0.5.8.1    sass_0.4.10          yaml_2.3.10         
[37] pillar_1.11.1        pkgdown_2.1.3        jquerylib_0.1.4     
[40] cachem_1.1.0         StanHeaders_2.32.10  bridgesampling_1.1-2
[43] abind_1.4-8          nlme_3.1-168         posterior_1.6.1     
[46] rstan_2.32.7         tidyselect_1.2.1     digest_0.6.37       
[49] mvtnorm_1.3-3        stringi_1.8.7        dplyr_1.1.4.9000    
[52] labeling_0.4.3       fastmap_1.2.0        grid_4.5.1          
[55] colorspace_2.1-1     cli_3.6.5            magrittr_2.0.4      
[58] pkgbuild_1.4.8       withr_3.0.2          scales_1.4.0        
[61] backports_1.5.0      rmarkdown_2.29       matrixStats_1.5.0   
[64] gridExtra_2.3        ragg_1.5.0           coda_0.19-4.1       
[67] evaluate_1.0.5       V8_6.0.5             rstantools_2.4.0    
[70] rlang_1.1.6          glue_1.8.0           jsonlite_2.0.0      
[73] R6_2.6.1             systemfonts_1.2.3    fs_1.6.6            </code></pre>
</div>
<div class="section level3">
<h3 id="appendix-licenses">Appendix: Licenses<a class="anchor" aria-label="anchor" href="#appendix-licenses"></a>
</h3>
<ul>
<li>Code © 2018, Paul Bürkner, Jonah Gabry, Aki Vehtari (licensed under
BSD-3).</li>
<li>Text © 2018, Paul Bürkner, Jonah Gabry, Aki Vehtari (licensed under
CC-BY-NC 4.0).</li>
</ul>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Aki Vehtari, Jonah Gabry, Måns Magnusson, Yuling Yao, Paul-Christian Bürkner, Topi Paananen, Andrew Gelman.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
