<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Using the loo package (version &gt;= 2.0.0) • loo</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Using the loo package (version &gt;= 2.0.0)">
<meta property="og:description" content="loo">
<meta property="og:image" content="https://mc-stan.org/loo/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">loo</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">2.4.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Other Packages
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="https://mc-stan.org/rstan">rstan</a>
    </li>
    <li>
      <a href="https://mc-stan.org/cmdstanr">cmdstanr</a>
    </li>
    <li>
      <a href="https://mc-stan.org/rstanarm">rstanarm</a>
    </li>
    <li>
      <a href="https://mc-stan.org/bayesplot">bayesplot</a>
    </li>
    <li>
      <a href="https://mc-stan.org/shinystan">shinystan</a>
    </li>
    <li>
      <a href="https://mc-stan.org/projpred">projpred</a>
    </li>
    <li>
      <a href="https://mc-stan.org/rstantools">rstantools</a>
    </li>
    <li>
      <a href="https://mc-stan.org/posterior">posterior</a>
    </li>
  </ul>
</li>
<li>
  <a href="https://mc-stan.org">Stan</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://twitter.com/mcmc_stan">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/stan-dev/loo">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="https://discourse.mc-stan.org/">
    <span class="fa fa-users"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="loo-package_files/header-attrs-2.3/header-attrs.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Using the loo package (version &gt;= 2.0.0)</h1>
                        <h4 class="author">Aki Vehtari and Jonah Gabry</h4>
            
            <h4 class="date">2020-12-01</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/stan-dev/loo/blob/master/vignettes/loo-package.Rmd"><code>vignettes/loo-package.Rmd</code></a></small>
      <div class="hidden name"><code>loo-package.Rmd</code></div>

    </div>

    
    
<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{Using the loo package}
-->
<div id="introduction" class="section level1">
<h1 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h1>
<p>This vignette demonstrates how to use the <strong>loo</strong> package to carry out Pareto smoothed importance-sampling leave-one-out cross-validation (PSIS-LOO) for purposes of model checking and model comparison.</p>
<p>In this vignette we can’t provide all necessary background information on PSIS-LOO and its diagnostics (Pareto <span class="math inline">\(k\)</span> and effective sample size), so we encourage readers to refer to the following papers for more details:</p>
<ul>
<li><p>Vehtari, A., Gelman, A., and Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. <em>Statistics and Computing</em>. 27(5), 1413–1432. :10.1007/s11222-016-9696-4. Links: <a href="https://link.springer.com/article/10.1007/s11222-016-9696-4">published</a> | <a href="https://arxiv.org/abs/1507.04544">arXiv preprint</a>.</p></li>
<li><p>Vehtari, A., Simpson, D., Gelman, A., Yao, Y., and Gabry, J. (2019). Pareto smoothed importance sampling. <a href="https://arxiv.org/abs/1507.04544">arXiv preprint arXiv:1507.04544</a>.</p></li>
</ul>
</div>
<div id="setup" class="section level1">
<h1 class="hasAnchor">
<a href="#setup" class="anchor"></a>Setup</h1>
<p>In addition to the <strong>loo</strong> package, we’ll also be using <strong>rstanarm</strong> and <strong>bayesplot</strong>:</p>
<div class="sourceCode" id="cb1"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="st">"rstanarm"</span>)
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="st">"bayesplot"</span>)
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="st">"loo"</span>)</pre></body></html></div>
</div>
<div id="example-poisson-vs-negative-binomial-for-the-roaches-dataset" class="section level1">
<h1 class="hasAnchor">
<a href="#example-poisson-vs-negative-binomial-for-the-roaches-dataset" class="anchor"></a>Example: Poisson vs negative binomial for the roaches dataset</h1>
<div id="background-and-model-fitting" class="section level2">
<h2 class="hasAnchor">
<a href="#background-and-model-fitting" class="anchor"></a>Background and model fitting</h2>
<p>The Poisson and negative binomial regression models used below in our example, as well as the <code>stan_glm</code> function used to fit the models, are covered in more depth in the <strong>rstanarm</strong> vignette <a href="http://mc-stan.org/rstanarm/articles/count.html"><em>Estimating Generalized Linear Models for Count Data with rstanarm</em></a>. In the rest of this vignette we will assume the reader is already familiar with these kinds of models.</p>
<div id="roaches-data" class="section level3">
<h3 class="hasAnchor">
<a href="#roaches-data" class="anchor"></a>Roaches data</h3>
<p>The example data we’ll use comes from Chapter 8.3 of <a href="http://www.stat.columbia.edu/~gelman/arm/">Gelman and Hill (2007)</a>. We want to make inferences about the efficacy of a certain pest management system at reducing the number of roaches in urban apartments. Here is how Gelman and Hill describe the experiment and data (pg. 161):</p>
<blockquote>
<p>the treatment and control were applied to 160 and 104 apartments, respectively, and the outcome measurement <span class="math inline">\(y_i\)</span> in each apartment <span class="math inline">\(i\)</span> was the number of roaches caught in a set of traps. Different apartments had traps for different numbers of days</p>
</blockquote>
<p>In addition to an intercept, the regression predictors for the model are <code>roach1</code>, the pre-treatment number of roaches (rescaled above to be in units of hundreds), the treatment indicator <code>treatment</code>, and a variable indicating whether the apartment is in a building restricted to elderly residents <code>senior</code>. Because the number of days for which the roach traps were used is not the same for all apartments in the sample, we use the <code>offset</code> argument to specify that <code><a href="https://rdrr.io/r/base/Log.html">log(exposure2)</a></code> should be added to the linear predictor.</p>
<div class="sourceCode" id="cb2"><html><body><pre class="r"><span class="co"># the 'roaches' data frame is included with the rstanarm package</span>
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span>(<span class="no">roaches</span>)
<span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span>(<span class="no">roaches</span>)</pre></body></html></div>
<pre><code>'data.frame':   262 obs. of  5 variables:
 $ y        : int  153 127 7 7 0 0 73 24 2 2 ...
 $ roach1   : num  308 331.25 1.67 3 2 ...
 $ treatment: int  1 1 1 1 1 1 1 1 0 0 ...
 $ senior   : int  0 0 0 0 0 0 0 0 0 0 ...
 $ exposure2: num  0.8 0.6 1 1 1.14 ...</code></pre>
<div class="sourceCode" id="cb4"><html><body><pre class="r"><span class="co"># rescale to units of hundreds of roaches</span>
<span class="no">roaches</span>$<span class="no">roach1</span> <span class="kw">&lt;-</span> <span class="no">roaches</span>$<span class="no">roach1</span> / <span class="fl">100</span></pre></body></html></div>
</div>
<div id="fit-poisson-model" class="section level3">
<h3 class="hasAnchor">
<a href="#fit-poisson-model" class="anchor"></a>Fit Poisson model</h3>
<p>We’ll fit a simple Poisson regression model using the <code>stan_glm</code> function from the <strong>rstanarm</strong> package.</p>
<div class="sourceCode" id="cb5"><html><body><pre class="r"><span class="no">fit1</span> <span class="kw">&lt;-</span>
  <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/stan_glm.html">stan_glm</a></span>(
    <span class="kw">formula</span> <span class="kw">=</span> <span class="no">y</span> ~ <span class="no">roach1</span> + <span class="no">treatment</span> + <span class="no">senior</span>,
    <span class="kw">offset</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span>(<span class="no">exposure2</span>),
    <span class="kw">data</span> <span class="kw">=</span> <span class="no">roaches</span>,
    <span class="kw">family</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">poisson</a></span>(<span class="kw">link</span> <span class="kw">=</span> <span class="st">"log"</span>),
    <span class="kw">prior</span> <span class="kw">=</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/priors.html">normal</a></span>(<span class="fl">0</span>, <span class="fl">2.5</span>, <span class="kw">autoscale</span> <span class="kw">=</span> <span class="fl">TRUE</span>),
    <span class="kw">prior_intercept</span> <span class="kw">=</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/priors.html">normal</a></span>(<span class="fl">0</span>, <span class="fl">5</span>, <span class="kw">autoscale</span> <span class="kw">=</span> <span class="fl">TRUE</span>),
    <span class="kw">seed</span> <span class="kw">=</span> <span class="fl">12345</span>
  )</pre></body></html></div>
<p>Usually we would also run posterior predictive checks as shown in the <strong>rstanarm</strong> vignette <a href="http://mc-stan.org/rstanarm/articles/count.html">Estimating Generalized Linear Models for Count Data with rstanarm</a>, but here we focus only on methods provided by the <strong>loo</strong> package.</p>
<p><br></p>
</div>
</div>
<div id="using-the-loo-package-for-model-checking-and-comparison" class="section level2">
<h2 class="hasAnchor">
<a href="#using-the-loo-package-for-model-checking-and-comparison" class="anchor"></a>Using the <strong>loo</strong> package for model checking and comparison</h2>
<p><em>Although cross-validation is mostly used for model comparison, it is also useful for model checking.</em></p>
<div id="computing-psis-loo-and-checking-diagnostics" class="section level3">
<h3 class="hasAnchor">
<a href="#computing-psis-loo-and-checking-diagnostics" class="anchor"></a>Computing PSIS-LOO and checking diagnostics</h3>
<p>We start by computing PSIS-LOO with the <code>loo</code> function. Since we fit our model using <strong>rstanarm</strong> we can use the <code>loo</code> method for <code>stanreg</code> objects (fitted model objects from <strong>rstanarm</strong>), which doesn’t require us to first extract the pointwise log-likelihood values. If we had written our own Stan program instead of using <strong>rstanarm</strong> we would pass an array or matrix of log-likelihood values to the <code>loo</code> function (see, e.g. <code><a href="../reference/loo.html">help("loo.array", package = "loo")</a></code>). We’ll also use the argument <code>save_psis = TRUE</code> to save some intermediate results to be re-used later.</p>
<div class="sourceCode" id="cb6"><html><body><pre class="r"><span class="no">loo1</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/loo.html">loo</a></span>(<span class="no">fit1</span>, <span class="kw">save_psis</span> <span class="kw">=</span> <span class="fl">TRUE</span>)</pre></body></html></div>
<pre><code>Warning: Found 17 observations with a pareto_k &gt; 0.7. With this many problematic observations we recommend calling 'kfold' with argument 'K=10' to perform 10-fold cross-validation rather than LOO.</code></pre>
<p><code>loo</code> gives us warnings about the Pareto diagnostics, which indicate that for some observations the leave-one-out posteriors are different enough from the full posterior that importance-sampling is not able to correct the difference. We can see more details by printing the <code>loo</code> object.</p>
<div class="sourceCode" id="cb8"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span>(<span class="no">loo1</span>)</pre></body></html></div>
<pre><code>
Computed from 4000 by 262 log-likelihood matrix

         Estimate     SE
elpd_loo  -6247.8  728.0
p_loo       292.4   73.3
looic     12495.5 1455.9
------
Monte Carlo SE of elpd_loo is NA.

Pareto k diagnostic values:
                         Count Pct.    Min. n_eff
(-Inf, 0.5]   (good)     239   91.2%   200       
 (0.5, 0.7]   (ok)         6    2.3%   56        
   (0.7, 1]   (bad)        8    3.1%   25        
   (1, Inf)   (very bad)   9    3.4%   1         
See help('pareto-k-diagnostic') for details.</code></pre>
<p>The table shows us a summary of Pareto <span class="math inline">\(k\)</span> diagnostic, which is used to assess the reliability of the estimates. In addition to the proportion of leave-one-out folds with <span class="math inline">\(k\)</span> values in different intervals, the minimum of the effective sample sizes in that category is shown to give idea why higher <span class="math inline">\(k\)</span> values are bad. Since we have some <span class="math inline">\(k&gt;1\)</span>, we are not able to compute an estimate for the Monte Carlo standard error (SE) of the expected log predictive density (<code>elpd_loo</code>) and <code>NA</code> is displayed. (Full details on the interpretation of the Pareto <span class="math inline">\(k\)</span> diagnostics are available in the Vehtari, Gelman, and Gabry (2017) and Vehtari, Simpson, Gelman, Yao, and Gabry (2019) papers referenced at the top of this vignette.)</p>
<p>In this case the <code>elpd_loo</code> estimate should not be considered reliable. If we had a well-specified model we would expect the estimated effective number of parameters (<code>p_loo</code>) to be smaller than or similar to the total number of parameters in the model. Here <code>p_loo</code> is almost 300, which is about 70 times the total number of parameters in the model, indicating severe model misspecification.</p>
</div>
<div id="plotting-pareto-k-diagnostics" class="section level3">
<h3 class="hasAnchor">
<a href="#plotting-pareto-k-diagnostics" class="anchor"></a>Plotting Pareto <span class="math inline">\(k\)</span> diagnostics</h3>
<p>Using the <code>plot</code> method on our <code>loo1</code> object produces a plot of the <span class="math inline">\(k\)</span> values (in the same order as the observations in the dataset used to fit the model) with horizontal lines corresponding to the same categories as in the printed output above.</p>
<div class="sourceCode" id="cb10"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/plot.html">plot</a></span>(<span class="no">loo1</span>)</pre></body></html></div>
<p><img src="loo-package_files/figure-html/plot-loo1-1.png" width="70%" style="display: block; margin: auto;"></p>
<p>This plot is useful to quickly see the distribution of <span class="math inline">\(k\)</span> values, but it’s often also possible to see structure with respect to data ordering. In our case this is mild, but there seems to be a block of data that is somewhat easier to predict (indices around 90–150). Unfortunately even for these data points we see some high <span class="math inline">\(k\)</span> values.</p>
</div>
<div id="marginal-posterior-predictive-checks" class="section level3">
<h3 class="hasAnchor">
<a href="#marginal-posterior-predictive-checks" class="anchor"></a>Marginal posterior predictive checks</h3>
<p>The <code>loo</code> package can be used in combination with the <code>bayesplot</code> package for leave-one-out cross-validation marginal posterior predictive checks <a href="https://arxiv.org/abs/1709.01449">Gabry et al (2018)</a>. LOO-PIT values are cumulative probabilities for <span class="math inline">\(y_i\)</span> computed using the LOO marginal predictive distributions <span class="math inline">\(p(y_i|y_{-i})\)</span>. For a good model, the distribution of LOO-PIT values should be uniform. In the following plot the distribution (smoothed density estimate) of the LOO-PIT values for our model (thick curve) is compared to many independently generated samples (each the same size as our dataset) from the standard uniform distribution (thin curves).</p>
<div class="sourceCode" id="cb11"><html><body><pre class="r"><span class="no">yrep</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/posterior_predict.stanreg.html">posterior_predict</a></span>(<span class="no">fit1</span>)

<span class="fu"><a href="https://mc-stan.org/bayesplot/reference/PPC-loo.html">ppc_loo_pit_overlay</a></span>(
  <span class="kw">y</span> <span class="kw">=</span> <span class="no">roaches</span>$<span class="no">y</span>,
  <span class="kw">yrep</span> <span class="kw">=</span> <span class="no">yrep</span>,
  <span class="kw">lw</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/weights.html">weights</a></span>(<span class="no">loo1</span>$<span class="no">psis_object</span>)
)</pre></body></html></div>
<p><img src="loo-package_files/figure-html/ppc_loo_pit_overlay-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>The excessive number of values close to 0 indicates that the model is under-dispersed compared to the data, and we should consider a model that allows for greater dispersion.</p>
</div>
</div>
<div id="try-alternative-model-with-more-flexibility" class="section level2">
<h2 class="hasAnchor">
<a href="#try-alternative-model-with-more-flexibility" class="anchor"></a>Try alternative model with more flexibility</h2>
<p>Here we will try <a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution">negative binomial</a> regression, which is commonly used for overdispersed count data.<br>
Unlike the Poisson distribution, the negative binomial distribution allows the conditional mean and variance of <span class="math inline">\(y\)</span> to differ.</p>
<div class="sourceCode" id="cb12"><html><body><pre class="r"><span class="no">fit2</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span>(<span class="no">fit1</span>, <span class="kw">family</span> <span class="kw">=</span> <span class="no">neg_binomial_2</span>)</pre></body></html></div>
<div class="sourceCode" id="cb13"><html><body><pre class="r"><span class="no">loo2</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/loo.html">loo</a></span>(<span class="no">fit2</span>, <span class="kw">save_psis</span> <span class="kw">=</span> <span class="fl">TRUE</span>, <span class="kw">cores</span> <span class="kw">=</span> <span class="fl">2</span>)</pre></body></html></div>
<pre><code>Warning: Found 1 observation(s) with a pareto_k &gt; 0.7. We recommend calling 'loo' again with argument 'k_threshold = 0.7' in order to calculate the ELPD without the assumption that these observations are negligible. This will refit the model 1 times to compute the ELPDs for the problematic observations directly.</code></pre>
<div class="sourceCode" id="cb15"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span>(<span class="no">loo2</span>)</pre></body></html></div>
<pre><code>
Computed from 4000 by 262 log-likelihood matrix

         Estimate   SE
elpd_loo   -895.6 37.8
p_loo         6.7  2.7
looic      1791.3 75.5
------
Monte Carlo SE of elpd_loo is NA.

Pareto k diagnostic values:
                         Count Pct.    Min. n_eff
(-Inf, 0.5]   (good)     260   99.2%   2615      
 (0.5, 0.7]   (ok)         1    0.4%   377       
   (0.7, 1]   (bad)        1    0.4%   28        
   (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;      
See help('pareto-k-diagnostic') for details.</code></pre>
<div class="sourceCode" id="cb17"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/plot.html">plot</a></span>(<span class="no">loo2</span>, <span class="kw">label_points</span> <span class="kw">=</span> <span class="fl">TRUE</span>)</pre></body></html></div>
<p><img src="loo-package_files/figure-html/plot-loo2-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>Using the <code>label_points</code> argument will label any <span class="math inline">\(k\)</span> values larger than 0.7 with the index of the corresponding data point. These high values are often the result of model misspecification and frequently correspond to data points that would be considered ``outliers’’ in the data and surprising according to the model <a href="https://arxiv.org/abs/1709.01449">Gabry et al (2019)</a>. Unfortunately, while large <span class="math inline">\(k\)</span> values are a useful indicator of model misspecification, small <span class="math inline">\(k\)</span> values are not a guarantee that a model is well-specified.</p>
<p>If there are a small number of problematic <span class="math inline">\(k\)</span> values then we can use a feature in <strong>rstanarm</strong> that lets us refit the model once for each of these problematic observations. Each time the model is refit, one of the observations with a high <span class="math inline">\(k\)</span> value is omitted and the LOO calculations are performed exactly for that observation. The results are then recombined with the approximate LOO calculations already carried out for the observations without problematic <span class="math inline">\(k\)</span> values:</p>
<div class="sourceCode" id="cb18"><html><body><pre class="r"><span class="kw">if</span> (<span class="fu"><a href="https://rdrr.io/r/base/any.html">any</a></span>(<span class="fu"><a href="../reference/pareto-k-diagnostic.html">pareto_k_values</a></span>(<span class="no">loo2</span>) <span class="kw">&gt;</span> <span class="fl">0.7</span>)) {
  <span class="no">loo2</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/loo.html">loo</a></span>(<span class="no">fit2</span>, <span class="kw">save_psis</span> <span class="kw">=</span> <span class="fl">TRUE</span>, <span class="kw">k_threshold</span> <span class="kw">=</span> <span class="fl">0.7</span>)
}</pre></body></html></div>
<pre><code>1 problematic observation(s) found.
Model will be refit 1 times.</code></pre>
<pre><code>
Fitting model 1 out of 1 (leaving out observation 93)</code></pre>
<div class="sourceCode" id="cb21"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span>(<span class="no">loo2</span>)</pre></body></html></div>
<pre><code>
Computed from 4000 by 262 log-likelihood matrix

         Estimate   SE
elpd_loo   -895.5 37.7
p_loo         6.6  2.6
looic      1791.1 75.4
------
Monte Carlo SE of elpd_loo is 0.2.

Pareto k diagnostic values:
                         Count Pct.    Min. n_eff
(-Inf, 0.5]   (good)     260   99.6%   2615      
 (0.5, 0.7]   (ok)         1    0.4%   377       
   (0.7, 1]   (bad)        0    0.0%   &lt;NA&gt;      
   (1, Inf)   (very bad)   0    0.0%   &lt;NA&gt;      

All Pareto k estimates are ok (k &lt; 0.7).
See help('pareto-k-diagnostic') for details.</code></pre>
<p>In the print output we can see that the Monte Carlo SE is small compared to the other uncertainties.</p>
<p>On the other hand, <code>p_loo</code> is about 7 and still a bit higher than the total number of parameters in the model. This indicates that there is almost certainly still some degree of model misspecification, but this is much better than the <code>p_loo</code> estimate for the Poisson model.</p>
<p>For further model checking we again examine the LOO-PIT values.</p>
<div class="sourceCode" id="cb23"><html><body><pre class="r"><span class="no">yrep</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstanarm/reference/posterior_predict.stanreg.html">posterior_predict</a></span>(<span class="no">fit2</span>)
<span class="fu"><a href="https://mc-stan.org/bayesplot/reference/PPC-loo.html">ppc_loo_pit_overlay</a></span>(<span class="no">roaches</span>$<span class="no">y</span>, <span class="no">yrep</span>, <span class="kw">lw</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/weights.html">weights</a></span>(<span class="no">loo2</span>$<span class="no">psis_object</span>))</pre></body></html></div>
<p><img src="loo-package_files/figure-html/ppc_loo_pit_overlay-negbin-1.png" width="60%" style="display: block; margin: auto;"></p>
<p>The plot for the negative binomial model looks better than the Poisson plot, but we still see that this model is not capturing all of the essential features in the data.</p>
</div>
<div id="comparing-the-models-on-expected-log-predictive-density" class="section level2">
<h2 class="hasAnchor">
<a href="#comparing-the-models-on-expected-log-predictive-density" class="anchor"></a>Comparing the models on expected log predictive density</h2>
<p>We can use the <code>loo_compare</code> function to compare our two models on expected log predictive density (ELPD) for new data:</p>
<div class="sourceCode" id="cb24"><html><body><pre class="r"><span class="fu"><a href="../reference/loo_compare.html">loo_compare</a></span>(<span class="no">loo1</span>, <span class="no">loo2</span>)</pre></body></html></div>
<pre><code>     elpd_diff se_diff
fit2     0.0       0.0
fit1 -5352.2     709.2</code></pre>
<p>The difference in ELPD is much larger than several times the estimated standard error of the difference again indicating that the negative-binomial model is expected to have better predictive performance than the Poisson model. However, according to the LOO-PIT checks there is still some misspecification, and a reasonable guess is that a hurdle or zero-inflated model would be an improvement (we leave that for another case study).</p>
<p><br></p>
</div>
</div>
<div id="references" class="section level1">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<p>Gabry, J., Simpson, D., Vehtari, A., Betancourt, M. and Gelman, A. (2019), Visualization in Bayesian workflow. <em>J. R. Stat. Soc. A</em>, 182: 389-402. :10.1111/rssa.12378. (<a href="https://rss.onlinelibrary.wiley.com/doi/full/10.1111/rssa.12378">journal version</a>, <a href="https://arxiv.org/abs/1709.01449">arXiv preprint</a>, <a href="https://github.com/jgabry/bayes-vis-paper">code on GitHub</a>) <a id="gabry2019"></a></p>
<p>Gelman, A. and Hill, J. (2007). <em>Data Analysis Using Regression and Multilevel/Hierarchical Models.</em> Cambridge University Press, Cambridge, UK.</p>
<p>Vehtari, A., Gelman, A., and Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. <em>Statistics and Computing</em>. 27(5), 1413–1432. :10.1007/s11222-016-9696-4. <a href="https://link.springer.com/article/10.1007/s11222-016-9696-4">online</a>, <a href="https://arxiv.org/abs/1507.04544">arXiv preprint arXiv:1507.04544</a>.</p>
<p>Vehtari, A., Simpson, D., Gelman, A., Yao, Y., and Gabry, J. (2019). Pareto smoothed importance sampling. <a href="https://arxiv.org/abs/1507.02646">arXiv preprint arXiv:1507.02646</a>.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Aki Vehtari, Jonah Gabry, Mans Magnusson, Yuling Yao, Paul-Christian Bürkner, Topi Paananen, Andrew Gelman.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
