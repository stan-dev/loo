<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>LOO package glossary — loo-glossary • loo</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="LOO package glossary — loo-glossary"><meta property="og:description" content="The pages provides definitions to key terms. Also see the
FAQ page on
the loo website for answers to frequently asked questions.
Note: VGG2017 refers to Vehtari, Gelman, and Gabry (2017). See
References, below."><meta property="og:image" content="https://mc-stan.org/loo/logo.svg"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">loo</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">2.8.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Other Packages
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="https://mc-stan.org/rstan" class="external-link">rstan</a>
    </li>
    <li>
      <a href="https://mc-stan.org/cmdstanr" class="external-link">cmdstanr</a>
    </li>
    <li>
      <a href="https://mc-stan.org/rstanarm" class="external-link">rstanarm</a>
    </li>
    <li>
      <a href="https://mc-stan.org/bayesplot" class="external-link">bayesplot</a>
    </li>
    <li>
      <a href="https://mc-stan.org/shinystan" class="external-link">shinystan</a>
    </li>
    <li>
      <a href="https://mc-stan.org/projpred" class="external-link">projpred</a>
    </li>
    <li>
      <a href="https://mc-stan.org/rstantools" class="external-link">rstantools</a>
    </li>
    <li>
      <a href="https://mc-stan.org/posterior" class="external-link">posterior</a>
    </li>
  </ul></li>
<li>
  <a href="https://mc-stan.org" class="external-link">Stan</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://twitter.com/mcmc_stan" class="external-link">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/stan-dev/loo" class="external-link">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="https://discourse.mc-stan.org/" class="external-link">
    <span class="fa fa-users"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>LOO package glossary</h1>
    <small class="dont-index">Source: <a href="https://github.com/stan-dev/loo/blob/HEAD/R/loo-glossary.R" class="external-link"><code>R/loo-glossary.R</code></a></small>
    <div class="hidden name"><code>loo-glossary.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>The pages provides definitions to key terms. Also see the
<a href="https://mc-stan.org/loo/articles/online-only/faq.html">FAQ page</a> on
the <strong>loo</strong> website for answers to frequently asked questions.</p>
<p>Note: VGG2017 refers to Vehtari, Gelman, and Gabry (2017). See
<strong>References</strong>, below.</p>
    </div>


    <div id="elpd-and-elpd-loo">
    <h2>ELPD and <code>elpd_loo</code></h2>
    


<p>The ELPD is the theoretical expected log pointwise predictive density for a new
dataset (Eq 1 in VGG2017), which can be estimated, e.g., using
cross-validation. <code>elpd_loo</code> is the Bayesian LOO estimate of the
expected log pointwise predictive density (Eq 4 in VGG2017) and
is a sum of N individual pointwise log predictive densities. Probability
densities can be smaller or larger than 1, and thus log predictive densities
can be negative or positive. For simplicity the ELPD acronym is used also for
expected log pointwise predictive probabilities for discrete models.
Probabilities are always equal or less than 1, and thus log predictive
probabilities are 0 or negative.</p>
    </div>
    <div id="standard-error-of-elpd-loo">
    <h2>Standard error of <code>elpd_loo</code></h2>
    


<p>As <code>elpd_loo</code> is defined as the sum of N independent components (Eq 4 in
VGG2017), we can compute the standard error by using the standard deviation
of the N components and multiplying by <code>sqrt(N)</code> (Eq 23 in VGG2017).
This standard error is a coarse description of our uncertainty about the
predictive performance for unknown future data. When N is small or there is
severe model misspecification, the current SE estimate is overoptimistic and
the actual SE can even be twice as large. Even for moderate N, when the SE
estimate is an accurate estimate for the scale, it ignores the skewness. When
making model comparisons, the SE of the component-wise (pairwise) differences
should be used instead (see the <code>se_diff</code> section below and Eq 24 in
VGG2017). Sivula et al. (2022) discuss the conditions when the normal
approximation used for SE and <code>se_diff</code> is good.</p>
    </div>
    <div id="monte-carlo-se-of-elpd-loo">
    <h2>Monte Carlo SE of elpd_loo</h2>
    


<p>The Monte Carlo standard error is the estimate for the computational accuracy
of MCMC and importance sampling used to compute <code>elpd_loo</code>. Usually this
is negligible compared to the standard describing the uncertainty due to
finite number of observations (Eq 23 in VGG2017).</p>
    </div>
    <div id="p-loo-effective-number-of-parameters-">
    <h2><code>p_loo</code> (effective number of parameters)</h2>
    


<p><code>p_loo</code> is the difference between <code>elpd_loo</code> and the non-cross-validated
log posterior predictive density. It describes how much more difficult it
is to predict future data than the observed data. Asymptotically under
certain regularity conditions, <code>p_loo</code> can be interpreted as the
<em>effective number of parameters</em>. In well behaving cases <code>p_loo &lt; N</code> and
<code>p_loo &lt; p</code>, where <code>p</code> is the total number of parameters in the
model. <code>p_loo &gt; N</code>  or <code>p_loo &gt; p</code> indicates that the model has very
weak predictive capability and may indicate a severe model misspecification.
See below for more on interpreting <code>p_loo</code> when there are warnings
about high Pareto k diagnostic values.</p>
    </div>
    <div id="pareto-k-estimates">
    <h2>Pareto k estimates</h2>
    


<p>The Pareto \(k\) estimate is a diagnostic for Pareto smoothed importance
sampling (PSIS), which is used to compute components of <code>elpd_loo</code>. In
importance-sampling LOO the full posterior distribution is used as the
proposal distribution. The Pareto k diagnostic estimates how far an
individual leave-one-out distribution is from the full distribution. If
leaving out an observation changes the posterior too much then importance
sampling is not able to give a reliable estimate. Pareto smoothing stabilizes
importance sampling and guarantees a finite variance estimate at the
cost of some bias.</p>
<p>The diagnostic threshold for Pareto \(k\) depends on sample size
\(S\) (sample size dependent threshold was introduced by Vehtari
et al., 2022, and before that fixed thresholds of 0.5 and 0.7 were
recommended). For simplicity, <code>loo</code> package uses the nominal sample
size \(S\)  when computing the sample size specific
threshold. This provides an optimistic threshold if the effective
sample size is less than 2200, but even then if ESS/S &gt; 1/2 the difference
is usually negligible. Thinning of MCMC draws can be used to improve
the ratio ESS/S.</p><ul><li><p>If \(k &lt; \min(1 - 1 / \log_{10}(S), 0.7)\), where \(S\) is the
sample size, the PSIS estimate and the corresponding Monte
Carlo standard error estimate are reliable.</p></li>
<li><p>If \(1 - 1 / \log_{10}(S) &lt;= k &lt; 0.7\), the PSIS estimate and the
corresponding Monte Carlo standard error estimate are not
reliable, but increasing the (effective) sample size \(S\) above
2200 may help (this will increase the sample size specific
threshold \((1 - 1 / \log_{10}(2200) &gt; 0.7\) and then the bias specific
threshold 0.7 dominates).</p></li>
<li><p>If \(0.7 &lt;= k &lt; 1\), the PSIS estimate and the corresponding Monte
Carlo standard error have large bias and are not reliable. Increasing
the sample size may reduce the variability in the \(k\) estimate, which
may also result in a lower \(k\) estimate.</p></li>
<li><p>If \(k \geq 1\), the target distribution is estimated to
have non-finite mean. The PSIS estimate and the corresponding Monte
Carlo standard error are not well defined. Increasing the sample size
may reduce the variability in \(k\) estimate, which may also result in
a lower \(k\) estimate.</p></li>
</ul><p>Pareto \(k\) is also useful as a measure of influence of an
observation.  Highly influential observations have high \(k\)
values. Very high \(k\) values often indicate model
misspecification, outliers or mistakes in data processing. See
Section 6 of Gabry et al. (2019) for an example.</p>
<div class="section">
<h3 id="interpreting-p-loo-when-pareto-k-is-large">Interpreting <code>p_loo</code> when Pareto <code>k</code> is large<a class="anchor" aria-label="anchor" href="#interpreting-p-loo-when-pareto-k-is-large"></a></h3>
<p>If \(k &gt; 0.7\) then we can also look at
the <code>p_loo</code> estimate for some additional information about the problem:</p><ul><li><p>If <code>p_loo &lt;&lt; p</code> (the total number of parameters in the model),
then the model is likely to be misspecified. Posterior predictive checks
(PPCs) are then likely to also detect the problem. Try using an overdispersed
model, or add more structural information (nonlinearity, mixture model,
etc.).</p></li>
<li><p>If <code>p_loo &lt; p</code> and the number of parameters <code>p</code> is relatively
large compared to the number of observations (e.g., <code>p&gt;N/5</code>), it is
likely that the model is so flexible or the population prior so weak that it’s
difficult to predict the left out observation (even for the true model).
This happens, for example, in the simulated 8 schools (in VGG2017), random
effect models with a few observations per random effect, and Gaussian
processes and spatial models with short correlation lengths.</p></li>
<li><p>If <code>p_loo &gt; p</code>, then the model is likely to be badly misspecified.
If the number of parameters <code>p&lt;&lt;N</code>, then PPCs are also likely to detect the
problem. See the case study at
<a href="https://avehtari.github.io/modelselection/roaches.html" class="external-link">https://avehtari.github.io/modelselection/roaches.html</a> for an example.
If <code>p</code> is relatively large compared to the number of
observations, say <code>p&gt;N/5</code> (more accurately we should count number of
observations influencing each parameter as in hierarchical models some groups
may have few observations and other groups many), it is possible that PPCs won't
detect the problem.</p></li>
</ul></div>

    </div>
    <div id="elpd-diff">
    <h2>elpd_diff</h2>
    

<p><code>elpd_diff</code> is the difference in <code>elpd_loo</code> for two models. If more
than two models are compared, the difference is computed relative to the
model with highest <code>elpd_loo</code>.</p>
    </div>
    <div id="se-diff">
    <h2>se_diff</h2>
    


<p>The standard error of component-wise differences of elpd_loo (Eq 24 in
VGG2017) between two models. This SE is <em>smaller</em> than the SE for
individual models due to correlation (i.e., if some observations are easier
and some more difficult to predict for all models).</p>
    </div>
    <div id="references">
    <h2>References</h2>
    <p>Vehtari, A., Gelman, A., and Gabry, J. (2017a). Practical Bayesian model
evaluation using leave-one-out cross-validation and WAIC.
<em>Statistics and Computing</em>. 27(5), 1413--1432. doi:10.1007/s11222-016-9696-4
(<a href="https://link.springer.com/article/10.1007/s11222-016-9696-4" class="external-link">journal version</a>,
<a href="https://arxiv.org/abs/1507.04544" class="external-link">preprint arXiv:1507.04544</a>).</p>
<p>Vehtari, A., Simpson, D., Gelman, A., Yao, Y., and Gabry, J. (2022).
Pareto smoothed importance sampling.
<a href="https://arxiv.org/abs/1507.02646" class="external-link">preprint arXiv:1507.02646</a></p>
<p>Sivula, T, Magnusson, M., Matamoros A. A., and Vehtari,
A. (2022).  Uncertainty in Bayesian leave-one-out
cross-validation based model comparison. <a href="https://arxiv.org/abs/2008.10296v3" class="external-link">preprint arXiv:2008.10296v3.</a>.</p>
<p>Gabry, J. , Simpson, D. , Vehtari, A. , Betancourt, M. and
Gelman, A. (2019), Visualization in Bayesian workflow.
<em>J. R. Stat. Soc. A</em>, 182: 389-402. doi:10.1111/rssa.12378
(<a href="https://rss.onlinelibrary.wiley.com/doi/full/10.1111/rssa.12378" class="external-link">journal version</a>,
<a href="https://arxiv.org/abs/1709.01449" class="external-link">preprint arXiv:1709.01449</a>,
<a href="https://github.com/jgabry/bayes-vis-paper" class="external-link">code on GitHub</a>)</p>
    </div>

  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Aki Vehtari, Jonah Gabry, Måns Magnusson, Yuling Yao, Paul-Christian Bürkner, Topi Paananen, Andrew Gelman.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

      </footer></div>

  


  

  </body></html>

