<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Mixture IS leave-one-out cross-validation for high-dimensional Bayesian models • loo</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Mixture IS leave-one-out cross-validation for high-dimensional Bayesian models">
<meta property="og:description" content="loo">
<meta property="og:image" content="https://mc-stan.org/loo/logo.svg">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">loo</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">2.8.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/index.html">Vignettes</a>
</li>
<li>
  <a href="../reference/index.html">Functions</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Other Packages
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="https://mc-stan.org/rstan" class="external-link">rstan</a>
    </li>
    <li>
      <a href="https://mc-stan.org/cmdstanr" class="external-link">cmdstanr</a>
    </li>
    <li>
      <a href="https://mc-stan.org/rstanarm" class="external-link">rstanarm</a>
    </li>
    <li>
      <a href="https://mc-stan.org/bayesplot" class="external-link">bayesplot</a>
    </li>
    <li>
      <a href="https://mc-stan.org/shinystan" class="external-link">shinystan</a>
    </li>
    <li>
      <a href="https://mc-stan.org/projpred" class="external-link">projpred</a>
    </li>
    <li>
      <a href="https://mc-stan.org/rstantools" class="external-link">rstantools</a>
    </li>
    <li>
      <a href="https://mc-stan.org/posterior" class="external-link">posterior</a>
    </li>
  </ul>
</li>
<li>
  <a href="https://mc-stan.org" class="external-link">Stan</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://twitter.com/mcmc_stan" class="external-link">
    <span class="fa fa-twitter"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/stan-dev/loo" class="external-link">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="https://discourse.mc-stan.org/" class="external-link">
    <span class="fa fa-users"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Mixture IS leave-one-out cross-validation for
high-dimensional Bayesian models</h1>
                        <h4 data-toc-skip class="author">Luca Silva and
Giacomo Zanella</h4>
            
            <h4 data-toc-skip class="date">2024-07-03</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/stan-dev/loo/blob/HEAD/vignettes/loo2-mixis.Rmd" class="external-link"><code>vignettes/loo2-mixis.Rmd</code></a></small>
      <div class="hidden name"><code>loo2-mixis.Rmd</code></div>

    </div>

    
    
<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{Mixture IS leave-one-out cross-validation for high-dimensional Bayesian models}
-->
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>This vignette shows how to perform Bayesian leave-one-out
cross-validation (LOO-CV) using the mixture estimators proposed in the
paper <a href="https://arxiv.org/abs/2209.09190" class="external-link">Silva and Zanella
(2022)</a>. These estimators have shown to be useful in presence of
outliers but also, and especially, in high-dimensional settings where
the model features many parameters. In these contexts it can happen that
a large portion of observations lead to high values of Pareto-<span class="math inline">\(k\)</span> diagnostics and potential instability
of PSIS-LOO estimators.</p>
<p>For this illustration we consider a high-dimensional Bayesian
Logistic regression model applied to the <em>Voice</em> dataset.</p>
<div class="section level3">
<h3 id="setup-load-packages-and-set-seed">Setup: load packages and set seed<a class="anchor" aria-label="anchor" href="#setup-load-packages-and-set-seed"></a>
</h3>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://mc-stan.org/rstan/" class="external-link">"rstan"</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://mc-stan.org/loo/">"loo"</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/HenrikBengtsson/matrixStats" class="external-link">"matrixStats"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span>mc.cores <span class="op">=</span> <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/detectCores.html" class="external-link">detectCores</a></span><span class="op">(</span><span class="op">)</span>, parallel<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">24877</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="model">Model<a class="anchor" aria-label="anchor" href="#model"></a>
</h3>
<p>This is the Stan code for a logistic regression model with
regularized horseshoe prior. The code includes an if statement to
include a code line needed later for the MixIS approach.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Note: some syntax used in this program requires RStan &gt;= 2.26 (or CmdStanR)</span></span>
<span><span class="co"># To use an older version of RStan change the line declaring `y` to:</span></span>
<span><span class="co">#    int&lt;lower=0,upper=1&gt; y[N];</span></span>
<span><span class="va">stancode_horseshoe</span> <span class="op">&lt;-</span> <span class="st">"</span></span>
<span><span class="st">data {</span></span>
<span><span class="st">  int &lt;lower=0&gt; N;</span></span>
<span><span class="st">  int &lt;lower=0&gt; P;</span></span>
<span><span class="st">  array[N] int &lt;lower=0, upper=1&gt; y;</span></span>
<span><span class="st">  matrix [N,P] X;</span></span>
<span><span class="st">  real &lt;lower=0&gt; scale_global;</span></span>
<span><span class="st">  int &lt;lower=0,upper=1&gt; mixis;</span></span>
<span><span class="st">}</span></span>
<span><span class="st">transformed data {</span></span>
<span><span class="st">  real&lt;lower=1&gt; nu_global=1; // degrees of freedom for the half-t priors for tau</span></span>
<span><span class="st">  real&lt;lower=1&gt; nu_local=1;  // degrees of freedom for the half-t priors for lambdas</span></span>
<span><span class="st">                             // (nu_local = 1 corresponds to the horseshoe)</span></span>
<span><span class="st">  real&lt;lower=0&gt; slab_scale=2;// for the regularized horseshoe</span></span>
<span><span class="st">  real&lt;lower=0&gt; slab_df=100; // for the regularized horseshoe</span></span>
<span><span class="st">}</span></span>
<span><span class="st">parameters {</span></span>
<span><span class="st">  vector[P] z;                // for non-centered parameterization</span></span>
<span><span class="st">  real &lt;lower=0&gt; tau;         // global shrinkage parameter</span></span>
<span><span class="st">  vector &lt;lower=0&gt;[P] lambda; // local shrinkage parameter</span></span>
<span><span class="st">  real&lt;lower=0&gt; caux;</span></span>
<span><span class="st">}</span></span>
<span><span class="st">transformed parameters {</span></span>
<span><span class="st">  vector[P] beta;</span></span>
<span><span class="st">  { </span></span>
<span><span class="st">    vector[P] lambda_tilde;   // 'truncated' local shrinkage parameter</span></span>
<span><span class="st">    real c = slab_scale * sqrt(caux); // slab scale</span></span>
<span><span class="st">    lambda_tilde = sqrt( c^2 * square(lambda) ./ (c^2 + tau^2*square(lambda)));</span></span>
<span><span class="st">    beta = z .* lambda_tilde*tau;</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">}</span></span>
<span><span class="st">model {</span></span>
<span><span class="st">  vector[N] means=X*beta;</span></span>
<span><span class="st">  vector[N] log_lik;</span></span>
<span><span class="st">  target += std_normal_lpdf(z);</span></span>
<span><span class="st">  target += student_t_lpdf(lambda | nu_local, 0, 1);</span></span>
<span><span class="st">  target += student_t_lpdf(tau | nu_global, 0, scale_global);</span></span>
<span><span class="st">  target += inv_gamma_lpdf(caux | 0.5*slab_df, 0.5*slab_df);</span></span>
<span><span class="st">  for (n in 1:N) {</span></span>
<span><span class="st">    log_lik[n]= bernoulli_logit_lpmf(y[n] | means[n]);</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">  target += sum(log_lik);</span></span>
<span><span class="st">  if (mixis) {</span></span>
<span><span class="st">    target += log_sum_exp(-log_lik);</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">}</span></span>
<span><span class="st">generated quantities {</span></span>
<span><span class="st">  vector[N] means=X*beta;</span></span>
<span><span class="st">  vector[N] log_lik;</span></span>
<span><span class="st">  for (n in 1:N) {</span></span>
<span><span class="st">    log_lik[n] = bernoulli_logit_lpmf(y[n] | means[n]);</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">}</span></span>
<span><span class="st">"</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="dataset">Dataset<a class="anchor" aria-label="anchor" href="#dataset"></a>
</h3>
<p>The <em>LSVT Voice Rehabilitation Data Set</em> (see <a href="https://archive.ics.uci.edu/ml/datasets/LSVT+Voice+Rehabilitation" class="external-link">link</a>
for details) has <span class="math inline">\(p=312\)</span> covariates
and <span class="math inline">\(n=126\)</span> observations with binary
response. We construct data list for Stan.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">voice</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">voice</span><span class="op">$</span><span class="va">y</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="va">voice</span><span class="op">[</span><span class="fl">2</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">voice</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span></span>
<span><span class="va">p0</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span><span class="va">scale_global</span> <span class="op">&lt;-</span> <span class="fl">2</span><span class="op">*</span><span class="va">p0</span><span class="op">/</span><span class="op">(</span><span class="va">p</span><span class="op">-</span><span class="va">p0</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">n</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">standata</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>N <span class="op">=</span> <span class="va">n</span>, P <span class="op">=</span> <span class="va">p</span>, X <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, scale_global <span class="op">=</span> <span class="va">scale_global</span>, mixis <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<p>Note that in our prior specification we divide the prior variance by
the number of covariates <span class="math inline">\(p\)</span>. This is
often done in high-dimensional contexts to have a prior variance for the
linear predictors <span class="math inline">\(X\beta\)</span> that
remains bounded as <span class="math inline">\(p\)</span> increases.</p>
</div>
<div class="section level3">
<h3 id="psis-estimators-and-pareto-k-diagnostics">PSIS estimators and Pareto-<span class="math inline">\(k\)</span>
diagnostics<a class="anchor" aria-label="anchor" href="#psis-estimators-and-pareto-k-diagnostics"></a>
</h3>
<p>LOO-CV computations are challenging in this context due to
high-dimensionality of the parameter space. To show that, we compute
PSIS-LOO estimators, which require sampling from the posterior
distribution, and inspect the associated Pareto-<span class="math inline">\(k\)</span> diagnostics.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">chains</span> <span class="op">&lt;-</span> <span class="fl">4</span></span>
<span><span class="va">n_iter</span> <span class="op">&lt;-</span> <span class="fl">2000</span></span>
<span><span class="va">warm_iter</span> <span class="op">&lt;-</span> <span class="fl">1000</span></span>
<span><span class="va">stanmodel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstan/reference/stan_model.html" class="external-link">stan_model</a></span><span class="op">(</span>model_code <span class="op">=</span> <span class="va">stancode_horseshoe</span><span class="op">)</span></span></code></pre></div>
<pre><code>Trying to compile a simple C file</code></pre>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_post</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstan/reference/stanmodel-method-sampling.html" class="external-link">sampling</a></span><span class="op">(</span><span class="va">stanmodel</span>, data <span class="op">=</span> <span class="va">standata</span>, chains <span class="op">=</span> <span class="va">chains</span>, iter <span class="op">=</span> <span class="va">n_iter</span>, warmup <span class="op">=</span> <span class="va">warm_iter</span>, refresh <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">loo_post</span> <span class="op">&lt;-</span><span class="fu"><a href="../reference/loo.html">loo</a></span><span class="op">(</span><span class="va">fit_post</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">loo_post</span><span class="op">)</span></span></code></pre></div>
<pre><code>
Computed from 4000 by 126 log-likelihood matrix.

         Estimate   SE
elpd_loo    -42.1  7.0
p_loo        23.8  5.1
looic        84.3 13.9
------
MCSE of elpd_loo is NA.
MCSE and ESS estimates assume MCMC draws (r_eff in [0.3, 1.0]).

Pareto k diagnostic values:
                         Count Pct.    Min. ESS
(-Inf, 0.7]   (good)     95    75.4%   108     
   (0.7, 1]   (bad)      24    19.0%   &lt;NA&gt;    
   (1, Inf)   (very bad)  7     5.6%   &lt;NA&gt;    
See help('pareto-k-diagnostic') for details.</code></pre>
<p>As we can see the diagnostics signal either “bad” or “very bad”
Pareto-<span class="math inline">\(k\)</span> values for roughly <span class="math inline">\(15-30\%\)</span> of the observations which is a
significant portion of the dataset.</p>
</div>
<div class="section level3">
<h3 id="mixture-estimators">Mixture estimators<a class="anchor" aria-label="anchor" href="#mixture-estimators"></a>
</h3>
<p>We now compute the mixture estimators proposed in Silva and Zanella
(2022). These require to sample from the following mixture of
leave-one-out posteriors <span class="math display">\[\begin{equation}
q_{mix}(\theta) =  \frac{\sum_{i=1}^n
p(y_{-i}|\theta)p(\theta)}{\sum_{i=1}^np(y_{-i})}\propto
p(\theta|y)\cdot \left(\sum_{i=1}^np(y_i|\theta)^{-1}\right).
\end{equation}\]</span> The code to generate a Stan model for the above
mixture distribution is the same to the one for the posterior, just
enabling one line of code with a <em>LogSumExp</em> contribution to
account for the last term in the equation above.</p>
<pre><code>  if (mixis) {
    target += log_sum_exp(-log_lik);
  }</code></pre>
<p>We sample from the mixture and collect the log-likelihoods term.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">standata</span><span class="op">$</span><span class="va">mixis</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span><span class="va">fit_mix</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstan/reference/stanmodel-method-sampling.html" class="external-link">sampling</a></span><span class="op">(</span><span class="va">stanmodel</span>, data <span class="op">=</span> <span class="va">standata</span>, chains <span class="op">=</span> <span class="va">chains</span>, iter <span class="op">=</span> <span class="va">n_iter</span>, warmup <span class="op">=</span> <span class="va">warm_iter</span>, refresh <span class="op">=</span> <span class="fl">0</span>, pars <span class="op">=</span> <span class="st">"log_lik"</span><span class="op">)</span></span>
<span><span class="va">log_lik_mix</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstan/reference/stanfit-method-extract.html" class="external-link">extract</a></span><span class="op">(</span><span class="va">fit_mix</span><span class="op">)</span><span class="op">$</span><span class="va">log_lik</span></span></code></pre></div>
<p>We now compute the mixture estimators, following the numerically
stable implementation in Appendix A.2 of <a href="https://arxiv.org/abs/2209.09190" class="external-link">Silva and Zanella (2022)</a>.
The code below makes use of the package “matrixStats”.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">l_common_mix</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/matrixStats/man/rowLogSumExps.html" class="external-link">rowLogSumExps</a></span><span class="op">(</span><span class="op">-</span><span class="va">log_lik_mix</span><span class="op">)</span></span>
<span><span class="va">log_weights</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="va">log_lik_mix</span> <span class="op">-</span> <span class="va">l_common_mix</span></span>
<span><span class="va">elpd_mixis</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/matrixStats/man/logSumExp.html" class="external-link">logSumExp</a></span><span class="op">(</span><span class="op">-</span><span class="va">l_common_mix</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/pkg/matrixStats/man/rowLogSumExps.html" class="external-link">rowLogSumExps</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">log_weights</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="comparison-with-benchmark-values-obtained-with-long-simulations">Comparison with benchmark values obtained with long simulations<a class="anchor" aria-label="anchor" href="#comparison-with-benchmark-values-obtained-with-long-simulations"></a>
</h3>
<p>To evaluate the performance of mixture estimators (MixIS) we also
generate <em>benchmark values</em>, i.e. accurate approximations of the
LOO predictives <span class="math inline">\(\{p(y_i|y_{-i})\}_{i=1,\dots,n}\)</span>, obtained
by brute-force sampling from the leave-one-out posteriors directly,
getting <span class="math inline">\(90k\)</span> samples from each and
discarding the first <span class="math inline">\(10k\)</span> as warmup.
This is computationally heavy, hence we have saved the results and we
just load them in the current vignette.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">voice_loo</span><span class="op">)</span></span>
<span><span class="va">elpd_loo</span> <span class="op">&lt;-</span> <span class="va">voice_loo</span><span class="op">$</span><span class="va">elpd_loo</span></span></code></pre></div>
<p>We can then compute the root mean squared error (RMSE) of the PSIS
and mixture estimators relative to such benchmark values.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">elpd_psis</span> <span class="op">&lt;-</span> <span class="va">loo_post</span><span class="op">$</span><span class="va">pointwise</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"RMSE(PSIS) ="</span>,<span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">elpd_loo</span><span class="op">-</span><span class="va">elpd_psis</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span> ,<span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>[1] "RMSE(PSIS) = 0.08"</code></pre>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"RMSE(MixIS) ="</span>,<span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">elpd_loo</span><span class="op">-</span><span class="va">elpd_mixis</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span> ,<span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>[1] "RMSE(MixIS) = 0.06"</code></pre>
<p>Here mixture estimator provides a reduction in RMSE. Note that this
value would increase with the number of samples drawn from the posterior
and mixture, since in this example the RMSE of MixIS will exhibit a
CLT-type decay while the one of PSIS will converge at a slower rate
(this can be verified by running the above code with a larger sample
size; see also Figure 3 of Silva and Zanella (2022) for analogous
results).</p>
<p>We then compare the overall ELPD estimates with the brute force
one.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">elpd_psis</span> <span class="op">&lt;-</span> <span class="va">loo_post</span><span class="op">$</span><span class="va">pointwise</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"ELPD (PSIS)="</span>,<span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">elpd_psis</span><span class="op">)</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>[1] "ELPD (PSIS)= -42.15"</code></pre>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"ELPD (MixIS)="</span>,<span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">elpd_mixis</span><span class="op">)</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>[1] "ELPD (MixIS)= -46.1"</code></pre>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"ELPD (brute force)="</span>,<span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">elpd_loo</span><span class="op">)</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>[1] "ELPD (brute force)= -45.63"</code></pre>
<p>In this example, MixIS provides a more accurate ELPD estimate closer
to the brute force estimate, while PSIS severely overestimates the ELPD.
Note that low accuracy of the PSIS ELPD estimate is expected in this
example given the large number of large Pareto-<span class="math inline">\(k\)</span> values. In this example, the accuracy
of MixIS estimate will also improve with bigger MCMC sample size.</p>
<p>More generally, mixture estimators can be useful in situations where
standard PSIS estimators struggle and return many large Pareto-<span class="math inline">\(k\)</span> values. In these contexts MixIS often
provides more accurate LOO-CV and ELPD estimates with a single sampling
routine (i.e. with a cost comparable to sampling from the original
posterior).</p>
</div>
<div class="section level3">
<h3 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h3>
<p>Silva L. and Zanella G. (2022). Robust leave-one-out cross-validation
for high-dimensional Bayesian models. Preprint at <a href="https://arxiv.org/abs/2209.09190" class="external-link">arXiv:2209.09190</a></p>
<p>Vehtari A., Gelman A., and Gabry J. (2017). Practical Bayesian model
evaluation using leave-one-out cross-validation and WAIC. <em>Statistics
and Computing</em>, 27(5), 1413–1432. Preprint at <a href="https://arxiv.org/abs/1507.04544" class="external-link">arXiv:1507.04544</a></p>
<p>Vehtari A., Simpson D., Gelman A., Yao Y., and Gabry J. (2022).
Pareto smoothed importance sampling. Preprint at <a href="https://arxiv.org/abs/1507.02646" class="external-link">arXiv:1507.02646</a></p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Aki Vehtari, Jonah Gabry, Måns Magnusson, Yuling Yao, Paul-Christian Bürkner, Topi Paananen, Andrew Gelman.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
