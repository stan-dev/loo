<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!-- upstream: inst/BS5/templates/head.html; pkgdown-version: 2.1.3, fe04924 --><!-- https://github.com/r-lib/pkgdown/tree/fe04924b3df129bea60ac871614b01d87bcae147 --><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Mixture IS leave-one-out cross-validation for high-dimensional Bayesian models • loo</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="96x96" href="../favicon-96x96.png">
<link rel="icon" type="”image/svg+xml”" href="../favicon.svg">
<link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
<link rel="icon" sizes="any" href="../favicon.ico">
<link rel="manifest" href="../site.webmanifest">
<!-- mathjax math --><script src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script><script>
  window.MathJax = {
    chtml: {
      fontURL: "https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/output/chtml/fonts/woff-v2"
    }
  };
</script><script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Source_Sans_3-0.4.10/font.css" rel="stylesheet">
<link href="../deps/Source_Code_Pro-0.4.10/font.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- Font Awesome 7.0.1 for Bluesky icon --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/7.0.1/css/all.min.css" referrerpolicy="no-referrer">
<!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Mixture IS leave-one-out cross-validation for high-dimensional Bayesian models">
<meta name="robots" content="noindex">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <!-- upstream: inst/BS5/templates/navbar.html; pkgdown-version: 2.1.3, fe04924 -->
<!-- https://github.com/r-lib/pkgdown/tree/fe04924b3df129bea60ac871614b01d87bcae147 -->
<nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">


    <a class="navbar-brand me-2" href="../index.html">
      <!-- Add Stan logo -->
      <picture><source type="image/svg+xml" srcset="../logo.svg"><img src="../logo.png" class="stan-logo" alt="Stan blue hex logo"></source></picture>
      loo
    </a>

    <small class="nav-text text-danger me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">2.8.0.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../index.html" aria-label="Go to homepage"><span class="fa fa-home fa-lg"></span></a></li>
<li class="active nav-item"><a class="nav-link" href="../articles/index.html">Vignettes</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Functions</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-other-packages" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Other Packages</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-other-packages">
<li><a class="external-link dropdown-item" href="https://mc-stan.org/rstan">rstan</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/cmdstanr">cmdstanr</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/rstanarm">rstanarm</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/bayesplot">bayesplot</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/shinystan">shinystan</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/projpred">projpred</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/rstantools">rstantools</a></li>
    <li><a class="external-link dropdown-item" href="https://mc-stan.org/posterior">posterior</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://mc-stan.org/about/">About Stan</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://bsky.app/profile/did:plc:qznndgdnkem2yryu7ipqbpv7" aria-label="Visit our Bluesky profile"><span class="fa fa-brands fa-bluesky"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://discourse.mc-stan.org/" aria-label="Visit our forums"><span class="fa fa-users"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/stan-dev/loo/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch">
<li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul>
</li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.svg" class="logo" alt=""><h1>Mixture IS leave-one-out cross-validation for high-dimensional Bayesian models</h1>
                        <h4 data-toc-skip class="author">Luca Silva and
Giacomo Zanella</h4>
            
            <h4 data-toc-skip class="date">2025-10-21</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/stan-dev/loo/blob/master/vignettes/loo2-mixis.Rmd" class="external-link"><code>vignettes/loo2-mixis.Rmd</code></a></small>
      <div class="d-none name"><code>loo2-mixis.Rmd</code></div>
    </div>

    
    
<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{Mixture IS leave-one-out cross-validation for high-dimensional Bayesian models}
-->
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>This vignette shows how to perform Bayesian leave-one-out
cross-validation (LOO-CV) using the mixture estimators proposed in the
paper <a href="https://arxiv.org/abs/2209.09190" class="external-link">Silva and Zanella
(2022)</a>. These estimators have shown to be useful in presence of
outliers but also, and especially, in high-dimensional settings where
the model features many parameters. In these contexts it can happen that
a large portion of observations lead to high values of Pareto-<span class="math inline">\(k\)</span> diagnostics and potential instability
of PSIS-LOO estimators.</p>
<p>For this illustration we consider a high-dimensional Bayesian
Logistic regression model applied to the <em>Voice</em> dataset.</p>
<div class="section level3">
<h3 id="setup-load-packages-and-set-seed">Setup: load packages and set seed<a class="anchor" aria-label="anchor" href="#setup-load-packages-and-set-seed"></a>
</h3>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://mc-stan.org/rstan/" class="external-link">"rstan"</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://mc-stan.org/loo/">"loo"</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/HenrikBengtsson/matrixStats" class="external-link">"matrixStats"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/options.html" class="external-link">options</a></span><span class="op">(</span>mc.cores <span class="op">=</span> <span class="fu">parallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/parallel/detectCores.html" class="external-link">detectCores</a></span><span class="op">(</span><span class="op">)</span>, parallel<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">24877</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="model">Model<a class="anchor" aria-label="anchor" href="#model"></a>
</h3>
<p>This is the Stan code for a logistic regression model with
regularized horseshoe prior. The code includes an if statement to
include a code line needed later for the MixIS approach.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Note: some syntax used in this program requires RStan &gt;= 2.26 (or CmdStanR)</span></span>
<span><span class="co"># To use an older version of RStan change the line declaring `y` to:</span></span>
<span><span class="co">#    int&lt;lower=0,upper=1&gt; y[N];</span></span>
<span><span class="va">stancode_horseshoe</span> <span class="op">&lt;-</span> <span class="st">"</span></span>
<span><span class="st">data {</span></span>
<span><span class="st">  int &lt;lower=0&gt; N;</span></span>
<span><span class="st">  int &lt;lower=0&gt; P;</span></span>
<span><span class="st">  array[N] int &lt;lower=0, upper=1&gt; y;</span></span>
<span><span class="st">  matrix [N,P] X;</span></span>
<span><span class="st">  real &lt;lower=0&gt; scale_global;</span></span>
<span><span class="st">  int &lt;lower=0,upper=1&gt; mixis;</span></span>
<span><span class="st">}</span></span>
<span><span class="st">transformed data {</span></span>
<span><span class="st">  real&lt;lower=1&gt; nu_global=1; // degrees of freedom for the half-t priors for tau</span></span>
<span><span class="st">  real&lt;lower=1&gt; nu_local=1;  // degrees of freedom for the half-t priors for lambdas</span></span>
<span><span class="st">                             // (nu_local = 1 corresponds to the horseshoe)</span></span>
<span><span class="st">  real&lt;lower=0&gt; slab_scale=2;// for the regularized horseshoe</span></span>
<span><span class="st">  real&lt;lower=0&gt; slab_df=100; // for the regularized horseshoe</span></span>
<span><span class="st">}</span></span>
<span><span class="st">parameters {</span></span>
<span><span class="st">  vector[P] z;                // for non-centered parameterization</span></span>
<span><span class="st">  real &lt;lower=0&gt; tau;         // global shrinkage parameter</span></span>
<span><span class="st">  vector &lt;lower=0&gt;[P] lambda; // local shrinkage parameter</span></span>
<span><span class="st">  real&lt;lower=0&gt; caux;</span></span>
<span><span class="st">}</span></span>
<span><span class="st">transformed parameters {</span></span>
<span><span class="st">  vector[P] beta;</span></span>
<span><span class="st">  { </span></span>
<span><span class="st">    vector[P] lambda_tilde;   // 'truncated' local shrinkage parameter</span></span>
<span><span class="st">    real c = slab_scale * sqrt(caux); // slab scale</span></span>
<span><span class="st">    lambda_tilde = sqrt( c^2 * square(lambda) ./ (c^2 + tau^2*square(lambda)));</span></span>
<span><span class="st">    beta = z .* lambda_tilde*tau;</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">}</span></span>
<span><span class="st">model {</span></span>
<span><span class="st">  vector[N] means=X*beta;</span></span>
<span><span class="st">  vector[N] log_lik;</span></span>
<span><span class="st">  target += std_normal_lpdf(z);</span></span>
<span><span class="st">  target += student_t_lpdf(lambda | nu_local, 0, 1);</span></span>
<span><span class="st">  target += student_t_lpdf(tau | nu_global, 0, scale_global);</span></span>
<span><span class="st">  target += inv_gamma_lpdf(caux | 0.5*slab_df, 0.5*slab_df);</span></span>
<span><span class="st">  for (n in 1:N) {</span></span>
<span><span class="st">    log_lik[n]= bernoulli_logit_lpmf(y[n] | means[n]);</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">  target += sum(log_lik);</span></span>
<span><span class="st">  if (mixis) {</span></span>
<span><span class="st">    target += log_sum_exp(-log_lik);</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">}</span></span>
<span><span class="st">generated quantities {</span></span>
<span><span class="st">  vector[N] means=X*beta;</span></span>
<span><span class="st">  vector[N] log_lik;</span></span>
<span><span class="st">  for (n in 1:N) {</span></span>
<span><span class="st">    log_lik[n] = bernoulli_logit_lpmf(y[n] | means[n]);</span></span>
<span><span class="st">  }</span></span>
<span><span class="st">}</span></span>
<span><span class="st">"</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="dataset">Dataset<a class="anchor" aria-label="anchor" href="#dataset"></a>
</h3>
<p>The <em>LSVT Voice Rehabilitation Data Set</em> (see <a href="https://archive.ics.uci.edu/ml/datasets/LSVT+Voice+Rehabilitation" class="external-link">link</a>
for details) has <span class="math inline">\(p=312\)</span> covariates
and <span class="math inline">\(n=126\)</span> observations with binary
response. We construct data list for Stan.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">voice</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">voice</span><span class="op">$</span><span class="va">y</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="va">voice</span><span class="op">[</span><span class="fl">2</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">voice</span><span class="op">)</span><span class="op">]</span></span>
<span><span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span></span>
<span><span class="va">p0</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span><span class="va">scale_global</span> <span class="op">&lt;-</span> <span class="fl">2</span><span class="op">*</span><span class="va">p0</span><span class="op">/</span><span class="op">(</span><span class="va">p</span><span class="op">-</span><span class="va">p0</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="va">n</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">standata</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>N <span class="op">=</span> <span class="va">n</span>, P <span class="op">=</span> <span class="va">p</span>, X <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span>, y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, scale_global <span class="op">=</span> <span class="va">scale_global</span>, mixis <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<p>Note that in our prior specification we divide the prior variance by
the number of covariates <span class="math inline">\(p\)</span>. This is
often done in high-dimensional contexts to have a prior variance for the
linear predictors <span class="math inline">\(X\beta\)</span> that
remains bounded as <span class="math inline">\(p\)</span> increases.</p>
</div>
<div class="section level3">
<h3 id="psis-estimators-and-pareto-k-diagnostics">PSIS estimators and Pareto-<span class="math inline">\(k\)</span>
diagnostics<a class="anchor" aria-label="anchor" href="#psis-estimators-and-pareto-k-diagnostics"></a>
</h3>
<p>LOO-CV computations are challenging in this context due to
high-dimensionality of the parameter space. To show that, we compute
PSIS-LOO estimators, which require sampling from the posterior
distribution, and inspect the associated Pareto-<span class="math inline">\(k\)</span> diagnostics.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">chains</span> <span class="op">&lt;-</span> <span class="fl">4</span></span>
<span><span class="va">n_iter</span> <span class="op">&lt;-</span> <span class="fl">2000</span></span>
<span><span class="va">warm_iter</span> <span class="op">&lt;-</span> <span class="fl">1000</span></span>
<span><span class="va">stanmodel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstan/reference/stan_model.html" class="external-link">stan_model</a></span><span class="op">(</span>model_code <span class="op">=</span> <span class="va">stancode_horseshoe</span><span class="op">)</span></span></code></pre></div>
<pre><code>Trying to compile a simple C file</code></pre>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_post</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstan/reference/stanmodel-method-sampling.html" class="external-link">sampling</a></span><span class="op">(</span><span class="va">stanmodel</span>, data <span class="op">=</span> <span class="va">standata</span>, chains <span class="op">=</span> <span class="va">chains</span>, iter <span class="op">=</span> <span class="va">n_iter</span>, warmup <span class="op">=</span> <span class="va">warm_iter</span>, refresh <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">loo_post</span> <span class="op">&lt;-</span><span class="fu"><a href="../reference/loo.html">loo</a></span><span class="op">(</span><span class="va">fit_post</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">loo_post</span><span class="op">)</span></span></code></pre></div>
<pre><code>
Computed from 4000 by 126 log-likelihood matrix.

         Estimate   SE
elpd_loo    -43.0  6.9
p_loo        24.0  4.9
looic        85.9 13.8
------
MCSE of elpd_loo is NA.
MCSE and ESS estimates assume MCMC draws (r_eff in [0.4, 1.0]).

Pareto k diagnostic values:
                         Count Pct.    Min. ESS
(-Inf, 0.7]   (good)     97    77.0%   101     
   (0.7, 1]   (bad)      21    16.7%   &lt;NA&gt;    
   (1, Inf)   (very bad)  8     6.3%   &lt;NA&gt;    
See help('pareto-k-diagnostic') for details.</code></pre>
<p>As we can see the diagnostics signal either “bad” or “very bad”
Pareto-<span class="math inline">\(k\)</span> values for roughly <span class="math inline">\(15-30\%\)</span> of the observations which is a
significant portion of the dataset.</p>
</div>
<div class="section level3">
<h3 id="mixture-estimators">Mixture estimators<a class="anchor" aria-label="anchor" href="#mixture-estimators"></a>
</h3>
<p>We now compute the mixture estimators proposed in Silva and Zanella
(2022). These require to sample from the following mixture of
leave-one-out posteriors <span class="math display">\[\begin{equation}
q_{mix}(\theta) =  \frac{\sum_{i=1}^n
p(y_{-i}|\theta)p(\theta)}{\sum_{i=1}^np(y_{-i})}\propto
p(\theta|y)\cdot \left(\sum_{i=1}^np(y_i|\theta)^{-1}\right).
\end{equation}\]</span> The code to generate a Stan model for the above
mixture distribution is the same to the one for the posterior, just
enabling one line of code with a <em>LogSumExp</em> contribution to
account for the last term in the equation above.</p>
<pre><code>  if (mixis) {
    target += log_sum_exp(-log_lik);
  }</code></pre>
<p>We sample from the mixture and collect the log-likelihoods term.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">standata</span><span class="op">$</span><span class="va">mixis</span> <span class="op">&lt;-</span> <span class="fl">1</span></span>
<span><span class="va">fit_mix</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstan/reference/stanmodel-method-sampling.html" class="external-link">sampling</a></span><span class="op">(</span><span class="va">stanmodel</span>, data <span class="op">=</span> <span class="va">standata</span>, chains <span class="op">=</span> <span class="va">chains</span>, iter <span class="op">=</span> <span class="va">n_iter</span>, warmup <span class="op">=</span> <span class="va">warm_iter</span>, refresh <span class="op">=</span> <span class="fl">0</span>, pars <span class="op">=</span> <span class="st">"log_lik"</span><span class="op">)</span></span>
<span><span class="va">log_lik_mix</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://mc-stan.org/rstan/reference/stanfit-method-extract.html" class="external-link">extract</a></span><span class="op">(</span><span class="va">fit_mix</span><span class="op">)</span><span class="op">$</span><span class="va">log_lik</span></span></code></pre></div>
<p>We now compute the mixture estimators, following the numerically
stable implementation in Appendix A.2 of <a href="https://arxiv.org/abs/2209.09190" class="external-link">Silva and Zanella (2022)</a>.
The code below makes use of the package “matrixStats”.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">l_common_mix</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/matrixStats/man/rowLogSumExps.html" class="external-link">rowLogSumExps</a></span><span class="op">(</span><span class="op">-</span><span class="va">log_lik_mix</span><span class="op">)</span></span>
<span><span class="va">log_weights</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="va">log_lik_mix</span> <span class="op">-</span> <span class="va">l_common_mix</span></span>
<span><span class="va">elpd_mixis</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/matrixStats/man/logSumExp.html" class="external-link">logSumExp</a></span><span class="op">(</span><span class="op">-</span><span class="va">l_common_mix</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/pkg/matrixStats/man/rowLogSumExps.html" class="external-link">rowLogSumExps</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">log_weights</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="comparison-with-benchmark-values-obtained-with-long-simulations">Comparison with benchmark values obtained with long simulations<a class="anchor" aria-label="anchor" href="#comparison-with-benchmark-values-obtained-with-long-simulations"></a>
</h3>
<p>To evaluate the performance of mixture estimators (MixIS) we also
generate <em>benchmark values</em>, i.e. accurate approximations of the
LOO predictives <span class="math inline">\(\{p(y_i|y_{-i})\}_{i=1,\dots,n}\)</span>, obtained
by brute-force sampling from the leave-one-out posteriors directly,
getting <span class="math inline">\(90k\)</span> samples from each and
discarding the first <span class="math inline">\(10k\)</span> as warmup.
This is computationally heavy, hence we have saved the results and we
just load them in the current vignette.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">voice_loo</span><span class="op">)</span></span>
<span><span class="va">elpd_loo</span> <span class="op">&lt;-</span> <span class="va">voice_loo</span><span class="op">$</span><span class="va">elpd_loo</span></span></code></pre></div>
<p>We can then compute the root mean squared error (RMSE) of the PSIS
and mixture estimators relative to such benchmark values.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">elpd_psis</span> <span class="op">&lt;-</span> <span class="va">loo_post</span><span class="op">$</span><span class="va">pointwise</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"RMSE(PSIS) ="</span>,<span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">elpd_loo</span><span class="op">-</span><span class="va">elpd_psis</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span> ,<span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>[1] "RMSE(PSIS) = 0.08"</code></pre>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"RMSE(MixIS) ="</span>,<span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">elpd_loo</span><span class="op">-</span><span class="va">elpd_mixis</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span> ,<span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>[1] "RMSE(MixIS) = 0.04"</code></pre>
<p>Here mixture estimator provides a reduction in RMSE. Note that this
value would increase with the number of samples drawn from the posterior
and mixture, since in this example the RMSE of MixIS will exhibit a
CLT-type decay while the one of PSIS will converge at a slower rate
(this can be verified by running the above code with a larger sample
size; see also Figure 3 of Silva and Zanella (2022) for analogous
results).</p>
<p>We then compare the overall ELPD estimates with the brute force
one.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">elpd_psis</span> <span class="op">&lt;-</span> <span class="va">loo_post</span><span class="op">$</span><span class="va">pointwise</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"ELPD (PSIS)="</span>,<span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">elpd_psis</span><span class="op">)</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>[1] "ELPD (PSIS)= -42.95"</code></pre>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"ELPD (MixIS)="</span>,<span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">elpd_mixis</span><span class="op">)</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>[1] "ELPD (MixIS)= -45.49"</code></pre>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste</a></span><span class="op">(</span><span class="st">"ELPD (brute force)="</span>,<span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">elpd_loo</span><span class="op">)</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>[1] "ELPD (brute force)= -45.63"</code></pre>
<p>In this example, MixIS provides a more accurate ELPD estimate closer
to the brute force estimate, while PSIS severely overestimates the ELPD.
Note that low accuracy of the PSIS ELPD estimate is expected in this
example given the large number of large Pareto-<span class="math inline">\(k\)</span> values. In this example, the accuracy
of MixIS estimate will also improve with bigger MCMC sample size.</p>
<p>More generally, mixture estimators can be useful in situations where
standard PSIS estimators struggle and return many large Pareto-<span class="math inline">\(k\)</span> values. In these contexts MixIS often
provides more accurate LOO-CV and ELPD estimates with a single sampling
routine (i.e. with a cost comparable to sampling from the original
posterior).</p>
</div>
<div class="section level3">
<h3 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h3>
<p>Silva L. and Zanella G. (2022). Robust leave-one-out cross-validation
for high-dimensional Bayesian models. Preprint at <a href="https://arxiv.org/abs/2209.09190" class="external-link">arXiv:2209.09190</a></p>
<p>Vehtari A., Gelman A., and Gabry J. (2017). Practical Bayesian model
evaluation using leave-one-out cross-validation and WAIC. <em>Statistics
and Computing</em>, 27(5), 1413–1432. Preprint at <a href="https://arxiv.org/abs/1507.04544" class="external-link">arXiv:1507.04544</a></p>
<p>Vehtari, A., Simpson, D., Gelman, A., Yao, Y., and Gabry, J. (2024).
Pareto smoothed importance sampling. <em>Journal of Machine Learning
Research</em>, 25(72):1-58. <a href="https://jmlr.org/papers/v25/19-556.html" class="external-link">PDF</a></p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Aki Vehtari, Jonah Gabry, Måns Magnusson, Yuling Yao, Paul-Christian Bürkner, Topi Paananen, Andrew Gelman.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
