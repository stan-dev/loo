% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bb-stacking.R
\name{model_weights}
\alias{model_weights}
\alias{model_weights.default}
\alias{stacking_weights}
\alias{pseudobma_weights}
\title{Model averaging/weighting via stacking or pseudo-BMA weighting}
\usage{
model_weights(x, ...)

\method{model_weights}{default}(x, ..., method = c("stacking", "pseudobma"),
  optim_method = "BFGS", optim_control = list(), BB = TRUE, BB_n = 1000,
  alpha = 1, seed = NULL, r_eff_list = NULL,
  cores = getOption("loo.cores", 1))

stacking_weights(lpd_point, optim_method = "BFGS", optim_control = list())

pseudobma_weights(lpd_point, BB = TRUE, BB_n = 1000, alpha = 1,
  seed = NULL)
}
\arguments{
\item{x}{A list of pointwise log-likelihood matrices, one for each model.
Each matrix should have dimensions \eqn{S} by \eqn{N}, where \eqn{S} is the
size of the posterior sample (with all chains merged) and \eqn{N} is the
number of data points.}

\item{...}{Unused, except for the generic to pass arguments to individual
methods.}

\item{method}{Either \code{"stacking"} or \code{"pseudobma"}, indicating
which method to use for obtaining the weights. \code{"stacking"} refers to
stacking of predictive distributions and  \code{"pseudobma"} refers to
pseudo-BMA weighting (by setting \code{BB=FALSE}) or pseudo-BMA+ weighting
(by leaving the default \code{BB=TRUE}).}

\item{optim_method}{The optimization method to use if
\code{method="stacking"}. It can be chosen from "Nelder-Mead", "BFGS",
"CG", "L-BFGS-B", "SANN" and "Brent". The default method is "BFGS".}

\item{optim_control}{If \code{method="stacking"}, a list of control
parameters for optimization. See \code{\link{constrOptim}} for details.}

\item{BB}{Logical used when \code{"method"}=\code{"pseudobma"}. If
\code{TRUE} (the default), the Bayesian bootstrap will be used to adjust the
pseudo-BMA weighting, which is called pseudo-BMA+ weighting. It helps
regularize the weight away from 0 and 1, so as to reduce the variance.}

\item{BB_n}{When \code{BB}=\code{TRUE}, a positive integer indicating the
number of samples for the Bayesian bootstrap. The default is 1000.}

\item{alpha}{A positive scalar; the shape parameter in the Dirichlet
distribution used for the Bayesian bootstrap. The default is 1, which
corresponds to a uniform distribution on the simplex space.}

\item{seed}{When \code{BB}=\code{TRUE}, an optional integer seed for the
Bayesian bootstrap sampling.}

\item{r_eff_list}{Optionally, a list of relative effective sample size
estimates for the likelihood \code{(exp(log_lik))} of each observation in
each model. See \code{\link{psis}} and  \code{\link{relative_eff}} helper
function for computing \code{r_eff}.}

\item{cores}{The number of cores to use for parallelization. Same as for
\code{\link{psis}}. The default for an entire R session can be set with
\code{options(loo.cores = NUMBER)}. \strong{As of version 2.0.0 the default
is now 1 core, but we recommend using as many (or close to as many) cores
as possible.}}

\item{lpd_point}{A matrix of pointwise log leave-one-out likelihoods
evaluated for different models. It should be a \eqn{N} by \eqn{K}  matrix
where \eqn{N} is sample size and \eqn{K} is the number of models. Each
column corresponds to one model. These values can be calculated
approximately using \code{\link{loo}} or by running exact leave-one-out
cross-validation.}
}
\value{
A numeric vector containing one weight for each model.
}
\description{
Model averaging via stacking of predictive distributions,
  pseudo-BMA weighting or pseudo-BMA+ weighting with the Bayesian bootstrap.
  See Yao et al. (2017) and  Vehtari, Gelman, and Gabry (2017) for
  background.
}
\details{
\code{model_weights} implements stacking, pseudo-BMA, and pseudo-BMA+
weighting for combining multiple predictive distributions. In all cases, we
can use leave-one-out cross-validation (LOO) to estimate the expected log
predictive density (ELPD).

The stacking method (\code{method="stacking"}) combines all models by
maximizing the leave-one-out predictive density of the combination
distribution. That is, it finds the optimal linear combining weights for
maximizing the leave-one-out log score.

The pseudo-BMA method (\code{method="pseudobma"}) finds the relative weights
proportional to the ELPD of each model. However, when
\code{method="pseudobma"}, the default is to also use the Bayesian bootstrap
(\code{BB=TRUE}), which corresponds to the pseudo-BMA+ method. The Bayesian
bootstrap  takes into account the uncertainty of finite data points and
regularizes the weights away from the extremes of 0 and 1.

In general, we recommend stacking for averaging predictive distributions,
while pseudo-BMA+ can serve as a computationally easier alternative.
}
\examples{
\dontrun{
### Demonstrating usage after fitting models with RStan
library(rstan)

# generate fake data from N(0,1).
set.seed(100)
N <- 100
y <- rnorm(N, 0, 1)

# Suppose we have three models: N(-1, sigma), N(0.5, sigma) and N(0.6,sigma).
stan_code <- "
  data {
    int N;
    vector[N] y;
    real mu_fixed;
  }
  parameters {
    real<lower=0> sigma;
  }
  model {
    sigma ~ exponential(1);
    y ~ normal(mu_fixed, sigma);
  }
  generated quantities {
    vector[N] log_lik;
    for (n in 1:N) log_lik[n] = normal_lpdf(y[n]| mu_fixed, sigma);
  }"

mod <- stan_model(model_code = stan_code)
fit1 <- sampling(mod, data=list(N=N, y=y, mu_fixed=-1))
fit2 <- sampling(mod, data=list(N=N, y=y, mu_fixed=0.5))
fit3 <- sampling(mod, data=list(N=N, y=y, mu_fixed=0.6))
log_lik_list <- lapply(c(fit1, fit2, fit3), extract_log_lik)

# optional but recommended
r_eff_list <- lapply(c(fit1, fit2, fit3), function(x) {
  relative_eff(exp(extract_log_lik(x, merge_chains = FALSE)))
})

# stacking method:
model_weights(
  log_lik_list,
  method="stacking",
  r_eff_list = r_eff_list,
  optim_control = list(reltol=1e-10)
)

# pseudo-BMA+ method:
model_weights(
  log_lik_list,
  method = "pseudobma",
  r_eff_list=r_eff_list
 )

# pseudo-BMA method (set BB = FALSE):
model_weights(
  log_lik_list,
  method = "pseudobma",
  BB = FALSE,
  r_eff_list=r_eff_list
 )

# calling stacking_weights or pseudobma_weights directly
lpd1 <- loo(log_lik_list[[1]], r_eff = r_eff_list[[1]])$pointwise[,1]
lpd2 <- loo(log_lik_list[[2]], r_eff = r_eff_list[[2]])$pointwise[,1]
lpd3 <- loo(log_lik_list[[3]], r_eff = r_eff_list[[3]])$pointwise[,1]
stacking_weights(cbind(lpd1, lpd2, lpd3))
pseudobma_weights(cbind(lpd1, lpd2, lpd3))
pseudobma_weights(cbind(lpd1, lpd2, lpd3), BB = FALSE)
}

}
\references{
Vehtari, A., Gelman, A., and Gabry, J. (2017). Practical
  Bayesian model evaluation using leave-one-out cross-validation and WAIC.
  \emph{Statistics and Computing}. 27(5), 1413--1432.
  doi:10.1007/s11222-016-9696-4.
  (\href{http://link.springer.com/article/10.1007\%2Fs11222-016-9696-4}{published
  version}, \href{http://arxiv.org/abs/1507.04544}{arXiv preprint}).

Yao, Y., Vehtari, A., Simpson, D., and Gelman, A. (2017) Using
stacking to average Bayesian predictive distributions. \emph{Bayesian Analysis},
advance publication,  doi:10.1214/17-BA1091. (\href{https://projecteuclid.org/euclid.ba/1516093227}{online}).
}
\seealso{
\itemize{
\item \code{\link{loo}} for details on leave-one-out ELPD estimation.
\item \code{\link{constrOptim}} for the choice of optimization methods and control-parameters.
\item \code{\link{relative_eff}} for computing \code{r_eff}.
}
}
